 INFO [2020-10-30 18:17:22,600] ({main} ZeppelinConfiguration.java[create]:121) - Load configuration from file:/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/zeppelin-site.xml
 WARN [2020-10-30 18:17:22,683] ({main} ZeppelinConfiguration.java[create]:124) - Failed to load configuration from file:/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/zeppelin-site.xml proceeding with a default
org.apache.commons.configuration.ConfigurationException: Error parsing file:/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/zeppelin-site.xml
	at org.apache.commons.configuration.XMLConfiguration.load(XMLConfiguration.java:950)
	at org.apache.commons.configuration.XMLConfiguration.load(XMLConfiguration.java:908)
	at org.apache.commons.configuration.XMLConfiguration$XMLFileConfigurationDelegate.load(XMLConfiguration.java:1583)
	at org.apache.commons.configuration.AbstractFileConfiguration.load(AbstractFileConfiguration.java:324)
	at org.apache.commons.configuration.AbstractHierarchicalFileConfiguration.load(AbstractHierarchicalFileConfiguration.java:199)
	at org.apache.zeppelin.conf.ZeppelinConfiguration.<init>(ZeppelinConfiguration.java:52)
	at org.apache.zeppelin.conf.ZeppelinConfiguration.create(ZeppelinConfiguration.java:122)
	at org.apache.zeppelin.server.ZeppelinServer.main(ZeppelinServer.java:219)
Caused by: org.xml.sax.SAXParseException; systemId: file:/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/zeppelin-site.xml; lineNumber: 1; columnNumber: 1; Premature end of file.
	at com.sun.org.apache.xerces.internal.parsers.DOMParser.parse(DOMParser.java:257)
	at com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderImpl.parse(DocumentBuilderImpl.java:339)
	at org.apache.commons.configuration.XMLConfiguration.load(XMLConfiguration.java:942)
	... 7 more
 INFO [2020-10-30 18:17:22,711] ({main} ZeppelinConfiguration.java[create]:129) - Server Host: 127.0.0.1
 INFO [2020-10-30 18:17:22,711] ({main} ZeppelinConfiguration.java[create]:131) - Server Port: 9322
 INFO [2020-10-30 18:17:22,711] ({main} ZeppelinConfiguration.java[create]:135) - Context Path: /
 INFO [2020-10-30 18:17:22,713] ({main} ZeppelinConfiguration.java[create]:136) - Zeppelin Version: 0.8.2
 INFO [2020-10-30 18:17:22,741] ({main} Log.java[initialized]:193) - Logging initialized @920ms to org.eclipse.jetty.util.log.Slf4jLog
 WARN [2020-10-30 18:17:22,867] ({main} ServerConnector.java[setSoLingerTime]:458) - Ignoring deprecated socket close linger time
 INFO [2020-10-30 18:17:22,928] ({main} ZeppelinServer.java[setupWebAppContext]:413) - ZeppelinServer Webapp path: /users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/webapps
 INFO [2020-10-30 18:17:23,019] ({main} ZeppelinServer.java[main]:239) - Starting zeppelin server
 INFO [2020-10-30 18:17:23,020] ({main} Server.java[doStart]:370) - jetty-9.4.14.v20181114; built: 2018-11-14T21:20:31.478Z; git: c4550056e785fb5665914545889f21dc136ad9e6; jvm 1.8.0_152-release-1056-b12
 INFO [2020-10-30 18:17:28,570] ({main} StandardDescriptorProcessor.java[visitServlet]:283) - NO JSP Support for /, did not find org.eclipse.jetty.jsp.JettyJspServlet
 INFO [2020-10-30 18:17:28,593] ({main} DefaultSessionIdManager.java[doStart]:365) - DefaultSessionIdManager workerName=node0
 INFO [2020-10-30 18:17:28,594] ({main} DefaultSessionIdManager.java[doStart]:370) - No SessionScavenger set, using defaults
 INFO [2020-10-30 18:17:28,597] ({main} HouseKeeper.java[startScavenging]:149) - node0 Scavenging every 660000ms
 INFO [2020-10-30 18:17:28,981] ({main} SchedulerFactory.java[<init>]:59) - Scheduler Thread Pool Size: 100
 WARN [2020-10-30 18:17:29,002] ({main} ZeppelinConfiguration.java[getConfigFSDir]:527) - zeppelin.config.fs.dir is not specified, fall back to local conf directory zeppelin.conf.dir
 WARN [2020-10-30 18:17:29,002] ({main} ZeppelinConfiguration.java[getConfigFSDir]:527) - zeppelin.config.fs.dir is not specified, fall back to local conf directory zeppelin.conf.dir
 INFO [2020-10-30 18:17:29,100] ({main} InterpreterSettingManager.java[<init>]:165) - Using RecoveryStorage: org.apache.zeppelin.interpreter.recovery.NullRecoveryStorage
 INFO [2020-10-30 18:17:29,101] ({main} InterpreterSettingManager.java[<init>]:169) - Using LifecycleManager: org.apache.zeppelin.interpreter.lifecycle.NullLifecycleManager
 INFO [2020-10-30 18:17:29,157] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: cassandra
 WARN [2020-10-30 18:17:29,164] ({main} InterpreterSettingManager.java[init]:331) - No interpreter-setting.json found in /users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/${interpreter.name}
 INFO [2020-10-30 18:17:29,169] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: angular
 INFO [2020-10-30 18:17:29,180] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: md
 INFO [2020-10-30 18:17:29,184] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: alluxio
 INFO [2020-10-30 18:17:29,188] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: groovy
 INFO [2020-10-30 18:17:29,192] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: pig
 INFO [2020-10-30 18:17:29,195] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: file
 INFO [2020-10-30 18:17:29,199] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: elasticsearch
 INFO [2020-10-30 18:17:29,203] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: lens
 INFO [2020-10-30 18:17:29,206] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: kylin
 INFO [2020-10-30 18:17:29,210] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: sap
 INFO [2020-10-30 18:17:29,215] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: ignite
 INFO [2020-10-30 18:17:29,229] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: neo4j
 INFO [2020-10-30 18:17:29,232] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: python
 INFO [2020-10-30 18:17:29,235] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: bigquery
 WARN [2020-10-30 18:17:29,600] ({main} InterpreterSettingManager.java[init]:331) - No interpreter-setting.json found in /users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/scio
 INFO [2020-10-30 18:17:29,606] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: spark
 INFO [2020-10-30 18:17:29,610] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: livy
 WARN [2020-10-30 18:17:29,615] ({main} InterpreterSettingManager.java[init]:331) - No interpreter-setting.json found in /users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/lib
 INFO [2020-10-30 18:17:29,619] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: sh
 INFO [2020-10-30 18:17:29,622] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: flink
 INFO [2020-10-30 18:17:29,626] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: hbase
 INFO [2020-10-30 18:17:29,629] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: jdbc
 INFO [2020-10-30 18:17:29,630] ({main} LocalConfigStorage.java[loadInterpreterSettings]:63) - Load Interpreter Setting from file: /users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/conf/interpreter.json
 INFO [2020-10-30 18:17:29,691] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting ignite from interpreter.json
 INFO [2020-10-30 18:17:29,692] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting python from interpreter.json
 INFO [2020-10-30 18:17:29,693] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting sap from interpreter.json
 INFO [2020-10-30 18:17:29,694] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting jdbc from interpreter.json
 INFO [2020-10-30 18:17:29,695] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting lens from interpreter.json
 INFO [2020-10-30 18:17:29,695] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting pig from interpreter.json
 INFO [2020-10-30 18:17:29,696] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting flink from interpreter.json
 INFO [2020-10-30 18:17:29,696] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting angular from interpreter.json
 INFO [2020-10-30 18:17:29,698] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting livy from interpreter.json
 INFO [2020-10-30 18:17:29,698] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting groovy from interpreter.json
 INFO [2020-10-30 18:17:29,698] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting neo4j from interpreter.json
 INFO [2020-10-30 18:17:29,699] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting file from interpreter.json
 INFO [2020-10-30 18:17:29,699] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting elasticsearch from interpreter.json
 INFO [2020-10-30 18:17:29,700] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting spark from interpreter.json
 INFO [2020-10-30 18:17:29,702] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting cassandra from interpreter.json
 INFO [2020-10-30 18:17:29,702] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting sh from interpreter.json
 INFO [2020-10-30 18:17:29,703] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting md from interpreter.json
 INFO [2020-10-30 18:17:29,703] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting alluxio from interpreter.json
 INFO [2020-10-30 18:17:29,703] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting bigquery from interpreter.json
 INFO [2020-10-30 18:17:29,703] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting hbase from interpreter.json
 INFO [2020-10-30 18:17:29,704] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting kylin from interpreter.json
 INFO [2020-10-30 18:17:29,718] ({main} LocalConfigStorage.java[save]:53) - Save Interpreter Setting to /users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/conf/interpreter.json
 INFO [2020-10-30 18:17:29,951] ({main} VfsLog.java[info]:138) - Using "/tmp/vfs_cache" as temporary files store.
 INFO [2020-10-30 18:17:30,008] ({main} GitNotebookRepo.java[<init>]:64) - Opening a git repo at '/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/notebook'
 INFO [2020-10-30 18:17:30,155] ({main} NotebookRepoSync.java[<init>]:77) - Instantiate NotebookRepo: org.apache.zeppelin.notebook.repo.GitNotebookRepo
 WARN [2020-10-30 18:17:30,358] ({main} NotebookAuthorization.java[getInstance]:86) - Notebook authorization module was called without initialization, initializing with default configuration
 INFO [2020-10-30 18:17:30,358] ({main} LocalConfigStorage.java[loadNotebookAuthorization]:80) - Load notebook authorization from file: /users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/conf/notebook-authorization.json
 INFO [2020-10-30 18:17:30,362] ({main} Credentials.java[loadFromFile]:121) - /users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/conf/credentials.json
 INFO [2020-10-30 18:17:30,410] ({main} StdSchedulerFactory.java[instantiate]:1184) - Using default implementation for ThreadExecutor
 INFO [2020-10-30 18:17:30,413] ({main} SimpleThreadPool.java[initialize]:268) - Job execution threads will use class loader of thread: main
 INFO [2020-10-30 18:17:30,428] ({main} SchedulerSignalerImpl.java[<init>]:61) - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
 INFO [2020-10-30 18:17:30,429] ({main} QuartzScheduler.java[<init>]:240) - Quartz Scheduler v.2.2.1 created.
 INFO [2020-10-30 18:17:30,430] ({main} RAMJobStore.java[initialize]:155) - RAMJobStore initialized.
 INFO [2020-10-30 18:17:30,431] ({main} QuartzScheduler.java[initialize]:305) - Scheduler meta-data: Quartz Scheduler (v2.2.1) 'DefaultQuartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

 INFO [2020-10-30 18:17:30,431] ({main} StdSchedulerFactory.java[instantiate]:1339) - Quartz scheduler 'DefaultQuartzScheduler' initialized from default resource file in Quartz package: 'quartz.properties'
 INFO [2020-10-30 18:17:30,432] ({main} StdSchedulerFactory.java[instantiate]:1343) - Quartz scheduler version: 2.2.1
 INFO [2020-10-30 18:17:30,432] ({main} QuartzScheduler.java[start]:575) - Scheduler DefaultQuartzScheduler_$_NON_CLUSTERED started.
 INFO [2020-10-30 18:17:30,813] ({main} FolderView.java[createFolder]:107) - Create folder Zeppelin Tutorial
 INFO [2020-10-30 18:17:30,814] ({main} FolderView.java[createFolder]:107) - Create folder /
 INFO [2020-10-30 18:17:30,814] ({main} Folder.java[setParent]:169) - Set parent of / to /
 INFO [2020-10-30 18:17:30,814] ({main} Folder.java[setParent]:169) - Set parent of Zeppelin Tutorial to /
 INFO [2020-10-30 18:17:30,814] ({main} Folder.java[addNote]:185) - Add note 2A94M5J1Z to folder Zeppelin Tutorial
 WARN [2020-10-30 18:17:30,815] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 18:17:30,831] ({main} Folder.java[addNote]:185) - Add note 2BWJFTXKJ to folder Zeppelin Tutorial
 WARN [2020-10-30 18:17:30,832] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 18:17:30,853] ({main} FolderView.java[createFolder]:107) - Create folder Diplodatos
 INFO [2020-10-30 18:17:30,853] ({main} Folder.java[setParent]:169) - Set parent of Diplodatos to /
 INFO [2020-10-30 18:17:30,853] ({main} Folder.java[addNote]:185) - Add note 2FMXBM6HK to folder Diplodatos
 WARN [2020-10-30 18:17:30,854] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 18:17:30,886] ({main} Folder.java[addNote]:185) - Add note 2FP83VA8P to folder Diplodatos
 WARN [2020-10-30 18:17:30,887] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 18:17:30,907] ({main} Folder.java[addNote]:185) - Add note 2FQA9JFA8 to folder Diplodatos
 WARN [2020-10-30 18:17:30,908] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 18:17:30,924] ({main} Folder.java[addNote]:185) - Add note 2FPTJC7P4 to folder Diplodatos
 WARN [2020-10-30 18:17:30,925] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 18:17:30,940] ({main} Folder.java[addNote]:185) - Add note 2C2AUG798 to folder Zeppelin Tutorial
 WARN [2020-10-30 18:17:30,940] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 18:17:30,946] ({main} Folder.java[addNote]:185) - Add note 2C57UKYWR to folder Zeppelin Tutorial
 WARN [2020-10-30 18:17:30,947] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 18:17:30,984] ({main} Folder.java[addNote]:185) - Add note 2FP1YEJHN to folder Diplodatos
 WARN [2020-10-30 18:17:30,985] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 18:17:31,002] ({main} Folder.java[addNote]:185) - Add note 2BYEZ5EVK to folder Zeppelin Tutorial
 WARN [2020-10-30 18:17:31,003] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 18:17:31,032] ({main} Folder.java[addNote]:185) - Add note 2FNR8STJW to folder Diplodatos
 WARN [2020-10-30 18:17:31,033] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 18:17:31,044] ({main} Folder.java[addNote]:185) - Add note 2C35YU814 to folder Zeppelin Tutorial
 WARN [2020-10-30 18:17:31,044] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 18:17:31,044] ({main} Notebook.java[<init>]:127) - Notebook indexing started...
 INFO [2020-10-30 18:17:31,333] ({main} LuceneSearch.java[addIndexDocs]:305) - Indexing 12 notebooks took 288ms
 INFO [2020-10-30 18:17:31,333] ({main} Notebook.java[<init>]:129) - Notebook indexing finished: 12 indexed in 0s
 INFO [2020-10-30 18:17:31,336] ({main} Helium.java[loadConf]:103) - Add helium local registry /users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/helium
 INFO [2020-10-30 18:17:31,337] ({main} Helium.java[loadConf]:100) - Add helium online registry https://s3.amazonaws.com/helium-package/helium.json
 WARN [2020-10-30 18:17:31,344] ({main} Helium.java[loadConf]:111) - /users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/conf/helium.json does not exists
 INFO [2020-10-30 18:17:34,159] ({main} ContextHandler.java[doStart]:855) - Started o.e.j.w.WebAppContext@15761df8{zeppelin-web,/,file:///users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/webapps/webapp/,AVAILABLE}{/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/zeppelin-web-0.8.2.war}
 INFO [2020-10-30 18:17:34,213] ({main} AbstractConnector.java[doStart]:292) - Started ServerConnector@4c5228e7{HTTP/1.1,[http/1.1]}{127.0.0.1:9322}
 INFO [2020-10-30 18:17:34,214] ({main} Server.java[doStart]:407) - Started @12397ms
 INFO [2020-10-30 18:17:34,215] ({main} ZeppelinServer.java[main]:249) - Done, zeppelin server started
 WARN [2020-10-30 18:18:03,290] ({qtp89387388-80} SecurityRestApi.java[ticket]:88) - {"status":"OK","message":"","body":{"principal":"anonymous","ticket":"anonymous","roles":"[]"}}
 INFO [2020-10-30 18:18:03,482] ({qtp89387388-25} NotebookServer.java[onOpen]:151) - New connection from 127.0.0.1 : 49144
 WARN [2020-10-30 18:18:10,434] ({qtp89387388-69} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:18:10,435] ({qtp89387388-69} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:18:10,435] ({qtp89387388-69} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:18:10,436] ({qtp89387388-69} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:18:10,436] ({qtp89387388-69} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:18:10,436] ({qtp89387388-69} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:18:59,238] ({qtp89387388-69} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:18:59,238] ({qtp89387388-69} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:18:59,239] ({qtp89387388-69} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:18:59,239] ({qtp89387388-69} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:18:59,239] ({qtp89387388-69} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:18:59,239] ({qtp89387388-69} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 INFO [2020-10-30 18:18:59,239] ({qtp89387388-69} LocalConfigStorage.java[save]:53) - Save Interpreter Setting to /users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/conf/interpreter.json
 INFO [2020-10-30 18:18:59,296] ({qtp89387388-69} VFSNotebookRepo.java[save]:196) - Saving note:2FRXGF37P
 INFO [2020-10-30 18:18:59,303] ({qtp89387388-69} FolderView.java[onNoteNameChanged]:205) - Note name changed: 2FRXGF37P -> Diplodatos/Clase 04 - Ejemplo Dataframes y Tablas
 INFO [2020-10-30 18:18:59,303] ({qtp89387388-69} Folder.java[addNote]:185) - Add note 2FRXGF37P to folder Diplodatos
 INFO [2020-10-30 18:18:59,556] ({qtp89387388-69} VFSNotebookRepo.java[save]:196) - Saving note:2FRXGF37P
 INFO [2020-10-30 18:18:59,696] ({qtp89387388-69} VFSNotebookRepo.java[save]:196) - Saving note:2FRXGF37P
 WARN [2020-10-30 18:21:30,317] ({qtp89387388-82} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:21:30,318] ({qtp89387388-82} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:21:30,318] ({qtp89387388-82} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:21:30,319] ({qtp89387388-82} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:21:30,319] ({qtp89387388-82} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:21:30,319] ({qtp89387388-82} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:26:38,845] ({qtp89387388-66} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:26:38,847] ({qtp89387388-66} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:26:38,847] ({qtp89387388-66} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:26:38,847] ({qtp89387388-66} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:26:38,848] ({qtp89387388-66} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:26:38,848] ({qtp89387388-66} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:26:42,907] ({qtp89387388-82} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:26:42,908] ({qtp89387388-82} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:26:42,908] ({qtp89387388-82} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:26:42,909] ({qtp89387388-82} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:26:42,909] ({qtp89387388-82} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:26:42,909] ({qtp89387388-82} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:27:38,041] ({qtp89387388-80} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:27:38,042] ({qtp89387388-80} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:27:38,042] ({qtp89387388-80} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:27:38,042] ({qtp89387388-80} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:27:38,042] ({qtp89387388-80} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:27:38,042] ({qtp89387388-80} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 INFO [2020-10-30 18:27:38,043] ({qtp89387388-80} LocalConfigStorage.java[save]:53) - Save Interpreter Setting to /users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/conf/interpreter.json
 INFO [2020-10-30 18:27:38,048] ({qtp89387388-80} VFSNotebookRepo.java[save]:196) - Saving note:2FPKYNWDF
 INFO [2020-10-30 18:27:38,051] ({qtp89387388-80} FolderView.java[onNoteNameChanged]:205) - Note name changed: 2FPKYNWDF -> Diplodatos/Clase 06 - ML Pipelines
 INFO [2020-10-30 18:27:38,051] ({qtp89387388-80} Folder.java[addNote]:185) - Add note 2FPKYNWDF to folder Diplodatos
 INFO [2020-10-30 18:27:38,139] ({qtp89387388-80} VFSNotebookRepo.java[save]:196) - Saving note:2FPKYNWDF
 INFO [2020-10-30 18:27:38,209] ({qtp89387388-80} VFSNotebookRepo.java[save]:196) - Saving note:2FPKYNWDF
 INFO [2020-10-30 18:28:01,632] ({Thread-39} ZeppelinServer.java[run]:253) - Shutting down Zeppelin Server ... 
 INFO [2020-10-30 18:28:01,647] ({qtp89387388-21} NotebookServer.java[onClose]:372) - Closed connection to 127.0.0.1 : 49144. (1006) Disconnected
 INFO [2020-10-30 18:28:01,650] ({Thread-39} AbstractConnector.java[doStop]:341) - Stopped ServerConnector@4c5228e7{HTTP/1.1,[http/1.1]}{127.0.0.1:9322}
 INFO [2020-10-30 18:28:01,651] ({Thread-39} HouseKeeper.java[stopScavenging]:167) - node0 Stopped scavenging
 INFO [2020-10-30 18:28:03,716] ({Thread-39} ContextHandler.java[doStop]:1045) - Stopped o.e.j.w.WebAppContext@15761df8{zeppelin-web,/,null,UNAVAILABLE}{/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/zeppelin-web-0.8.2.war}
 INFO [2020-10-30 18:28:03,719] ({Thread-65} InterpreterSetting.java[close]:483) - Close InterpreterSetting: ignite
 INFO [2020-10-30 18:28:03,719] ({Thread-66} InterpreterSetting.java[close]:483) - Close InterpreterSetting: ignite
 INFO [2020-10-30 18:28:03,720] ({Thread-67} InterpreterSetting.java[close]:483) - Close InterpreterSetting: python
 INFO [2020-10-30 18:28:03,720] ({Thread-73} InterpreterSetting.java[close]:483) - Close InterpreterSetting: lens
 INFO [2020-10-30 18:28:03,720] ({Thread-70} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sap
 INFO [2020-10-30 18:28:03,721] ({Thread-71} InterpreterSetting.java[close]:483) - Close InterpreterSetting: jdbc
 INFO [2020-10-30 18:28:03,720] ({Thread-72} InterpreterSetting.java[close]:483) - Close InterpreterSetting: jdbc
 INFO [2020-10-30 18:28:03,720] ({Thread-69} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sap
 INFO [2020-10-30 18:28:03,720] ({Thread-68} InterpreterSetting.java[close]:483) - Close InterpreterSetting: python
 INFO [2020-10-30 18:28:03,723] ({Thread-87} InterpreterSetting.java[close]:483) - Close InterpreterSetting: neo4j
 INFO [2020-10-30 18:28:03,723] ({Thread-86} InterpreterSetting.java[close]:483) - Close InterpreterSetting: groovy
 INFO [2020-10-30 18:28:03,723] ({Thread-85} InterpreterSetting.java[close]:483) - Close InterpreterSetting: livy
 INFO [2020-10-30 18:28:03,726] ({Thread-95} InterpreterSetting.java[close]:483) - Close InterpreterSetting: md
 INFO [2020-10-30 18:28:03,723] ({Thread-84} InterpreterSetting.java[close]:483) - Close InterpreterSetting: angular
 INFO [2020-10-30 18:28:03,723] ({Thread-83} InterpreterSetting.java[close]:483) - Close InterpreterSetting: flink
 INFO [2020-10-30 18:28:03,722] ({Thread-82} InterpreterSetting.java[close]:483) - Close InterpreterSetting: pig
 INFO [2020-10-30 18:28:03,727] ({Thread-104} InterpreterSetting.java[close]:483) - Close InterpreterSetting: bigquery
 INFO [2020-10-30 18:28:03,722] ({Thread-77} InterpreterSetting.java[close]:483) - Close InterpreterSetting: lens
 INFO [2020-10-30 18:28:03,722] ({Thread-80} InterpreterSetting.java[close]:483) - Close InterpreterSetting: neo4j
 INFO [2020-10-30 18:28:03,722] ({Thread-79} InterpreterSetting.java[close]:483) - Close InterpreterSetting: groovy
 INFO [2020-10-30 18:28:03,721] ({Thread-78} InterpreterSetting.java[close]:483) - Close InterpreterSetting: livy
 INFO [2020-10-30 18:28:03,721] ({Thread-76} InterpreterSetting.java[close]:483) - Close InterpreterSetting: angular
 INFO [2020-10-30 18:28:03,721] ({Thread-75} InterpreterSetting.java[close]:483) - Close InterpreterSetting: flink
 INFO [2020-10-30 18:28:03,721] ({Thread-74} InterpreterSetting.java[close]:483) - Close InterpreterSetting: pig
 INFO [2020-10-30 18:28:03,728] ({Thread-106} InterpreterSetting.java[close]:483) - Close InterpreterSetting: kylin
 INFO [2020-10-30 18:28:03,728] ({Thread-105} InterpreterSetting.java[close]:483) - Close InterpreterSetting: hbase
 INFO [2020-10-30 18:28:03,727] ({Thread-103} InterpreterSetting.java[close]:483) - Close InterpreterSetting: alluxio
 INFO [2020-10-30 18:28:03,727] ({Thread-102} InterpreterSetting.java[close]:483) - Close InterpreterSetting: md
 INFO [2020-10-30 18:28:03,727] ({Thread-101} InterpreterSetting.java[close]:483) - Close InterpreterSetting: kylin
 INFO [2020-10-30 18:28:03,727] ({Thread-100} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sh
 INFO [2020-10-30 18:28:03,727] ({Thread-99} InterpreterSetting.java[close]:483) - Close InterpreterSetting: hbase
 INFO [2020-10-30 18:28:03,726] ({Thread-97} InterpreterSetting.java[close]:483) - Close InterpreterSetting: cassandra
 INFO [2020-10-30 18:28:03,726] ({Thread-98} InterpreterSetting.java[close]:483) - Close InterpreterSetting: bigquery
 INFO [2020-10-30 18:28:03,726] ({Thread-96} InterpreterSetting.java[close]:483) - Close InterpreterSetting: alluxio
 INFO [2020-10-30 18:28:03,726] ({Thread-94} InterpreterSetting.java[close]:483) - Close InterpreterSetting: spark
 INFO [2020-10-30 18:28:03,725] ({Thread-90} InterpreterSetting.java[close]:483) - Close InterpreterSetting: elasticsearch
 INFO [2020-10-30 18:28:03,725] ({Thread-93} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sh
 INFO [2020-10-30 18:28:03,725] ({Thread-92} InterpreterSetting.java[close]:483) - Close InterpreterSetting: cassandra
 INFO [2020-10-30 18:28:03,725] ({Thread-91} InterpreterSetting.java[close]:483) - Close InterpreterSetting: spark
 INFO [2020-10-30 18:28:03,725] ({Thread-81} InterpreterSetting.java[close]:483) - Close InterpreterSetting: file
 INFO [2020-10-30 18:28:03,724] ({Thread-89} InterpreterSetting.java[close]:483) - Close InterpreterSetting: elasticsearch
 INFO [2020-10-30 18:28:03,724] ({Thread-88} InterpreterSetting.java[close]:483) - Close InterpreterSetting: file
 INFO [2020-10-30 18:28:03,734] ({Thread-39} NotebookRepoSync.java[close]:428) - Closing all notebook storages
 INFO [2020-10-30 18:28:06,744] ({Thread-39} ZeppelinServer.java[run]:264) - Bye
 INFO [2020-10-30 18:30:05,551] ({main} ZeppelinConfiguration.java[create]:121) - Load configuration from file:/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/zeppelin-site.xml
 WARN [2020-10-30 18:30:05,609] ({main} ZeppelinConfiguration.java[create]:124) - Failed to load configuration from file:/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/zeppelin-site.xml proceeding with a default
org.apache.commons.configuration.ConfigurationException: Error parsing file:/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/zeppelin-site.xml
	at org.apache.commons.configuration.XMLConfiguration.load(XMLConfiguration.java:950)
	at org.apache.commons.configuration.XMLConfiguration.load(XMLConfiguration.java:908)
	at org.apache.commons.configuration.XMLConfiguration$XMLFileConfigurationDelegate.load(XMLConfiguration.java:1583)
	at org.apache.commons.configuration.AbstractFileConfiguration.load(AbstractFileConfiguration.java:324)
	at org.apache.commons.configuration.AbstractHierarchicalFileConfiguration.load(AbstractHierarchicalFileConfiguration.java:199)
	at org.apache.zeppelin.conf.ZeppelinConfiguration.<init>(ZeppelinConfiguration.java:52)
	at org.apache.zeppelin.conf.ZeppelinConfiguration.create(ZeppelinConfiguration.java:122)
	at org.apache.zeppelin.server.ZeppelinServer.main(ZeppelinServer.java:219)
Caused by: org.xml.sax.SAXParseException; systemId: file:/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/zeppelin-site.xml; lineNumber: 1; columnNumber: 1; Premature end of file.
	at com.sun.org.apache.xerces.internal.parsers.DOMParser.parse(DOMParser.java:257)
	at com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderImpl.parse(DocumentBuilderImpl.java:339)
	at org.apache.commons.configuration.XMLConfiguration.load(XMLConfiguration.java:942)
	... 7 more
 INFO [2020-10-30 18:30:05,635] ({main} ZeppelinConfiguration.java[create]:129) - Server Host: 127.0.0.1
 INFO [2020-10-30 18:30:05,635] ({main} ZeppelinConfiguration.java[create]:131) - Server Port: 9322
 INFO [2020-10-30 18:30:05,635] ({main} ZeppelinConfiguration.java[create]:135) - Context Path: /
 INFO [2020-10-30 18:30:05,637] ({main} ZeppelinConfiguration.java[create]:136) - Zeppelin Version: 0.8.2
 INFO [2020-10-30 18:30:05,659] ({main} Log.java[initialized]:193) - Logging initialized @478ms to org.eclipse.jetty.util.log.Slf4jLog
 WARN [2020-10-30 18:30:05,786] ({main} ServerConnector.java[setSoLingerTime]:458) - Ignoring deprecated socket close linger time
 INFO [2020-10-30 18:30:05,843] ({main} ZeppelinServer.java[setupWebAppContext]:413) - ZeppelinServer Webapp path: /users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/webapps
 INFO [2020-10-30 18:30:05,930] ({main} ZeppelinServer.java[main]:239) - Starting zeppelin server
 INFO [2020-10-30 18:30:05,931] ({main} Server.java[doStart]:370) - jetty-9.4.14.v20181114; built: 2018-11-14T21:20:31.478Z; git: c4550056e785fb5665914545889f21dc136ad9e6; jvm 1.8.0_152-release-1056-b12
 INFO [2020-10-30 18:30:11,203] ({main} StandardDescriptorProcessor.java[visitServlet]:283) - NO JSP Support for /, did not find org.eclipse.jetty.jsp.JettyJspServlet
 INFO [2020-10-30 18:30:11,222] ({main} DefaultSessionIdManager.java[doStart]:365) - DefaultSessionIdManager workerName=node0
 INFO [2020-10-30 18:30:11,222] ({main} DefaultSessionIdManager.java[doStart]:370) - No SessionScavenger set, using defaults
 INFO [2020-10-30 18:30:11,226] ({main} HouseKeeper.java[startScavenging]:149) - node0 Scavenging every 600000ms
 INFO [2020-10-30 18:30:11,623] ({main} SchedulerFactory.java[<init>]:59) - Scheduler Thread Pool Size: 100
 WARN [2020-10-30 18:30:11,639] ({main} ZeppelinConfiguration.java[getConfigFSDir]:527) - zeppelin.config.fs.dir is not specified, fall back to local conf directory zeppelin.conf.dir
 WARN [2020-10-30 18:30:11,640] ({main} ZeppelinConfiguration.java[getConfigFSDir]:527) - zeppelin.config.fs.dir is not specified, fall back to local conf directory zeppelin.conf.dir
 INFO [2020-10-30 18:30:11,747] ({main} InterpreterSettingManager.java[<init>]:165) - Using RecoveryStorage: org.apache.zeppelin.interpreter.recovery.NullRecoveryStorage
 INFO [2020-10-30 18:30:11,748] ({main} InterpreterSettingManager.java[<init>]:169) - Using LifecycleManager: org.apache.zeppelin.interpreter.lifecycle.NullLifecycleManager
 INFO [2020-10-30 18:30:11,781] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: cassandra
 WARN [2020-10-30 18:30:11,786] ({main} InterpreterSettingManager.java[init]:331) - No interpreter-setting.json found in /users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/${interpreter.name}
 INFO [2020-10-30 18:30:11,796] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: angular
 INFO [2020-10-30 18:30:11,799] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: md
 INFO [2020-10-30 18:30:11,802] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: alluxio
 INFO [2020-10-30 18:30:11,805] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: groovy
 INFO [2020-10-30 18:30:11,807] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: pig
 INFO [2020-10-30 18:30:11,810] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: file
 INFO [2020-10-30 18:30:11,813] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: elasticsearch
 INFO [2020-10-30 18:30:11,816] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: lens
 INFO [2020-10-30 18:30:11,818] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: kylin
 INFO [2020-10-30 18:30:11,821] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: sap
 INFO [2020-10-30 18:30:11,824] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: ignite
 INFO [2020-10-30 18:30:11,829] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: neo4j
 INFO [2020-10-30 18:30:11,832] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: python
 INFO [2020-10-30 18:30:11,834] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: bigquery
 WARN [2020-10-30 18:30:11,938] ({main} InterpreterSettingManager.java[init]:331) - No interpreter-setting.json found in /users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/scio
 INFO [2020-10-30 18:30:11,941] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: spark
 INFO [2020-10-30 18:30:11,944] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: livy
 WARN [2020-10-30 18:30:11,947] ({main} InterpreterSettingManager.java[init]:331) - No interpreter-setting.json found in /users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/lib
 INFO [2020-10-30 18:30:11,949] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: sh
 INFO [2020-10-30 18:30:11,951] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: flink
 INFO [2020-10-30 18:30:11,952] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: hbase
 INFO [2020-10-30 18:30:11,955] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: jdbc
 INFO [2020-10-30 18:30:11,955] ({main} LocalConfigStorage.java[loadInterpreterSettings]:63) - Load Interpreter Setting from file: /users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/conf/interpreter.json
 INFO [2020-10-30 18:30:12,006] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting ignite from interpreter.json
 INFO [2020-10-30 18:30:12,007] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting python from interpreter.json
 INFO [2020-10-30 18:30:12,008] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting sap from interpreter.json
 INFO [2020-10-30 18:30:12,009] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting jdbc from interpreter.json
 INFO [2020-10-30 18:30:12,010] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting lens from interpreter.json
 INFO [2020-10-30 18:30:12,011] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting pig from interpreter.json
 INFO [2020-10-30 18:30:12,011] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting flink from interpreter.json
 INFO [2020-10-30 18:30:12,012] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting angular from interpreter.json
 INFO [2020-10-30 18:30:12,013] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting livy from interpreter.json
 INFO [2020-10-30 18:30:12,014] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting groovy from interpreter.json
 INFO [2020-10-30 18:30:12,014] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting neo4j from interpreter.json
 INFO [2020-10-30 18:30:12,015] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting file from interpreter.json
 INFO [2020-10-30 18:30:12,015] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting elasticsearch from interpreter.json
 INFO [2020-10-30 18:30:12,016] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting spark from interpreter.json
 INFO [2020-10-30 18:30:12,018] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting cassandra from interpreter.json
 INFO [2020-10-30 18:30:12,018] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting sh from interpreter.json
 INFO [2020-10-30 18:30:12,018] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting md from interpreter.json
 INFO [2020-10-30 18:30:12,019] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting alluxio from interpreter.json
 INFO [2020-10-30 18:30:12,019] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting bigquery from interpreter.json
 INFO [2020-10-30 18:30:12,019] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting hbase from interpreter.json
 INFO [2020-10-30 18:30:12,020] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting kylin from interpreter.json
 INFO [2020-10-30 18:30:12,029] ({main} LocalConfigStorage.java[save]:53) - Save Interpreter Setting to /users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/conf/interpreter.json
 INFO [2020-10-30 18:30:12,202] ({main} VfsLog.java[info]:138) - Using "/tmp/vfs_cache" as temporary files store.
 INFO [2020-10-30 18:30:12,258] ({main} GitNotebookRepo.java[<init>]:64) - Opening a git repo at '/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/notebook'
 INFO [2020-10-30 18:30:12,333] ({main} NotebookRepoSync.java[<init>]:77) - Instantiate NotebookRepo: org.apache.zeppelin.notebook.repo.GitNotebookRepo
 WARN [2020-10-30 18:30:12,455] ({main} NotebookAuthorization.java[getInstance]:86) - Notebook authorization module was called without initialization, initializing with default configuration
 INFO [2020-10-30 18:30:12,456] ({main} LocalConfigStorage.java[loadNotebookAuthorization]:80) - Load notebook authorization from file: /users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/conf/notebook-authorization.json
 INFO [2020-10-30 18:30:12,458] ({main} Credentials.java[loadFromFile]:121) - /users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/conf/credentials.json
 INFO [2020-10-30 18:30:12,495] ({main} StdSchedulerFactory.java[instantiate]:1184) - Using default implementation for ThreadExecutor
 INFO [2020-10-30 18:30:12,498] ({main} SimpleThreadPool.java[initialize]:268) - Job execution threads will use class loader of thread: main
 INFO [2020-10-30 18:30:12,511] ({main} SchedulerSignalerImpl.java[<init>]:61) - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
 INFO [2020-10-30 18:30:12,512] ({main} QuartzScheduler.java[<init>]:240) - Quartz Scheduler v.2.2.1 created.
 INFO [2020-10-30 18:30:12,513] ({main} RAMJobStore.java[initialize]:155) - RAMJobStore initialized.
 INFO [2020-10-30 18:30:12,514] ({main} QuartzScheduler.java[initialize]:305) - Scheduler meta-data: Quartz Scheduler (v2.2.1) 'DefaultQuartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

 INFO [2020-10-30 18:30:12,514] ({main} StdSchedulerFactory.java[instantiate]:1339) - Quartz scheduler 'DefaultQuartzScheduler' initialized from default resource file in Quartz package: 'quartz.properties'
 INFO [2020-10-30 18:30:12,514] ({main} StdSchedulerFactory.java[instantiate]:1343) - Quartz scheduler version: 2.2.1
 INFO [2020-10-30 18:30:12,515] ({main} QuartzScheduler.java[start]:575) - Scheduler DefaultQuartzScheduler_$_NON_CLUSTERED started.
 INFO [2020-10-30 18:30:12,990] ({main} FolderView.java[createFolder]:107) - Create folder Zeppelin Tutorial
 INFO [2020-10-30 18:30:12,990] ({main} FolderView.java[createFolder]:107) - Create folder /
 INFO [2020-10-30 18:30:12,991] ({main} Folder.java[setParent]:169) - Set parent of / to /
 INFO [2020-10-30 18:30:12,991] ({main} Folder.java[setParent]:169) - Set parent of Zeppelin Tutorial to /
 INFO [2020-10-30 18:30:12,991] ({main} Folder.java[addNote]:185) - Add note 2A94M5J1Z to folder Zeppelin Tutorial
 WARN [2020-10-30 18:30:12,992] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 18:30:13,006] ({main} Folder.java[addNote]:185) - Add note 2BWJFTXKJ to folder Zeppelin Tutorial
 WARN [2020-10-30 18:30:13,007] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 18:30:13,021] ({main} FolderView.java[createFolder]:107) - Create folder Diplodatos
 INFO [2020-10-30 18:30:13,021] ({main} Folder.java[setParent]:169) - Set parent of Diplodatos to /
 INFO [2020-10-30 18:30:13,021] ({main} Folder.java[addNote]:185) - Add note 2FMXBM6HK to folder Diplodatos
 WARN [2020-10-30 18:30:13,022] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 18:30:13,038] ({main} Folder.java[addNote]:185) - Add note 2FP83VA8P to folder Diplodatos
 WARN [2020-10-30 18:30:13,039] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 18:30:13,050] ({main} Folder.java[addNote]:185) - Add note 2FQA9JFA8 to folder Diplodatos
 WARN [2020-10-30 18:30:13,051] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 18:30:13,065] ({main} Folder.java[addNote]:185) - Add note 2FRXGF37P to folder Diplodatos
 WARN [2020-10-30 18:30:13,066] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 18:30:13,074] ({main} Folder.java[addNote]:185) - Add note 2FPTJC7P4 to folder Diplodatos
 WARN [2020-10-30 18:30:13,074] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 18:30:13,080] ({main} Folder.java[addNote]:185) - Add note 2C2AUG798 to folder Zeppelin Tutorial
 WARN [2020-10-30 18:30:13,081] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 18:30:13,084] ({main} Folder.java[addNote]:185) - Add note 2C57UKYWR to folder Zeppelin Tutorial
 WARN [2020-10-30 18:30:13,084] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 18:30:13,104] ({main} Folder.java[addNote]:185) - Add note 2FP1YEJHN to folder Diplodatos
 WARN [2020-10-30 18:30:13,105] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 18:30:13,114] ({main} Folder.java[addNote]:185) - Add note 2BYEZ5EVK to folder Zeppelin Tutorial
 WARN [2020-10-30 18:30:13,115] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 18:30:13,128] ({main} Folder.java[addNote]:185) - Add note 2FNR8STJW to folder Diplodatos
 WARN [2020-10-30 18:30:13,129] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
ERROR [2020-10-30 18:30:13,129] ({main} Notebook.java[loadNoteFromRepo]:508) - Failed to load 2EUZZ1P8Y
java.io.IOException: file:///users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/notebook/2EUZZ1P8Y is not a directory
	at org.apache.zeppelin.notebook.repo.VFSNotebookRepo.getNote(VFSNotebookRepo.java:151)
	at org.apache.zeppelin.notebook.repo.VFSNotebookRepo.get(VFSNotebookRepo.java:177)
	at org.apache.zeppelin.notebook.repo.NotebookRepoSync.get(NotebookRepoSync.java:165)
	at org.apache.zeppelin.notebook.Notebook.loadNoteFromRepo(Notebook.java:506)
	at org.apache.zeppelin.notebook.Notebook.loadAllNotes(Notebook.java:590)
	at org.apache.zeppelin.notebook.Notebook.<init>(Notebook.java:124)
	at org.apache.zeppelin.server.ZeppelinServer.<init>(ZeppelinServer.java:168)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.glassfish.hk2.utilities.reflection.ReflectionHelper.makeMe(ReflectionHelper.java:1375)
	at org.jvnet.hk2.internal.Utilities.justCreate(Utilities.java:1083)
	at org.jvnet.hk2.internal.ServiceLocatorImpl.create(ServiceLocatorImpl.java:978)
	at org.jvnet.hk2.internal.ServiceLocatorImpl.createAndInitialize(ServiceLocatorImpl.java:1082)
	at org.jvnet.hk2.internal.ServiceLocatorImpl.createAndInitialize(ServiceLocatorImpl.java:1074)
	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.createAndInitialize(AbstractHk2InjectionManager.java:213)
	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.createAndInitialize(ImmediateHk2InjectionManager.java:54)
	at org.glassfish.jersey.server.ApplicationConfigurator.createApplication(ApplicationConfigurator.java:138)
	at org.glassfish.jersey.server.ApplicationConfigurator.init(ApplicationConfigurator.java:96)
	at org.glassfish.jersey.server.ApplicationHandler.lambda$initialize$0(ApplicationHandler.java:313)
	at java.util.Arrays$ArrayList.forEach(Arrays.java:3880)
	at org.glassfish.jersey.server.ApplicationHandler.initialize(ApplicationHandler.java:313)
	at org.glassfish.jersey.server.ApplicationHandler.<init>(ApplicationHandler.java:282)
	at org.glassfish.jersey.servlet.WebComponent.<init>(WebComponent.java:335)
	at org.glassfish.jersey.servlet.ServletContainer.init(ServletContainer.java:178)
	at org.glassfish.jersey.servlet.ServletContainer.init(ServletContainer.java:370)
	at javax.servlet.GenericServlet.init(GenericServlet.java:244)
	at org.eclipse.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:672)
	at org.eclipse.jetty.servlet.ServletHolder.initialize(ServletHolder.java:429)
	at org.eclipse.jetty.servlet.ServletHandler.lambda$initialize$0(ServletHandler.java:750)
	at java.util.stream.SortedOps$SizedRefSortingSink.end(SortedOps.java:352)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471)
	at java.util.stream.StreamSpliterators$WrappingSpliterator.forEachRemaining(StreamSpliterators.java:312)
	at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:743)
	at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742)
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580)
	at org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:744)
	at org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:368)
	at org.eclipse.jetty.webapp.WebAppContext.startWebapp(WebAppContext.java:1497)
	at org.eclipse.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1459)
	at org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:852)
	at org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:278)
	at org.eclipse.jetty.webapp.WebAppContext.doStart(WebAppContext.java:545)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:138)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)
	at org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:113)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.doStart(ContextHandlerCollection.java:168)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:138)
	at org.eclipse.jetty.server.Server.start(Server.java:415)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:108)
	at org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:113)
	at org.eclipse.jetty.server.Server.doStart(Server.java:382)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.zeppelin.server.ZeppelinServer.main(ZeppelinServer.java:241)
 INFO [2020-10-30 18:30:13,136] ({main} Folder.java[addNote]:185) - Add note 2C35YU814 to folder Zeppelin Tutorial
 WARN [2020-10-30 18:30:13,137] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 18:30:13,137] ({main} Notebook.java[<init>]:127) - Notebook indexing started...
 INFO [2020-10-30 18:30:13,394] ({main} LuceneSearch.java[addIndexDocs]:305) - Indexing 13 notebooks took 256ms
 INFO [2020-10-30 18:30:13,395] ({main} Notebook.java[<init>]:129) - Notebook indexing finished: 13 indexed in 0s
 INFO [2020-10-30 18:30:13,397] ({main} Helium.java[loadConf]:103) - Add helium local registry /users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/helium
 INFO [2020-10-30 18:30:13,398] ({main} Helium.java[loadConf]:100) - Add helium online registry https://s3.amazonaws.com/helium-package/helium.json
 WARN [2020-10-30 18:30:13,403] ({main} Helium.java[loadConf]:111) - /users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/conf/helium.json does not exists
 INFO [2020-10-30 18:30:15,909] ({main} ContextHandler.java[doStart]:855) - Started o.e.j.w.WebAppContext@15761df8{zeppelin-web,/,file:///users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/webapps/webapp/,AVAILABLE}{/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/zeppelin-web-0.8.2.war}
 INFO [2020-10-30 18:30:15,929] ({main} AbstractConnector.java[doStart]:292) - Started ServerConnector@3ed34ef5{HTTP/1.1,[http/1.1]}{127.0.0.1:9322}
 INFO [2020-10-30 18:30:15,930] ({main} Server.java[doStart]:407) - Started @10752ms
 INFO [2020-10-30 18:30:15,930] ({main} ZeppelinServer.java[main]:249) - Done, zeppelin server started
 WARN [2020-10-30 18:30:22,605] ({qtp89387388-69} SecurityRestApi.java[ticket]:88) - {"status":"OK","message":"","body":{"principal":"anonymous","ticket":"anonymous","roles":"[]"}}
 INFO [2020-10-30 18:30:22,796] ({qtp89387388-21} NotebookServer.java[onOpen]:151) - New connection from 127.0.0.1 : 49510
 INFO [2020-10-30 18:30:28,637] ({qtp89387388-73} NotebookServer.java[onClose]:372) - Closed connection to 127.0.0.1 : 49510. (1001) null
 WARN [2020-10-30 18:30:29,122] ({qtp89387388-71} SecurityRestApi.java[ticket]:88) - {"status":"OK","message":"","body":{"principal":"anonymous","ticket":"anonymous","roles":"[]"}}
 INFO [2020-10-30 18:30:29,236] ({qtp89387388-23} NotebookServer.java[onOpen]:151) - New connection from 127.0.0.1 : 49518
 WARN [2020-10-30 18:30:42,340] ({qtp89387388-73} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:30:42,341] ({qtp89387388-73} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:30:42,341] ({qtp89387388-73} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:30:42,341] ({qtp89387388-73} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:30:42,342] ({qtp89387388-73} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:30:42,342] ({qtp89387388-73} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:31:19,312] ({qtp89387388-74} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:31:19,313] ({qtp89387388-74} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:31:19,313] ({qtp89387388-74} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:31:19,313] ({qtp89387388-74} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:31:19,313] ({qtp89387388-74} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:31:19,313] ({qtp89387388-74} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 INFO [2020-10-30 18:31:19,314] ({qtp89387388-74} LocalConfigStorage.java[save]:53) - Save Interpreter Setting to /users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/conf/interpreter.json
 INFO [2020-10-30 18:31:19,360] ({qtp89387388-74} VFSNotebookRepo.java[save]:196) - Saving note:2FNG3ZFM5
 INFO [2020-10-30 18:31:19,366] ({qtp89387388-74} FolderView.java[onNoteNameChanged]:205) - Note name changed: 2FNG3ZFM5 -> Diplodatos/Clase 06 - ML Pipelines
 INFO [2020-10-30 18:31:19,367] ({qtp89387388-74} Folder.java[addNote]:185) - Add note 2FNG3ZFM5 to folder Diplodatos
 INFO [2020-10-30 18:31:19,515] ({qtp89387388-74} VFSNotebookRepo.java[save]:196) - Saving note:2FNG3ZFM5
 INFO [2020-10-30 18:31:19,609] ({qtp89387388-74} VFSNotebookRepo.java[save]:196) - Saving note:2FNG3ZFM5
 INFO [2020-10-30 18:31:23,316] ({qtp89387388-71} NotebookServer.java[sendNote]:828) - New operation from 127.0.0.1 : 49518 : anonymous : GET_NOTE : 2FNG3ZFM5
 WARN [2020-10-30 18:31:23,388] ({qtp89387388-71} GitNotebookRepo.java[revisionHistory]:158) - No Head found for 2FNG3ZFM5, No HEAD exists and no explicit starting revision was specified
 WARN [2020-10-30 18:31:23,391] ({qtp89387388-71} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:31:23,391] ({qtp89387388-71} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:31:23,391] ({qtp89387388-71} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:31:23,391] ({qtp89387388-71} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:31:23,391] ({qtp89387388-71} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:31:23,392] ({qtp89387388-71} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 INFO [2020-10-30 18:31:23,540] ({qtp89387388-22} InterpreterSetting.java[getOrCreateInterpreterGroup]:419) - Create InterpreterGroup with groupId: spark:shared_process for user: anonymous and note: 2FNG3ZFM5
 INFO [2020-10-30 18:31:23,540] ({qtp89387388-75} InterpreterSetting.java[getOrCreateInterpreterGroup]:419) - Create InterpreterGroup with groupId: md:shared_process for user: anonymous and note: 2FNG3ZFM5
 INFO [2020-10-30 18:31:23,545] ({qtp89387388-22} InterpreterSetting.java[createInterpreters]:689) - Interpreter org.apache.zeppelin.spark.SparkInterpreter created for user: anonymous, sessionId: shared_session
 INFO [2020-10-30 18:31:23,545] ({qtp89387388-75} InterpreterSetting.java[createInterpreters]:689) - Interpreter org.apache.zeppelin.markdown.Markdown created for user: anonymous, sessionId: shared_session
 INFO [2020-10-30 18:31:23,545] ({qtp89387388-22} InterpreterSetting.java[createInterpreters]:689) - Interpreter org.apache.zeppelin.spark.SparkSqlInterpreter created for user: anonymous, sessionId: shared_session
 INFO [2020-10-30 18:31:23,546] ({qtp89387388-22} InterpreterSetting.java[createInterpreters]:689) - Interpreter org.apache.zeppelin.spark.DepInterpreter created for user: anonymous, sessionId: shared_session
 INFO [2020-10-30 18:31:23,546] ({qtp89387388-22} InterpreterSetting.java[createInterpreters]:689) - Interpreter org.apache.zeppelin.spark.PySparkInterpreter created for user: anonymous, sessionId: shared_session
 INFO [2020-10-30 18:31:23,546] ({qtp89387388-22} InterpreterSetting.java[createInterpreters]:689) - Interpreter org.apache.zeppelin.spark.IPySparkInterpreter created for user: anonymous, sessionId: shared_session
 INFO [2020-10-30 18:31:23,546] ({qtp89387388-75} ManagedInterpreterGroup.java[getOrCreateSession]:158) - Create Session: shared_session in InterpreterGroup: md:shared_process for user: anonymous
 INFO [2020-10-30 18:31:23,546] ({qtp89387388-22} InterpreterSetting.java[createInterpreters]:689) - Interpreter org.apache.zeppelin.spark.SparkRInterpreter created for user: anonymous, sessionId: shared_session
 INFO [2020-10-30 18:31:23,547] ({qtp89387388-22} ManagedInterpreterGroup.java[getOrCreateSession]:158) - Create Session: shared_session in InterpreterGroup: spark:shared_process for user: anonymous
 INFO [2020-10-30 18:31:32,073] ({qtp89387388-24} VFSNotebookRepo.java[save]:196) - Saving note:2FNG3ZFM5
 INFO [2020-10-30 18:31:32,078] ({qtp89387388-24} NotebookServer.java[broadcastNewParagraph]:688) - Broadcasting paragraph on run call instead of note.
 INFO [2020-10-30 18:31:35,448] ({qtp89387388-24} VFSNotebookRepo.java[save]:196) - Saving note:2FNG3ZFM5
 INFO [2020-10-30 18:31:35,452] ({qtp89387388-24} NotebookServer.java[broadcastNewParagraph]:688) - Broadcasting paragraph on run call instead of note.
 INFO [2020-10-30 18:31:40,448] ({qtp89387388-20} VFSNotebookRepo.java[save]:196) - Saving note:2FNG3ZFM5
 INFO [2020-10-30 18:31:43,677] ({qtp89387388-24} VFSNotebookRepo.java[save]:196) - Saving note:2FNG3ZFM5
 INFO [2020-10-30 18:32:18,411] ({qtp89387388-24} NotebookServer.java[onClose]:372) - Closed connection to 127.0.0.1 : 49518. (1001) null
 INFO [2020-10-30 18:32:22,652] ({qtp89387388-69} NotebookServer.java[onOpen]:151) - New connection from 127.0.0.1 : 49574
 INFO [2020-10-30 18:32:22,769] ({qtp89387388-22} NotebookServer.java[sendNote]:828) - New operation from 127.0.0.1 : 49574 : anonymous : GET_NOTE : 2FNG3ZFM5
 WARN [2020-10-30 18:32:22,776] ({qtp89387388-22} GitNotebookRepo.java[revisionHistory]:158) - No Head found for 2FNG3ZFM5, No HEAD exists and no explicit starting revision was specified
 WARN [2020-10-30 18:32:22,877] ({qtp89387388-69} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:32:22,878] ({qtp89387388-69} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:32:22,878] ({qtp89387388-69} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:32:22,879] ({qtp89387388-69} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:32:22,879] ({qtp89387388-69} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:32:22,879] ({qtp89387388-69} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:33:33,232] ({qtp89387388-74} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:33:33,233] ({qtp89387388-74} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:33:33,233] ({qtp89387388-74} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:33:33,234] ({qtp89387388-74} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:33:33,234] ({qtp89387388-74} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:33:33,234] ({qtp89387388-74} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 INFO [2020-10-30 18:36:51,257] ({qtp89387388-74} NotebookServer.java[sendNote]:828) - New operation from 127.0.0.1 : 49574 : anonymous : GET_NOTE : 2FNG3ZFM5
 WARN [2020-10-30 18:36:51,265] ({qtp89387388-74} GitNotebookRepo.java[revisionHistory]:158) - No Head found for 2FNG3ZFM5, No HEAD exists and no explicit starting revision was specified
 WARN [2020-10-30 18:36:51,309] ({qtp89387388-81} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:36:51,309] ({qtp89387388-81} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:36:51,310] ({qtp89387388-81} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:36:51,310] ({qtp89387388-81} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:36:51,310] ({qtp89387388-81} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:36:51,311] ({qtp89387388-81} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 INFO [2020-10-30 18:39:11,001] ({qtp89387388-81} NotebookServer.java[onClose]:372) - Closed connection to 127.0.0.1 : 49574. (1001) null
 WARN [2020-10-30 18:39:11,400] ({qtp89387388-22} SecurityRestApi.java[ticket]:88) - {"status":"OK","message":"","body":{"principal":"anonymous","ticket":"anonymous","roles":"[]"}}
 INFO [2020-10-30 18:39:11,504] ({qtp89387388-75} NotebookServer.java[onOpen]:151) - New connection from 127.0.0.1 : 49810
 INFO [2020-10-30 18:39:11,598] ({qtp89387388-81} NotebookServer.java[sendNote]:828) - New operation from 127.0.0.1 : 49810 : anonymous : GET_NOTE : 2FNG3ZFM5
 WARN [2020-10-30 18:39:11,606] ({qtp89387388-81} GitNotebookRepo.java[revisionHistory]:158) - No Head found for 2FNG3ZFM5, No HEAD exists and no explicit starting revision was specified
 WARN [2020-10-30 18:39:11,688] ({qtp89387388-19} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:39:11,688] ({qtp89387388-19} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:39:11,689] ({qtp89387388-19} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:39:11,689] ({qtp89387388-19} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:39:11,689] ({qtp89387388-19} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 18:39:11,689] ({qtp89387388-19} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 INFO [2020-10-30 18:39:37,077] ({qtp89387388-73} NotebookServer.java[sendNote]:828) - New operation from 127.0.0.1 : 49810 : anonymous : GET_NOTE : 2FQ14U3Q7
 WARN [2020-10-30 18:39:37,080] ({qtp89387388-73} GitNotebookRepo.java[revisionHistory]:158) - No Head found for 2FQ14U3Q7, No HEAD exists and no explicit starting revision was specified
 WARN [2020-10-30 19:49:37,794] ({qtp89387388-157} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 19:49:37,795] ({qtp89387388-157} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 19:49:37,795] ({qtp89387388-157} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 19:49:37,795] ({qtp89387388-157} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 19:49:37,795] ({qtp89387388-157} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 19:49:37,796] ({qtp89387388-157} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 INFO [2020-10-30 19:49:44,473] ({qtp89387388-160} NotebookServer.java[sendNote]:828) - New operation from 127.0.0.1 : 49810 : anonymous : GET_NOTE : 2FNG3ZFM5
 WARN [2020-10-30 19:49:44,479] ({qtp89387388-160} GitNotebookRepo.java[revisionHistory]:158) - No Head found for 2FNG3ZFM5, No HEAD exists and no explicit starting revision was specified
 WARN [2020-10-30 19:49:44,518] ({qtp89387388-159} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 19:49:44,518] ({qtp89387388-159} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 19:49:44,518] ({qtp89387388-159} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 19:49:44,518] ({qtp89387388-159} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 19:49:44,519] ({qtp89387388-159} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 19:49:44,519] ({qtp89387388-159} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 INFO [2020-10-30 19:54:19,573] ({Thread-39} ZeppelinServer.java[run]:253) - Shutting down Zeppelin Server ... 
 INFO [2020-10-30 19:54:19,583] ({qtp89387388-164} NotebookServer.java[onClose]:372) - Closed connection to 127.0.0.1 : 49810. (1006) Disconnected
 INFO [2020-10-30 19:54:19,585] ({Thread-39} AbstractConnector.java[doStop]:341) - Stopped ServerConnector@3ed34ef5{HTTP/1.1,[http/1.1]}{127.0.0.1:9322}
 INFO [2020-10-30 19:54:19,586] ({Thread-39} HouseKeeper.java[stopScavenging]:167) - node0 Stopped scavenging
 INFO [2020-10-30 19:54:21,504] ({Thread-39} ContextHandler.java[doStop]:1045) - Stopped o.e.j.w.WebAppContext@15761df8{zeppelin-web,/,null,UNAVAILABLE}{/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/zeppelin-web-0.8.2.war}
 INFO [2020-10-30 19:54:21,506] ({Thread-136} InterpreterSetting.java[close]:483) - Close InterpreterSetting: ignite
 INFO [2020-10-30 19:54:21,506] ({Thread-135} InterpreterSetting.java[close]:483) - Close InterpreterSetting: ignite
 INFO [2020-10-30 19:54:21,507] ({Thread-138} InterpreterSetting.java[close]:483) - Close InterpreterSetting: python
 INFO [2020-10-30 19:54:21,506] ({Thread-137} InterpreterSetting.java[close]:483) - Close InterpreterSetting: python
 INFO [2020-10-30 19:54:21,508] ({Thread-147} InterpreterSetting.java[close]:483) - Close InterpreterSetting: lens
 INFO [2020-10-30 19:54:21,508] ({Thread-145} InterpreterSetting.java[close]:483) - Close InterpreterSetting: flink
 INFO [2020-10-30 19:54:21,508] ({Thread-143} InterpreterSetting.java[close]:483) - Close InterpreterSetting: jdbc
 INFO [2020-10-30 19:54:21,508] ({Thread-144} InterpreterSetting.java[close]:483) - Close InterpreterSetting: pig
 INFO [2020-10-30 19:54:21,507] ({Thread-140} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sap
 INFO [2020-10-30 19:54:21,507] ({Thread-142} InterpreterSetting.java[close]:483) - Close InterpreterSetting: lens
 INFO [2020-10-30 19:54:21,507] ({Thread-139} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sap
 INFO [2020-10-30 19:54:21,509] ({Thread-157} InterpreterSetting.java[close]:483) - Close InterpreterSetting: neo4j
 INFO [2020-10-30 19:54:21,507] ({Thread-141} InterpreterSetting.java[close]:483) - Close InterpreterSetting: jdbc
 INFO [2020-10-30 19:54:21,510] ({Thread-158} InterpreterSetting.java[close]:483) - Close InterpreterSetting: file
 INFO [2020-10-30 19:54:21,510] ({Thread-156} InterpreterSetting.java[close]:483) - Close InterpreterSetting: file
 INFO [2020-10-30 19:54:21,511] ({Thread-162} InterpreterSetting.java[close]:483) - Close InterpreterSetting: spark
 INFO [2020-10-30 19:54:21,509] ({Thread-155} InterpreterSetting.java[close]:483) - Close InterpreterSetting: groovy
 INFO [2020-10-30 19:54:21,509] ({Thread-154} InterpreterSetting.java[close]:483) - Close InterpreterSetting: neo4j
 INFO [2020-10-30 19:54:21,509] ({Thread-153} InterpreterSetting.java[close]:483) - Close InterpreterSetting: livy
 INFO [2020-10-30 19:54:21,508] ({Thread-152} InterpreterSetting.java[close]:483) - Close InterpreterSetting: groovy
 INFO [2020-10-30 19:54:21,508] ({Thread-149} InterpreterSetting.java[close]:483) - Close InterpreterSetting: livy
 INFO [2020-10-30 19:54:21,508] ({Thread-151} InterpreterSetting.java[close]:483) - Close InterpreterSetting: angular
 INFO [2020-10-30 19:54:21,508] ({Thread-150} InterpreterSetting.java[close]:483) - Close InterpreterSetting: flink
 INFO [2020-10-30 19:54:21,508] ({Thread-148} InterpreterSetting.java[close]:483) - Close InterpreterSetting: pig
 INFO [2020-10-30 19:54:21,508] ({Thread-146} InterpreterSetting.java[close]:483) - Close InterpreterSetting: angular
 INFO [2020-10-30 19:54:21,514] ({Thread-174} InterpreterSetting.java[close]:483) - Close InterpreterSetting: bigquery
 INFO [2020-10-30 19:54:21,514] ({Thread-176} InterpreterSetting.java[close]:483) - Close InterpreterSetting: kylin
 INFO [2020-10-30 19:54:21,514] ({Thread-175} InterpreterSetting.java[close]:483) - Close InterpreterSetting: hbase
 INFO [2020-10-30 19:54:21,513] ({Thread-171} InterpreterSetting.java[close]:483) - Close InterpreterSetting: hbase
 INFO [2020-10-30 19:54:21,514] ({Thread-172} InterpreterSetting.java[close]:483) - Close InterpreterSetting: kylin
 INFO [2020-10-30 19:54:21,513] ({Thread-173} InterpreterSetting.java[close]:483) - Close InterpreterSetting: alluxio
 INFO [2020-10-30 19:54:21,513] ({Thread-168} InterpreterSetting.java[close]:483) - Close InterpreterSetting: md
 INFO [2020-10-30 19:54:21,516] ({Thread-168} ManagedInterpreterGroup.java[close]:89) - Close InterpreterGroup: md:shared_process
 INFO [2020-10-30 19:54:21,513] ({Thread-170} InterpreterSetting.java[close]:483) - Close InterpreterSetting: bigquery
 INFO [2020-10-30 19:54:21,512] ({Thread-169} InterpreterSetting.java[close]:483) - Close InterpreterSetting: alluxio
 INFO [2020-10-30 19:54:21,512] ({Thread-164} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sh
 INFO [2020-10-30 19:54:21,512] ({Thread-166} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sh
 INFO [2020-10-30 19:54:21,512] ({Thread-165} InterpreterSetting.java[close]:483) - Close InterpreterSetting: cassandra
 INFO [2020-10-30 19:54:21,512] ({Thread-167} InterpreterSetting.java[close]:483) - Close InterpreterSetting: md
 INFO [2020-10-30 19:54:21,512] ({Thread-162} ManagedInterpreterGroup.java[close]:89) - Close InterpreterGroup: spark:shared_process
 INFO [2020-10-30 19:54:21,518] ({Thread-162} ManagedInterpreterGroup.java[close]:100) - Close Session: shared_session for interpreter setting: spark
 INFO [2020-10-30 19:54:21,511] ({Thread-163} InterpreterSetting.java[close]:483) - Close InterpreterSetting: cassandra
 INFO [2020-10-30 19:54:21,511] ({Thread-161} InterpreterSetting.java[close]:483) - Close InterpreterSetting: spark
 INFO [2020-10-30 19:54:21,511] ({Thread-159} InterpreterSetting.java[close]:483) - Close InterpreterSetting: elasticsearch
 INFO [2020-10-30 19:54:21,511] ({Thread-160} InterpreterSetting.java[close]:483) - Close InterpreterSetting: elasticsearch
 INFO [2020-10-30 19:54:21,516] ({Thread-168} ManagedInterpreterGroup.java[close]:100) - Close Session: shared_session for interpreter setting: md
 WARN [2020-10-30 19:54:21,525] ({Thread-168} RemoteInterpreter.java[close]:199) - close is called when RemoterInterpreter is not opened for org.apache.zeppelin.markdown.Markdown
 WARN [2020-10-30 19:54:21,526] ({Thread-162} RemoteInterpreter.java[close]:199) - close is called when RemoterInterpreter is not opened for org.apache.zeppelin.spark.SparkInterpreter
 INFO [2020-10-30 19:54:21,527] ({Thread-168} ManagedInterpreterGroup.java[close]:105) - Remove this InterpreterGroup: md:shared_process as all the sessions are closed
 INFO [2020-10-30 19:54:21,528] ({Thread-167} ManagedInterpreterGroup.java[close]:89) - Close InterpreterGroup: md:shared_process
 WARN [2020-10-30 19:54:21,528] ({Thread-162} RemoteInterpreter.java[close]:199) - close is called when RemoterInterpreter is not opened for org.apache.zeppelin.spark.SparkSqlInterpreter
 WARN [2020-10-30 19:54:21,528] ({Thread-162} RemoteInterpreter.java[close]:199) - close is called when RemoterInterpreter is not opened for org.apache.zeppelin.spark.DepInterpreter
 WARN [2020-10-30 19:54:21,529] ({Thread-162} RemoteInterpreter.java[close]:199) - close is called when RemoterInterpreter is not opened for org.apache.zeppelin.spark.PySparkInterpreter
 WARN [2020-10-30 19:54:21,529] ({Thread-162} RemoteInterpreter.java[close]:199) - close is called when RemoterInterpreter is not opened for org.apache.zeppelin.spark.IPySparkInterpreter
 WARN [2020-10-30 19:54:21,530] ({Thread-162} RemoteInterpreter.java[close]:199) - close is called when RemoterInterpreter is not opened for org.apache.zeppelin.spark.SparkRInterpreter
 INFO [2020-10-30 19:54:21,530] ({Thread-162} ManagedInterpreterGroup.java[close]:105) - Remove this InterpreterGroup: spark:shared_process as all the sessions are closed
 INFO [2020-10-30 19:54:21,530] ({Thread-161} ManagedInterpreterGroup.java[close]:89) - Close InterpreterGroup: spark:shared_process
 INFO [2020-10-30 19:54:21,530] ({Thread-39} NotebookRepoSync.java[close]:428) - Closing all notebook storages
 INFO [2020-10-30 19:54:24,541] ({Thread-39} ZeppelinServer.java[run]:264) - Bye
 INFO [2020-10-30 19:55:17,340] ({main} ZeppelinConfiguration.java[create]:121) - Load configuration from file:/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/zeppelin-site.xml
 WARN [2020-10-30 19:55:17,399] ({main} ZeppelinConfiguration.java[create]:124) - Failed to load configuration from file:/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/zeppelin-site.xml proceeding with a default
org.apache.commons.configuration.ConfigurationException: Error parsing file:/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/zeppelin-site.xml
	at org.apache.commons.configuration.XMLConfiguration.load(XMLConfiguration.java:950)
	at org.apache.commons.configuration.XMLConfiguration.load(XMLConfiguration.java:908)
	at org.apache.commons.configuration.XMLConfiguration$XMLFileConfigurationDelegate.load(XMLConfiguration.java:1583)
	at org.apache.commons.configuration.AbstractFileConfiguration.load(AbstractFileConfiguration.java:324)
	at org.apache.commons.configuration.AbstractHierarchicalFileConfiguration.load(AbstractHierarchicalFileConfiguration.java:199)
	at org.apache.zeppelin.conf.ZeppelinConfiguration.<init>(ZeppelinConfiguration.java:52)
	at org.apache.zeppelin.conf.ZeppelinConfiguration.create(ZeppelinConfiguration.java:122)
	at org.apache.zeppelin.server.ZeppelinServer.main(ZeppelinServer.java:219)
Caused by: org.xml.sax.SAXParseException; systemId: file:/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/zeppelin-site.xml; lineNumber: 1; columnNumber: 1; Premature end of file.
	at com.sun.org.apache.xerces.internal.parsers.DOMParser.parse(DOMParser.java:257)
	at com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderImpl.parse(DocumentBuilderImpl.java:339)
	at org.apache.commons.configuration.XMLConfiguration.load(XMLConfiguration.java:942)
	... 7 more
 INFO [2020-10-30 19:55:17,423] ({main} ZeppelinConfiguration.java[create]:129) - Server Host: 127.0.0.1
 INFO [2020-10-30 19:55:17,424] ({main} ZeppelinConfiguration.java[create]:131) - Server Port: 9322
 INFO [2020-10-30 19:55:17,424] ({main} ZeppelinConfiguration.java[create]:135) - Context Path: /
 INFO [2020-10-30 19:55:17,425] ({main} ZeppelinConfiguration.java[create]:136) - Zeppelin Version: 0.8.2
 INFO [2020-10-30 19:55:17,447] ({main} Log.java[initialized]:193) - Logging initialized @470ms to org.eclipse.jetty.util.log.Slf4jLog
 WARN [2020-10-30 19:55:17,565] ({main} ServerConnector.java[setSoLingerTime]:458) - Ignoring deprecated socket close linger time
 INFO [2020-10-30 19:55:17,623] ({main} ZeppelinServer.java[setupWebAppContext]:413) - ZeppelinServer Webapp path: /users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/webapps
 INFO [2020-10-30 19:55:17,711] ({main} ZeppelinServer.java[main]:239) - Starting zeppelin server
 INFO [2020-10-30 19:55:17,713] ({main} Server.java[doStart]:370) - jetty-9.4.14.v20181114; built: 2018-11-14T21:20:31.478Z; git: c4550056e785fb5665914545889f21dc136ad9e6; jvm 1.8.0_152-release-1056-b12
 INFO [2020-10-30 19:55:23,016] ({main} StandardDescriptorProcessor.java[visitServlet]:283) - NO JSP Support for /, did not find org.eclipse.jetty.jsp.JettyJspServlet
 INFO [2020-10-30 19:55:23,040] ({main} DefaultSessionIdManager.java[doStart]:365) - DefaultSessionIdManager workerName=node0
 INFO [2020-10-30 19:55:23,041] ({main} DefaultSessionIdManager.java[doStart]:370) - No SessionScavenger set, using defaults
 INFO [2020-10-30 19:55:23,044] ({main} HouseKeeper.java[startScavenging]:149) - node0 Scavenging every 660000ms
 INFO [2020-10-30 19:55:23,428] ({main} SchedulerFactory.java[<init>]:59) - Scheduler Thread Pool Size: 100
 WARN [2020-10-30 19:55:23,445] ({main} ZeppelinConfiguration.java[getConfigFSDir]:527) - zeppelin.config.fs.dir is not specified, fall back to local conf directory zeppelin.conf.dir
 WARN [2020-10-30 19:55:23,445] ({main} ZeppelinConfiguration.java[getConfigFSDir]:527) - zeppelin.config.fs.dir is not specified, fall back to local conf directory zeppelin.conf.dir
 INFO [2020-10-30 19:55:23,566] ({main} InterpreterSettingManager.java[<init>]:165) - Using RecoveryStorage: org.apache.zeppelin.interpreter.recovery.NullRecoveryStorage
 INFO [2020-10-30 19:55:23,568] ({main} InterpreterSettingManager.java[<init>]:169) - Using LifecycleManager: org.apache.zeppelin.interpreter.lifecycle.NullLifecycleManager
 INFO [2020-10-30 19:55:23,608] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: cassandra
 WARN [2020-10-30 19:55:23,614] ({main} InterpreterSettingManager.java[init]:331) - No interpreter-setting.json found in /users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/${interpreter.name}
 INFO [2020-10-30 19:55:23,626] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: angular
 INFO [2020-10-30 19:55:23,631] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: md
 INFO [2020-10-30 19:55:23,635] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: alluxio
 INFO [2020-10-30 19:55:23,639] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: groovy
 INFO [2020-10-30 19:55:23,644] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: pig
 INFO [2020-10-30 19:55:23,649] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: file
 INFO [2020-10-30 19:55:23,654] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: elasticsearch
 INFO [2020-10-30 19:55:23,659] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: lens
 INFO [2020-10-30 19:55:23,663] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: kylin
 INFO [2020-10-30 19:55:23,668] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: sap
 INFO [2020-10-30 19:55:23,673] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: ignite
 INFO [2020-10-30 19:55:23,680] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: neo4j
 INFO [2020-10-30 19:55:23,684] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: python
 INFO [2020-10-30 19:55:23,688] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: bigquery
 WARN [2020-10-30 19:55:23,793] ({main} InterpreterSettingManager.java[init]:331) - No interpreter-setting.json found in /users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/scio
 INFO [2020-10-30 19:55:23,798] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: spark
 INFO [2020-10-30 19:55:23,803] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: livy
 WARN [2020-10-30 19:55:23,806] ({main} InterpreterSettingManager.java[init]:331) - No interpreter-setting.json found in /users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/lib
 INFO [2020-10-30 19:55:23,810] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: sh
 INFO [2020-10-30 19:55:23,813] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: flink
 INFO [2020-10-30 19:55:23,816] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: hbase
 INFO [2020-10-30 19:55:23,820] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: jdbc
 INFO [2020-10-30 19:55:23,820] ({main} LocalConfigStorage.java[loadInterpreterSettings]:63) - Load Interpreter Setting from file: /users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/conf/interpreter.json
 INFO [2020-10-30 19:55:23,899] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting ignite from interpreter.json
 INFO [2020-10-30 19:55:23,899] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting python from interpreter.json
 INFO [2020-10-30 19:55:23,901] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting sap from interpreter.json
 INFO [2020-10-30 19:55:23,902] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting jdbc from interpreter.json
 INFO [2020-10-30 19:55:23,903] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting lens from interpreter.json
 INFO [2020-10-30 19:55:23,904] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting pig from interpreter.json
 INFO [2020-10-30 19:55:23,904] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting flink from interpreter.json
 INFO [2020-10-30 19:55:23,904] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting angular from interpreter.json
 INFO [2020-10-30 19:55:23,906] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting livy from interpreter.json
 INFO [2020-10-30 19:55:23,907] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting groovy from interpreter.json
 INFO [2020-10-30 19:55:23,907] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting neo4j from interpreter.json
 INFO [2020-10-30 19:55:23,908] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting file from interpreter.json
 INFO [2020-10-30 19:55:23,908] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting elasticsearch from interpreter.json
 INFO [2020-10-30 19:55:23,909] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting spark from interpreter.json
 INFO [2020-10-30 19:55:23,911] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting cassandra from interpreter.json
 INFO [2020-10-30 19:55:23,912] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting sh from interpreter.json
 INFO [2020-10-30 19:55:23,912] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting md from interpreter.json
 INFO [2020-10-30 19:55:23,912] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting alluxio from interpreter.json
 INFO [2020-10-30 19:55:23,913] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting bigquery from interpreter.json
 INFO [2020-10-30 19:55:23,913] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting hbase from interpreter.json
 INFO [2020-10-30 19:55:23,914] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting kylin from interpreter.json
 INFO [2020-10-30 19:55:23,919] ({main} LocalConfigStorage.java[save]:53) - Save Interpreter Setting to /users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/conf/interpreter.json
 INFO [2020-10-30 19:55:24,103] ({main} VfsLog.java[info]:138) - Using "/tmp/vfs_cache" as temporary files store.
 INFO [2020-10-30 19:55:24,154] ({main} GitNotebookRepo.java[<init>]:64) - Opening a git repo at '/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/notebook'
 INFO [2020-10-30 19:55:24,227] ({main} NotebookRepoSync.java[<init>]:77) - Instantiate NotebookRepo: org.apache.zeppelin.notebook.repo.GitNotebookRepo
 WARN [2020-10-30 19:55:24,351] ({main} NotebookAuthorization.java[getInstance]:86) - Notebook authorization module was called without initialization, initializing with default configuration
 INFO [2020-10-30 19:55:24,352] ({main} LocalConfigStorage.java[loadNotebookAuthorization]:80) - Load notebook authorization from file: /users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/conf/notebook-authorization.json
 INFO [2020-10-30 19:55:24,355] ({main} Credentials.java[loadFromFile]:121) - /users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/conf/credentials.json
 INFO [2020-10-30 19:55:24,399] ({main} StdSchedulerFactory.java[instantiate]:1184) - Using default implementation for ThreadExecutor
 INFO [2020-10-30 19:55:24,402] ({main} SimpleThreadPool.java[initialize]:268) - Job execution threads will use class loader of thread: main
 INFO [2020-10-30 19:55:24,417] ({main} SchedulerSignalerImpl.java[<init>]:61) - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
 INFO [2020-10-30 19:55:24,418] ({main} QuartzScheduler.java[<init>]:240) - Quartz Scheduler v.2.2.1 created.
 INFO [2020-10-30 19:55:24,419] ({main} RAMJobStore.java[initialize]:155) - RAMJobStore initialized.
 INFO [2020-10-30 19:55:24,420] ({main} QuartzScheduler.java[initialize]:305) - Scheduler meta-data: Quartz Scheduler (v2.2.1) 'DefaultQuartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

 INFO [2020-10-30 19:55:24,420] ({main} StdSchedulerFactory.java[instantiate]:1339) - Quartz scheduler 'DefaultQuartzScheduler' initialized from default resource file in Quartz package: 'quartz.properties'
 INFO [2020-10-30 19:55:24,421] ({main} StdSchedulerFactory.java[instantiate]:1343) - Quartz scheduler version: 2.2.1
 INFO [2020-10-30 19:55:24,421] ({main} QuartzScheduler.java[start]:575) - Scheduler DefaultQuartzScheduler_$_NON_CLUSTERED started.
 INFO [2020-10-30 19:55:24,923] ({main} FolderView.java[createFolder]:107) - Create folder Zeppelin Tutorial
 INFO [2020-10-30 19:55:24,924] ({main} FolderView.java[createFolder]:107) - Create folder /
 INFO [2020-10-30 19:55:24,924] ({main} Folder.java[setParent]:169) - Set parent of / to /
 INFO [2020-10-30 19:55:24,924] ({main} Folder.java[setParent]:169) - Set parent of Zeppelin Tutorial to /
 INFO [2020-10-30 19:55:24,924] ({main} Folder.java[addNote]:185) - Add note 2A94M5J1Z to folder Zeppelin Tutorial
 WARN [2020-10-30 19:55:24,925] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 19:55:24,938] ({main} Folder.java[addNote]:185) - Add note 2BWJFTXKJ to folder Zeppelin Tutorial
 WARN [2020-10-30 19:55:24,939] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 19:55:24,950] ({main} FolderView.java[createFolder]:107) - Create folder Diplodatos
 INFO [2020-10-30 19:55:24,950] ({main} Folder.java[setParent]:169) - Set parent of Diplodatos to /
 INFO [2020-10-30 19:55:24,950] ({main} Folder.java[addNote]:185) - Add note 2FMXBM6HK to folder Diplodatos
 WARN [2020-10-30 19:55:24,951] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 19:55:24,957] ({main} Folder.java[addNote]:185) - Add note 2FNG3ZFM5 to folder Diplodatos
 WARN [2020-10-30 19:55:24,957] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 19:55:24,971] ({main} Folder.java[addNote]:185) - Add note 2FP83VA8P to folder Diplodatos
 WARN [2020-10-30 19:55:24,972] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 19:55:24,981] ({main} Folder.java[addNote]:185) - Add note 2FQA9JFA8 to folder Diplodatos
 WARN [2020-10-30 19:55:24,981] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 19:55:24,994] ({main} Folder.java[addNote]:185) - Add note 2FRXGF37P to folder Diplodatos
 WARN [2020-10-30 19:55:24,995] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 19:55:25,001] ({main} Folder.java[addNote]:185) - Add note 2FPTJC7P4 to folder Diplodatos
 WARN [2020-10-30 19:55:25,002] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 19:55:25,008] ({main} Folder.java[addNote]:185) - Add note 2C2AUG798 to folder Zeppelin Tutorial
 WARN [2020-10-30 19:55:25,009] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 19:55:25,011] ({main} Folder.java[addNote]:185) - Add note 2C57UKYWR to folder Zeppelin Tutorial
 WARN [2020-10-30 19:55:25,012] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 19:55:25,027] ({main} Folder.java[addNote]:185) - Add note 2FP1YEJHN to folder Diplodatos
 WARN [2020-10-30 19:55:25,028] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 19:55:25,035] ({main} Folder.java[addNote]:185) - Add note 2BYEZ5EVK to folder Zeppelin Tutorial
 WARN [2020-10-30 19:55:25,036] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 19:55:25,050] ({main} Folder.java[addNote]:185) - Add note 2FNR8STJW to folder Diplodatos
 WARN [2020-10-30 19:55:25,050] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
ERROR [2020-10-30 19:55:25,050] ({main} Notebook.java[loadNoteFromRepo]:508) - Failed to load 2EUZZ1P8Y
java.io.IOException: file:///users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/notebook/2EUZZ1P8Y is not a directory
	at org.apache.zeppelin.notebook.repo.VFSNotebookRepo.getNote(VFSNotebookRepo.java:151)
	at org.apache.zeppelin.notebook.repo.VFSNotebookRepo.get(VFSNotebookRepo.java:177)
	at org.apache.zeppelin.notebook.repo.NotebookRepoSync.get(NotebookRepoSync.java:165)
	at org.apache.zeppelin.notebook.Notebook.loadNoteFromRepo(Notebook.java:506)
	at org.apache.zeppelin.notebook.Notebook.loadAllNotes(Notebook.java:590)
	at org.apache.zeppelin.notebook.Notebook.<init>(Notebook.java:124)
	at org.apache.zeppelin.server.ZeppelinServer.<init>(ZeppelinServer.java:168)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.glassfish.hk2.utilities.reflection.ReflectionHelper.makeMe(ReflectionHelper.java:1375)
	at org.jvnet.hk2.internal.Utilities.justCreate(Utilities.java:1083)
	at org.jvnet.hk2.internal.ServiceLocatorImpl.create(ServiceLocatorImpl.java:978)
	at org.jvnet.hk2.internal.ServiceLocatorImpl.createAndInitialize(ServiceLocatorImpl.java:1082)
	at org.jvnet.hk2.internal.ServiceLocatorImpl.createAndInitialize(ServiceLocatorImpl.java:1074)
	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.createAndInitialize(AbstractHk2InjectionManager.java:213)
	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.createAndInitialize(ImmediateHk2InjectionManager.java:54)
	at org.glassfish.jersey.server.ApplicationConfigurator.createApplication(ApplicationConfigurator.java:138)
	at org.glassfish.jersey.server.ApplicationConfigurator.init(ApplicationConfigurator.java:96)
	at org.glassfish.jersey.server.ApplicationHandler.lambda$initialize$0(ApplicationHandler.java:313)
	at java.util.Arrays$ArrayList.forEach(Arrays.java:3880)
	at org.glassfish.jersey.server.ApplicationHandler.initialize(ApplicationHandler.java:313)
	at org.glassfish.jersey.server.ApplicationHandler.<init>(ApplicationHandler.java:282)
	at org.glassfish.jersey.servlet.WebComponent.<init>(WebComponent.java:335)
	at org.glassfish.jersey.servlet.ServletContainer.init(ServletContainer.java:178)
	at org.glassfish.jersey.servlet.ServletContainer.init(ServletContainer.java:370)
	at javax.servlet.GenericServlet.init(GenericServlet.java:244)
	at org.eclipse.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:672)
	at org.eclipse.jetty.servlet.ServletHolder.initialize(ServletHolder.java:429)
	at org.eclipse.jetty.servlet.ServletHandler.lambda$initialize$0(ServletHandler.java:750)
	at java.util.stream.SortedOps$SizedRefSortingSink.end(SortedOps.java:352)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471)
	at java.util.stream.StreamSpliterators$WrappingSpliterator.forEachRemaining(StreamSpliterators.java:312)
	at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:743)
	at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742)
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580)
	at org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:744)
	at org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:368)
	at org.eclipse.jetty.webapp.WebAppContext.startWebapp(WebAppContext.java:1497)
	at org.eclipse.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1459)
	at org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:852)
	at org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:278)
	at org.eclipse.jetty.webapp.WebAppContext.doStart(WebAppContext.java:545)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:138)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)
	at org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:113)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.doStart(ContextHandlerCollection.java:168)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:138)
	at org.eclipse.jetty.server.Server.start(Server.java:415)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:108)
	at org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:113)
	at org.eclipse.jetty.server.Server.doStart(Server.java:382)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.zeppelin.server.ZeppelinServer.main(ZeppelinServer.java:241)
ERROR [2020-10-30 19:55:25,051] ({main} Notebook.java[loadNoteFromRepo]:508) - Failed to load 2FNMF7WE2
java.io.IOException: file:///users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/notebook/2FNMF7WE2 is not a directory
	at org.apache.zeppelin.notebook.repo.VFSNotebookRepo.getNote(VFSNotebookRepo.java:151)
	at org.apache.zeppelin.notebook.repo.VFSNotebookRepo.get(VFSNotebookRepo.java:177)
	at org.apache.zeppelin.notebook.repo.NotebookRepoSync.get(NotebookRepoSync.java:165)
	at org.apache.zeppelin.notebook.Notebook.loadNoteFromRepo(Notebook.java:506)
	at org.apache.zeppelin.notebook.Notebook.loadAllNotes(Notebook.java:590)
	at org.apache.zeppelin.notebook.Notebook.<init>(Notebook.java:124)
	at org.apache.zeppelin.server.ZeppelinServer.<init>(ZeppelinServer.java:168)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.glassfish.hk2.utilities.reflection.ReflectionHelper.makeMe(ReflectionHelper.java:1375)
	at org.jvnet.hk2.internal.Utilities.justCreate(Utilities.java:1083)
	at org.jvnet.hk2.internal.ServiceLocatorImpl.create(ServiceLocatorImpl.java:978)
	at org.jvnet.hk2.internal.ServiceLocatorImpl.createAndInitialize(ServiceLocatorImpl.java:1082)
	at org.jvnet.hk2.internal.ServiceLocatorImpl.createAndInitialize(ServiceLocatorImpl.java:1074)
	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.createAndInitialize(AbstractHk2InjectionManager.java:213)
	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.createAndInitialize(ImmediateHk2InjectionManager.java:54)
	at org.glassfish.jersey.server.ApplicationConfigurator.createApplication(ApplicationConfigurator.java:138)
	at org.glassfish.jersey.server.ApplicationConfigurator.init(ApplicationConfigurator.java:96)
	at org.glassfish.jersey.server.ApplicationHandler.lambda$initialize$0(ApplicationHandler.java:313)
	at java.util.Arrays$ArrayList.forEach(Arrays.java:3880)
	at org.glassfish.jersey.server.ApplicationHandler.initialize(ApplicationHandler.java:313)
	at org.glassfish.jersey.server.ApplicationHandler.<init>(ApplicationHandler.java:282)
	at org.glassfish.jersey.servlet.WebComponent.<init>(WebComponent.java:335)
	at org.glassfish.jersey.servlet.ServletContainer.init(ServletContainer.java:178)
	at org.glassfish.jersey.servlet.ServletContainer.init(ServletContainer.java:370)
	at javax.servlet.GenericServlet.init(GenericServlet.java:244)
	at org.eclipse.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:672)
	at org.eclipse.jetty.servlet.ServletHolder.initialize(ServletHolder.java:429)
	at org.eclipse.jetty.servlet.ServletHandler.lambda$initialize$0(ServletHandler.java:750)
	at java.util.stream.SortedOps$SizedRefSortingSink.end(SortedOps.java:352)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471)
	at java.util.stream.StreamSpliterators$WrappingSpliterator.forEachRemaining(StreamSpliterators.java:312)
	at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:743)
	at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742)
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580)
	at org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:744)
	at org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:368)
	at org.eclipse.jetty.webapp.WebAppContext.startWebapp(WebAppContext.java:1497)
	at org.eclipse.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1459)
	at org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:852)
	at org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:278)
	at org.eclipse.jetty.webapp.WebAppContext.doStart(WebAppContext.java:545)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:138)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)
	at org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:113)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.doStart(ContextHandlerCollection.java:168)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:138)
	at org.eclipse.jetty.server.Server.start(Server.java:415)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:108)
	at org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:113)
	at org.eclipse.jetty.server.Server.doStart(Server.java:382)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.zeppelin.server.ZeppelinServer.main(ZeppelinServer.java:241)
 INFO [2020-10-30 19:55:25,058] ({main} Folder.java[addNote]:185) - Add note 2C35YU814 to folder Zeppelin Tutorial
 WARN [2020-10-30 19:55:25,058] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 19:55:25,058] ({main} Notebook.java[<init>]:127) - Notebook indexing started...
 INFO [2020-10-30 19:55:25,321] ({main} LuceneSearch.java[addIndexDocs]:305) - Indexing 14 notebooks took 262ms
 INFO [2020-10-30 19:55:25,322] ({main} Notebook.java[<init>]:129) - Notebook indexing finished: 14 indexed in 0s
 INFO [2020-10-30 19:55:25,324] ({main} Helium.java[loadConf]:103) - Add helium local registry /users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/helium
 INFO [2020-10-30 19:55:25,325] ({main} Helium.java[loadConf]:100) - Add helium online registry https://s3.amazonaws.com/helium-package/helium.json
 WARN [2020-10-30 19:55:25,330] ({main} Helium.java[loadConf]:111) - /users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/conf/helium.json does not exists
 INFO [2020-10-30 19:55:27,893] ({main} ContextHandler.java[doStart]:855) - Started o.e.j.w.WebAppContext@15761df8{zeppelin-web,/,file:///users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/webapps/webapp/,AVAILABLE}{/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/zeppelin-web-0.8.2.war}
 INFO [2020-10-30 19:55:27,917] ({main} AbstractConnector.java[doStart]:292) - Started ServerConnector@39e69ea7{HTTP/1.1,[http/1.1]}{127.0.0.1:9322}
 INFO [2020-10-30 19:55:27,917] ({main} Server.java[doStart]:407) - Started @10943ms
 INFO [2020-10-30 19:55:27,917] ({main} ZeppelinServer.java[main]:249) - Done, zeppelin server started
 WARN [2020-10-30 19:55:31,558] ({qtp89387388-23} SecurityRestApi.java[ticket]:88) - {"status":"OK","message":"","body":{"principal":"anonymous","ticket":"anonymous","roles":"[]"}}
 INFO [2020-10-30 19:55:31,773] ({qtp89387388-24} NotebookServer.java[onOpen]:151) - New connection from 127.0.0.1 : 51380
 WARN [2020-10-30 19:55:40,426] ({qtp89387388-22} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 19:55:40,427] ({qtp89387388-22} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 19:55:40,427] ({qtp89387388-22} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 19:55:40,427] ({qtp89387388-22} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 19:55:40,428] ({qtp89387388-22} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 19:55:40,428] ({qtp89387388-22} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 19:55:55,337] ({qtp89387388-20} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 19:55:55,337] ({qtp89387388-20} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 19:55:55,338] ({qtp89387388-20} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 19:55:55,338] ({qtp89387388-20} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 19:55:55,338] ({qtp89387388-20} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 19:55:55,338] ({qtp89387388-20} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 INFO [2020-10-30 19:55:55,339] ({qtp89387388-20} LocalConfigStorage.java[save]:53) - Save Interpreter Setting to /users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/conf/interpreter.json
 INFO [2020-10-30 19:55:55,384] ({qtp89387388-20} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 19:55:55,390] ({qtp89387388-20} FolderView.java[onNoteNameChanged]:205) - Note name changed: 2FP7CYTB9 -> Diplodatos/Clase 05 - Machine Learning
 INFO [2020-10-30 19:55:55,390] ({qtp89387388-20} Folder.java[addNote]:185) - Add note 2FP7CYTB9 to folder Diplodatos
 INFO [2020-10-30 19:55:55,746] ({qtp89387388-20} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 19:55:55,963] ({qtp89387388-20} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 19:55:59,145] ({qtp89387388-22} NotebookServer.java[sendNote]:828) - New operation from 127.0.0.1 : 51380 : anonymous : GET_NOTE : 2FP7CYTB9
 WARN [2020-10-30 19:55:59,429] ({qtp89387388-22} GitNotebookRepo.java[revisionHistory]:158) - No Head found for 2FP7CYTB9, No HEAD exists and no explicit starting revision was specified
 WARN [2020-10-30 19:56:02,392] ({qtp89387388-22} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 19:56:02,392] ({qtp89387388-22} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 19:56:02,393] ({qtp89387388-22} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 19:56:02,393] ({qtp89387388-22} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 19:56:02,394] ({qtp89387388-22} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 19:56:02,394] ({qtp89387388-22} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 INFO [2020-10-30 19:56:02,858] ({qtp89387388-75} InterpreterSetting.java[getOrCreateInterpreterGroup]:419) - Create InterpreterGroup with groupId: spark:shared_process for user: anonymous and note: 2FP7CYTB9
 INFO [2020-10-30 19:56:02,863] ({qtp89387388-75} InterpreterSetting.java[createInterpreters]:689) - Interpreter org.apache.zeppelin.spark.SparkInterpreter created for user: anonymous, sessionId: shared_session
 INFO [2020-10-30 19:56:02,863] ({qtp89387388-75} InterpreterSetting.java[createInterpreters]:689) - Interpreter org.apache.zeppelin.spark.SparkSqlInterpreter created for user: anonymous, sessionId: shared_session
 INFO [2020-10-30 19:56:02,864] ({qtp89387388-75} InterpreterSetting.java[createInterpreters]:689) - Interpreter org.apache.zeppelin.spark.DepInterpreter created for user: anonymous, sessionId: shared_session
 INFO [2020-10-30 19:56:02,864] ({qtp89387388-75} InterpreterSetting.java[createInterpreters]:689) - Interpreter org.apache.zeppelin.spark.PySparkInterpreter created for user: anonymous, sessionId: shared_session
 INFO [2020-10-30 19:56:02,864] ({qtp89387388-75} InterpreterSetting.java[createInterpreters]:689) - Interpreter org.apache.zeppelin.spark.IPySparkInterpreter created for user: anonymous, sessionId: shared_session
 INFO [2020-10-30 19:56:02,864] ({qtp89387388-75} InterpreterSetting.java[createInterpreters]:689) - Interpreter org.apache.zeppelin.spark.SparkRInterpreter created for user: anonymous, sessionId: shared_session
 INFO [2020-10-30 19:56:02,865] ({qtp89387388-75} ManagedInterpreterGroup.java[getOrCreateSession]:158) - Create Session: shared_session in InterpreterGroup: spark:shared_process for user: anonymous
 INFO [2020-10-30 19:56:03,237] ({qtp89387388-65} InterpreterSetting.java[getOrCreateInterpreterGroup]:419) - Create InterpreterGroup with groupId: md:shared_process for user: anonymous and note: 2FP7CYTB9
 INFO [2020-10-30 19:56:03,238] ({qtp89387388-65} InterpreterSetting.java[createInterpreters]:689) - Interpreter org.apache.zeppelin.markdown.Markdown created for user: anonymous, sessionId: shared_session
 INFO [2020-10-30 19:56:03,239] ({qtp89387388-65} ManagedInterpreterGroup.java[getOrCreateSession]:158) - Create Session: shared_session in InterpreterGroup: md:shared_process for user: anonymous
 INFO [2020-10-30 19:57:52,925] ({qtp89387388-95} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 19:57:53,713] ({qtp89387388-25} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 19:57:53,769] ({pool-2-thread-2} SchedulerFactory.java[jobStarted]:114) - Job 20171030-192143_1165730818 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 19:57:53,770] ({pool-2-thread-2} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20171030-192143_1165730818, interpreter: pyspark, note_id: 2FP7CYTB9, user: anonymous]
 INFO [2020-10-30 19:57:53,770] ({pool-2-thread-2} ManagedInterpreterGroup.java[getOrCreateInterpreterProcess]:61) - Create InterpreterProcess for InterpreterGroup: spark:shared_process
 INFO [2020-10-30 19:57:53,771] ({pool-2-thread-2} ShellScriptLauncher.java[launch]:48) - Launching Interpreter: spark
 WARN [2020-10-30 19:57:53,789] ({pool-2-thread-2} SparkInterpreterLauncher.java[setupPropertiesForSparkR]:172) - sparkr.zip is not found, SparkR may not work.
 INFO [2020-10-30 19:57:53,789] ({pool-2-thread-2} SparkInterpreterLauncher.java[buildEnvFromProperties]:108) - Run Spark under non-secure mode as no keytab and principal is specified
 INFO [2020-10-30 19:57:53,794] ({pool-2-thread-2} RemoteInterpreterManagedProcess.java[start]:115) - Thrift server for callback will start. Port: 35507
 INFO [2020-10-30 19:57:53,808] ({pool-2-thread-2} RemoteInterpreterManagedProcess.java[start]:190) - Run interpreter process [/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/bin/interpreter.sh, -d, /users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark, -c, 200.16.29.165, -p, 35507, -r, :, -l, /users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/local-repo/spark, -g, spark]
 INFO [2020-10-30 19:57:55,298] ({pool-7-thread-1} RemoteInterpreterManagedProcess.java[callback]:123) - RemoteInterpreterServer Registered: CallbackInfo(host:200.16.29.165, port:45927)
 INFO [2020-10-30 19:57:55,377] ({pool-2-thread-2} RemoteInterpreter.java[call]:168) - Create RemoteInterpreter org.apache.zeppelin.spark.SparkInterpreter
 INFO [2020-10-30 19:57:55,552] ({pool-2-thread-2} RemoteInterpreter.java[call]:168) - Create RemoteInterpreter org.apache.zeppelin.spark.SparkSqlInterpreter
 INFO [2020-10-30 19:57:55,555] ({pool-2-thread-2} RemoteInterpreter.java[call]:168) - Create RemoteInterpreter org.apache.zeppelin.spark.DepInterpreter
 INFO [2020-10-30 19:57:55,580] ({pool-2-thread-2} RemoteInterpreter.java[call]:168) - Create RemoteInterpreter org.apache.zeppelin.spark.PySparkInterpreter
 INFO [2020-10-30 19:57:55,601] ({pool-2-thread-2} RemoteInterpreter.java[call]:168) - Create RemoteInterpreter org.apache.zeppelin.spark.IPySparkInterpreter
 INFO [2020-10-30 19:57:55,607] ({pool-2-thread-2} RemoteInterpreter.java[call]:168) - Create RemoteInterpreter org.apache.zeppelin.spark.SparkRInterpreter
 INFO [2020-10-30 19:57:55,611] ({pool-2-thread-2} RemoteInterpreter.java[call]:142) - Open RemoteInterpreter org.apache.zeppelin.spark.PySparkInterpreter
 INFO [2020-10-30 19:57:55,611] ({pool-2-thread-2} RemoteInterpreter.java[pushAngularObjectRegistryToRemote]:436) - Push local angular object registry from ZeppelinServer to remote interpreter group spark:shared_process
 WARN [2020-10-30 19:58:06,638] ({pool-2-thread-2} NotebookServer.java[afterStatusChange]:2316) - Job 20171030-192143_1165730818 is finished, status: ERROR, exception: null, result: %text Traceback (most recent call last):
  File "/tmp/zeppelin_pyspark-22800890596813490.py", line 364, in <module>
    code = compile('\n'.join(stmts), '<stdin>', 'exec', ast.PyCF_ONLY_AST, 1)
  File "<stdin>", line 11
    dtModel2 = dtEstimator2...
                             ^
SyntaxError: invalid syntax

 INFO [2020-10-30 19:58:06,743] ({pool-2-thread-2} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 19:58:06,804] ({pool-2-thread-2} SchedulerFactory.java[jobFinished]:120) - Job 20171030-192143_1165730818 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 19:58:36,647] ({qtp89387388-69} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 19:58:36,787] ({qtp89387388-69} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 19:58:36,852] ({pool-2-thread-2} SchedulerFactory.java[jobStarted]:114) - Job 20171030-192143_1165730818 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 19:58:36,853] ({pool-2-thread-2} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20171030-192143_1165730818, interpreter: pyspark, note_id: 2FP7CYTB9, user: anonymous]
 WARN [2020-10-30 19:58:37,013] ({pool-2-thread-2} NotebookServer.java[afterStatusChange]:2316) - Job 20171030-192143_1165730818 is finished, status: ERROR, exception: null, result: %text Fail to execute line 11: dtModel2 = dtEstimator2.fit(trainFeaturized)
Traceback (most recent call last):
  File "/tmp/zeppelin_pyspark-22800890596813490.py", line 375, in <module>
    exec(code, _zcUserQueryNameSpace)
  File "<stdin>", line 11, in <module>
NameError: name 'trainFeaturized' is not defined

 INFO [2020-10-30 19:58:37,103] ({pool-2-thread-2} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 19:58:37,150] ({pool-2-thread-2} SchedulerFactory.java[jobFinished]:120) - Job 20171030-192143_1165730818 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 19:59:01,086] ({qtp89387388-23} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 19:59:01,220] ({qtp89387388-23} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 19:59:01,276] ({pool-2-thread-3} SchedulerFactory.java[jobStarted]:114) - Job 20171030-192143_1165730818 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 19:59:01,276] ({pool-2-thread-3} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20171030-192143_1165730818, interpreter: pyspark, note_id: 2FP7CYTB9, user: anonymous]
 WARN [2020-10-30 19:59:01,294] ({pool-2-thread-3} NotebookServer.java[afterStatusChange]:2316) - Job 20171030-192143_1165730818 is finished, status: ERROR, exception: null, result: %text Fail to execute line 11: dtModel2 = dtEstimator2.fit(trainFeaturized)
Traceback (most recent call last):
  File "/tmp/zeppelin_pyspark-22800890596813490.py", line 375, in <module>
    exec(code, _zcUserQueryNameSpace)
  File "<stdin>", line 11, in <module>
NameError: name 'trainFeaturized' is not defined

 INFO [2020-10-30 19:59:01,382] ({pool-2-thread-3} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 19:59:01,431] ({pool-2-thread-3} SchedulerFactory.java[jobFinished]:120) - Job 20171030-192143_1165730818 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 19:59:31,064] ({qtp89387388-21} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 19:59:31,112] ({pool-2-thread-2} SchedulerFactory.java[jobStarted]:114) - Job 20161101-163522_1877878760 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 19:59:31,113] ({pool-2-thread-2} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20161101-163522_1877878760, interpreter: pyspark, note_id: 2FP7CYTB9, user: anonymous]
 WARN [2020-10-30 19:59:31,122] ({pool-2-thread-2} NotebookServer.java[afterStatusChange]:2316) - Job 20161101-163522_1877878760 is finished, status: ERROR, exception: null, result: %text Traceback (most recent call last):
  File "/tmp/zeppelin_pyspark-22800890596813490.py", line 364, in <module>
    code = compile('\n'.join(stmts), '<stdin>', 'exec', ast.PyCF_ONLY_AST, 1)
  File "<stdin>", line 8
    print "Cantidad de filas: {}. Cantidad de particiones: {}.".format(people.count(), people.rdd.getNumPartitions())
                                                              ^
SyntaxError: invalid syntax

 INFO [2020-10-30 19:59:31,199] ({pool-2-thread-2} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 19:59:31,247] ({pool-2-thread-2} SchedulerFactory.java[jobFinished]:120) - Job 20161101-163522_1877878760 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:00:01,058] ({qtp89387388-93} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:00:01,180] ({qtp89387388-93} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:00:01,234] ({pool-2-thread-4} SchedulerFactory.java[jobStarted]:114) - Job 20161101-163522_1877878760 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:00:01,234] ({pool-2-thread-4} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20161101-163522_1877878760, interpreter: pyspark, note_id: 2FP7CYTB9, user: anonymous]
 WARN [2020-10-30 20:00:06,441] ({pool-2-thread-4} NotebookServer.java[afterStatusChange]:2316) - Job 20161101-163522_1877878760 is finished, status: ERROR, exception: null, result: %text Fail to execute line 3: people = spark.read.json(inputFile) \
Traceback (most recent call last):
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/sql/utils.py", line 63, in deco
    return f(*a, **kw)
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/py4j-0.10.4-src.zip/py4j/protocol.py", line 319, in get_return_value
    format(target_id, ".", name), value)
py4j.protocol.Py4JJavaError: An error occurred while calling o56.json.
: org.apache.spark.sql.AnalysisException: Path does not exist: file:/users/ssulca/diplodatos_bigdata/diplodatos_bigdata/ds/people_sex_height_age_weight.json;
	at org.apache.spark.sql.execution.datasources.DataSource$.org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary(DataSource.scala:626)
	at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:350)
	at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:350)
	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
	at scala.collection.immutable.List.flatMap(List.scala:344)
	at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:349)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:178)
	at org.apache.spark.sql.DataFrameReader.json(DataFrameReader.scala:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:214)
	at java.lang.Thread.run(Thread.java:745)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/tmp/zeppelin_pyspark-22800890596813490.py", line 375, in <module>
    exec(code, _zcUserQueryNameSpace)
  File "<stdin>", line 3, in <module>
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/sql/readwriter.py", line 249, in json
    return self._df(self._jreader.json(self._spark._sc._jvm.PythonUtils.toSeq(path)))
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/py4j-0.10.4-src.zip/py4j/java_gateway.py", line 1133, in __call__
    answer, self.gateway_client, self.target_id, self.name)
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/sql/utils.py", line 69, in deco
    raise AnalysisException(s.split(': ', 1)[1], stackTrace)
pyspark.sql.utils.AnalysisException: 'Path does not exist: file:/users/ssulca/diplodatos_bigdata/diplodatos_bigdata/ds/people_sex_height_age_weight.json;'

 INFO [2020-10-30 20:00:06,537] ({pool-2-thread-4} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:00:06,586] ({pool-2-thread-4} SchedulerFactory.java[jobFinished]:120) - Job 20161101-163522_1877878760 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:00:37,397] ({qtp89387388-66} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:00:37,511] ({qtp89387388-66} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:00:37,556] ({pool-2-thread-3} SchedulerFactory.java[jobStarted]:114) - Job 20161101-163522_1877878760 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:00:37,557] ({pool-2-thread-3} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20161101-163522_1877878760, interpreter: pyspark, note_id: 2FP7CYTB9, user: anonymous]
 INFO [2020-10-30 20:00:40,495] ({pool-2-thread-3} NotebookServer.java[afterStatusChange]:2314) - Job 20161101-163522_1877878760 is finished successfully, status: FINISHED
 INFO [2020-10-30 20:00:40,566] ({pool-2-thread-3} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:00:40,613] ({pool-2-thread-3} SchedulerFactory.java[jobFinished]:120) - Job 20161101-163522_1877878760 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:00:48,903] ({qtp89387388-92} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:00:48,958] ({pool-2-thread-5} SchedulerFactory.java[jobStarted]:114) - Job 20171030-162612_256050184 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:00:48,959] ({pool-2-thread-5} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20171030-162612_256050184, interpreter: pyspark, note_id: 2FP7CYTB9, user: anonymous]
 WARN [2020-10-30 20:00:48,968] ({pool-2-thread-5} NotebookServer.java[afterStatusChange]:2316) - Job 20171030-162612_256050184 is finished, status: ERROR, exception: null, result: %text Traceback (most recent call last):
  File "/tmp/zeppelin_pyspark-22800890596813490.py", line 364, in <module>
    code = compile('\n'.join(stmts), '<stdin>', 'exec', ast.PyCF_ONLY_AST, 1)
  File "<stdin>", line 3
    print testDF.count(), trainDF.count()
               ^
SyntaxError: invalid syntax

 INFO [2020-10-30 20:00:49,042] ({pool-2-thread-5} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:00:49,090] ({pool-2-thread-5} SchedulerFactory.java[jobFinished]:120) - Job 20171030-162612_256050184 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:00:55,147] ({qtp89387388-24} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:00:55,295] ({qtp89387388-93} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:00:55,361] ({pool-2-thread-2} SchedulerFactory.java[jobStarted]:114) - Job 20171030-162612_256050184 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:00:55,362] ({pool-2-thread-2} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20171030-162612_256050184, interpreter: pyspark, note_id: 2FP7CYTB9, user: anonymous]
 INFO [2020-10-30 20:00:55,806] ({pool-2-thread-2} NotebookServer.java[afterStatusChange]:2314) - Job 20171030-162612_256050184 is finished successfully, status: FINISHED
 INFO [2020-10-30 20:00:55,893] ({pool-2-thread-2} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:00:55,959] ({pool-2-thread-2} SchedulerFactory.java[jobFinished]:120) - Job 20171030-162612_256050184 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:00:59,950] ({qtp89387388-24} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:01:00,018] ({pool-2-thread-6} SchedulerFactory.java[jobStarted]:114) - Job 20171030-163816_785316912 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:01:00,019] ({pool-2-thread-6} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20171030-163816_785316912, interpreter: pyspark, note_id: 2FP7CYTB9, user: anonymous]
 INFO [2020-10-30 20:01:00,416] ({pool-2-thread-6} NotebookServer.java[afterStatusChange]:2314) - Job 20171030-163816_785316912 is finished successfully, status: FINISHED
 INFO [2020-10-30 20:01:00,486] ({pool-2-thread-6} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:01:00,536] ({pool-2-thread-6} SchedulerFactory.java[jobFinished]:120) - Job 20171030-163816_785316912 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:01:03,770] ({qtp89387388-93} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:01:03,819] ({pool-2-thread-4} SchedulerFactory.java[jobStarted]:114) - Job 20171030-164611_870874723 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:01:03,820] ({pool-2-thread-4} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20171030-164611_870874723, interpreter: pyspark, note_id: 2FP7CYTB9, user: anonymous]
 INFO [2020-10-30 20:01:04,566] ({pool-2-thread-4} NotebookServer.java[afterStatusChange]:2314) - Job 20171030-164611_870874723 is finished successfully, status: FINISHED
 INFO [2020-10-30 20:01:04,633] ({pool-2-thread-4} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:01:04,681] ({pool-2-thread-4} SchedulerFactory.java[jobFinished]:120) - Job 20171030-164611_870874723 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:01:08,319] ({qtp89387388-92} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:01:08,372] ({pool-2-thread-7} SchedulerFactory.java[jobStarted]:114) - Job 20161102-154506_492289084 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:01:08,373] ({pool-2-thread-7} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20161102-154506_492289084, interpreter: pyspark, note_id: 2FP7CYTB9, user: anonymous]
 WARN [2020-10-30 20:01:08,384] ({pool-2-thread-7} NotebookServer.java[afterStatusChange]:2316) - Job 20161102-154506_492289084 is finished, status: ERROR, exception: null, result: %text Traceback (most recent call last):
  File "/tmp/zeppelin_pyspark-22800890596813490.py", line 364, in <module>
    code = compile('\n'.join(stmts), '<stdin>', 'exec', ast.PyCF_ONLY_AST, 1)
  File "<stdin>", line 18
    print "%html <div style='width:600px'><img src=\"data:image/png;base64," + img.buf.encode('base64').replace('\n', '') + "\"/></div>"
                                                                           ^
SyntaxError: invalid syntax

 INFO [2020-10-30 20:01:08,454] ({pool-2-thread-7} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:01:08,502] ({pool-2-thread-7} SchedulerFactory.java[jobFinished]:120) - Job 20161102-154506_492289084 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:01:26,391] ({qtp89387388-71} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:01:26,502] ({qtp89387388-71} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:01:26,556] ({pool-2-thread-3} SchedulerFactory.java[jobStarted]:114) - Job 20161102-154506_492289084 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:01:26,557] ({pool-2-thread-3} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20161102-154506_492289084, interpreter: pyspark, note_id: 2FP7CYTB9, user: anonymous]
 INFO [2020-10-30 20:01:26,574] ({pool-2-thread-3} NotebookServer.java[afterStatusChange]:2314) - Job 20161102-154506_492289084 is finished successfully, status: FINISHED
 INFO [2020-10-30 20:01:26,648] ({pool-2-thread-3} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:01:26,701] ({pool-2-thread-3} SchedulerFactory.java[jobFinished]:120) - Job 20161102-154506_492289084 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:01:30,508] ({qtp89387388-24} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:01:30,556] ({pool-2-thread-8} SchedulerFactory.java[jobStarted]:114) - Job 20171030-173939_397652020 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:01:30,557] ({pool-2-thread-8} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20171030-173939_397652020, interpreter: pyspark, note_id: 2FP7CYTB9, user: anonymous]
 WARN [2020-10-30 20:01:31,532] ({pool-2-thread-8} NotebookServer.java[afterStatusChange]:2316) - Job 20171030-173939_397652020 is finished, status: ERROR, exception: null, result: %text Fail to execute line 1: plot_classification(trainFeaturized)
Traceback (most recent call last):
  File "/tmp/zeppelin_pyspark-22800890596813490.py", line 380, in <module>
    exec(code, _zcUserQueryNameSpace)
  File "<stdin>", line 1, in <module>
  File "<stdin>", line 59, in plot_classification
  File "<stdin>", line 14, in show
ModuleNotFoundError: No module named 'StringIO'

 INFO [2020-10-30 20:01:31,609] ({pool-2-thread-8} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:01:31,655] ({pool-2-thread-8} SchedulerFactory.java[jobFinished]:120) - Job 20171030-173939_397652020 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:01:46,439] ({qtp89387388-19} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:01:46,491] ({pool-2-thread-5} SchedulerFactory.java[jobStarted]:114) - Job 20161102-154506_492289084 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:01:46,491] ({pool-2-thread-5} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20161102-154506_492289084, interpreter: pyspark, note_id: 2FP7CYTB9, user: anonymous]
 INFO [2020-10-30 20:01:46,834] ({pool-2-thread-5} NotebookServer.java[afterStatusChange]:2314) - Job 20161102-154506_492289084 is finished successfully, status: FINISHED
 INFO [2020-10-30 20:01:46,900] ({pool-2-thread-5} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:01:46,967] ({pool-2-thread-5} SchedulerFactory.java[jobFinished]:120) - Job 20161102-154506_492289084 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:01:50,427] ({qtp89387388-24} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:01:50,474] ({pool-2-thread-9} SchedulerFactory.java[jobStarted]:114) - Job 20171030-173939_397652020 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:01:50,475] ({pool-2-thread-9} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20171030-173939_397652020, interpreter: pyspark, note_id: 2FP7CYTB9, user: anonymous]
 WARN [2020-10-30 20:01:50,661] ({pool-2-thread-9} NotebookServer.java[afterStatusChange]:2316) - Job 20171030-173939_397652020 is finished, status: ERROR, exception: null, result: %text Fail to execute line 1: plot_classification(trainFeaturized)
Traceback (most recent call last):
  File "/tmp/zeppelin_pyspark-22800890596813490.py", line 380, in <module>
    exec(code, _zcUserQueryNameSpace)
  File "<stdin>", line 1, in <module>
  File "<stdin>", line 59, in plot_classification
  File "<stdin>", line 14, in show
ModuleNotFoundError: No module named 'StringIO'

 INFO [2020-10-30 20:01:50,739] ({pool-2-thread-9} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:01:50,787] ({pool-2-thread-9} SchedulerFactory.java[jobFinished]:120) - Job 20171030-173939_397652020 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:02:05,965] ({qtp89387388-73} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:02:06,018] ({pool-2-thread-2} SchedulerFactory.java[jobStarted]:114) - Job 20161107-153258_1183600330 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:02:06,018] ({pool-2-thread-2} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20161107-153258_1183600330, interpreter: pyspark, note_id: 2FP7CYTB9, user: anonymous]
 INFO [2020-10-30 20:02:07,671] ({pool-2-thread-2} NotebookServer.java[afterStatusChange]:2314) - Job 20161107-153258_1183600330 is finished successfully, status: FINISHED
 INFO [2020-10-30 20:02:07,738] ({pool-2-thread-2} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:02:07,794] ({pool-2-thread-2} SchedulerFactory.java[jobFinished]:120) - Job 20161107-153258_1183600330 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:02:11,786] ({qtp89387388-19} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:02:11,845] ({pool-2-thread-10} SchedulerFactory.java[jobStarted]:114) - Job 20171030-191336_34491578 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:02:11,846] ({pool-2-thread-10} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20171030-191336_34491578, interpreter: pyspark, note_id: 2FP7CYTB9, user: anonymous]
 INFO [2020-10-30 20:02:12,016] ({pool-2-thread-10} NotebookServer.java[afterStatusChange]:2314) - Job 20171030-191336_34491578 is finished successfully, status: FINISHED
 INFO [2020-10-30 20:02:12,087] ({pool-2-thread-10} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:02:12,139] ({pool-2-thread-10} SchedulerFactory.java[jobFinished]:120) - Job 20171030-191336_34491578 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:02:16,841] ({qtp89387388-19} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:02:16,894] ({pool-2-thread-6} SchedulerFactory.java[jobStarted]:114) - Job 20161107-030549_2115288931 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:02:16,895] ({pool-2-thread-6} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20161107-030549_2115288931, interpreter: pyspark, note_id: 2FP7CYTB9, user: anonymous]
 WARN [2020-10-30 20:02:16,908] ({pool-2-thread-6} NotebookServer.java[afterStatusChange]:2316) - Job 20161107-030549_2115288931 is finished, status: ERROR, exception: null, result: %text Traceback (most recent call last):
  File "/tmp/zeppelin_pyspark-22800890596813490.py", line 364, in <module>
    code = compile('\n'.join(stmts), '<stdin>', 'exec', ast.PyCF_ONLY_AST, 1)
  File "<stdin>", line 20
    .map(lambda (x,y): (fgrid(x,minKgs,maxKgs,maxTics), fgrid(y,minMts,maxMts,maxTics))) \
                ^
SyntaxError: invalid syntax

 INFO [2020-10-30 20:02:16,976] ({pool-2-thread-6} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:02:17,025] ({pool-2-thread-6} SchedulerFactory.java[jobFinished]:120) - Job 20161107-030549_2115288931 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:02:33,211] ({qtp89387388-73} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:02:33,543] ({qtp89387388-73} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:02:33,615] ({pool-2-thread-11} SchedulerFactory.java[jobStarted]:114) - Job 20161107-030549_2115288931 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:02:33,616] ({pool-2-thread-11} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20161107-030549_2115288931, interpreter: pyspark, note_id: 2FP7CYTB9, user: anonymous]
 WARN [2020-10-30 20:02:34,321] ({pool-2-thread-11} NotebookServer.java[afterStatusChange]:2316) - Job 20161107-030549_2115288931 is finished, status: ERROR, exception: null, result: %text Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 66.0 failed 1 times, most recent failure: Lost task 0.0 in stage 66.0 (TID 489, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py", line 177, in main
    process()
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py", line 172, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/rdd.py", line 1339, in takeUpToNumLeft
TypeError: <lambda>() missing 1 required positional argument: 'y'

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2069)
	at org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:455)
	at org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:214)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py", line 177, in main
    process()
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py", line 172, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/rdd.py", line 1339, in takeUpToNumLeft
TypeError: <lambda>() missing 1 required positional argument: 'y'

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	... 1 more

(<class 'py4j.protocol.Py4JJavaError'>, Py4JJavaError('An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n', JavaObject id=o232), <traceback object at 0x7fdafb2853c8>)
 INFO [2020-10-30 20:02:34,383] ({pool-2-thread-11} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:02:34,431] ({pool-2-thread-11} SchedulerFactory.java[jobFinished]:120) - Job 20161107-030549_2115288931 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:03:54,340] ({qtp89387388-73} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:03:54,390] ({pool-2-thread-4} SchedulerFactory.java[jobStarted]:114) - Job 20171030-185922_914672286 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:03:54,392] ({pool-2-thread-4} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20171030-185922_914672286, interpreter: pyspark, note_id: 2FP7CYTB9, user: anonymous]
 WARN [2020-10-30 20:03:54,407] ({pool-2-thread-4} NotebookServer.java[afterStatusChange]:2316) - Job 20171030-185922_914672286 is finished, status: ERROR, exception: null, result: %text Fail to execute line 2: gridPredictionDT = dtModel.transform(grid)
Traceback (most recent call last):
  File "/tmp/zeppelin_pyspark-22800890596813490.py", line 375, in <module>
    exec(code, _zcUserQueryNameSpace)
  File "<stdin>", line 2, in <module>
NameError: name 'grid' is not defined

 INFO [2020-10-30 20:03:54,477] ({pool-2-thread-4} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:03:54,532] ({pool-2-thread-4} SchedulerFactory.java[jobFinished]:120) - Job 20171030-185922_914672286 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:04:11,598] ({qtp89387388-65} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:04:11,651] ({pool-2-thread-12} SchedulerFactory.java[jobStarted]:114) - Job 20161107-030549_2115288931 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:04:11,652] ({pool-2-thread-12} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20161107-030549_2115288931, interpreter: pyspark, note_id: 2FP7CYTB9, user: anonymous]
 WARN [2020-10-30 20:04:11,842] ({pool-2-thread-12} NotebookServer.java[afterStatusChange]:2316) - Job 20161107-030549_2115288931 is finished, status: ERROR, exception: null, result: %text Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 70.0 failed 1 times, most recent failure: Lost task 0.0 in stage 70.0 (TID 511, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py", line 177, in main
    process()
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py", line 172, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/rdd.py", line 1339, in takeUpToNumLeft
TypeError: <lambda>() missing 1 required positional argument: 'y'

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2069)
	at org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:455)
	at org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:214)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py", line 177, in main
    process()
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py", line 172, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/rdd.py", line 1339, in takeUpToNumLeft
TypeError: <lambda>() missing 1 required positional argument: 'y'

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	... 1 more

(<class 'py4j.protocol.Py4JJavaError'>, Py4JJavaError('An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n', JavaObject id=o290), <traceback object at 0x7fdafb285688>)
 INFO [2020-10-30 20:04:11,914] ({pool-2-thread-12} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:04:11,973] ({pool-2-thread-12} SchedulerFactory.java[jobFinished]:120) - Job 20161107-030549_2115288931 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:05:39,616] ({qtp89387388-20} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:05:39,752] ({qtp89387388-20} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:05:39,815] ({pool-2-thread-7} SchedulerFactory.java[jobStarted]:114) - Job 20161102-154506_492289084 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:05:39,817] ({pool-2-thread-7} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20161102-154506_492289084, interpreter: pyspark, note_id: 2FP7CYTB9, user: anonymous]
 INFO [2020-10-30 20:05:39,834] ({pool-2-thread-7} NotebookServer.java[afterStatusChange]:2314) - Job 20161102-154506_492289084 is finished successfully, status: FINISHED
 INFO [2020-10-30 20:05:39,896] ({pool-2-thread-7} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:05:39,944] ({pool-2-thread-7} SchedulerFactory.java[jobFinished]:120) - Job 20161102-154506_492289084 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:05:45,597] ({qtp89387388-75} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:05:45,649] ({pool-2-thread-13} SchedulerFactory.java[jobStarted]:114) - Job 20171030-173939_397652020 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:05:45,650] ({pool-2-thread-13} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20171030-173939_397652020, interpreter: pyspark, note_id: 2FP7CYTB9, user: anonymous]
 WARN [2020-10-30 20:05:45,886] ({pool-2-thread-13} NotebookServer.java[afterStatusChange]:2316) - Job 20171030-173939_397652020 is finished, status: ERROR, exception: null, result: %text Fail to execute line 1: plot_classification(trainFeaturized)
Traceback (most recent call last):
  File "/tmp/zeppelin_pyspark-22800890596813490.py", line 380, in <module>
    exec(code, _zcUserQueryNameSpace)
  File "<stdin>", line 1, in <module>
  File "<stdin>", line 60, in plot_classification
  File "<stdin>", line 16, in show
AttributeError: type object '_io.StringIO' has no attribute 'StringIO'

 INFO [2020-10-30 20:05:45,962] ({pool-2-thread-13} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:05:46,011] ({pool-2-thread-13} SchedulerFactory.java[jobFinished]:120) - Job 20171030-173939_397652020 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:06:12,124] ({qtp89387388-25} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:06:12,239] ({qtp89387388-25} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:06:12,289] ({pool-2-thread-3} SchedulerFactory.java[jobStarted]:114) - Job 20161102-154506_492289084 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:06:12,289] ({pool-2-thread-3} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20161102-154506_492289084, interpreter: pyspark, note_id: 2FP7CYTB9, user: anonymous]
 WARN [2020-10-30 20:06:12,297] ({pool-2-thread-3} NotebookServer.java[afterStatusChange]:2316) - Job 20161102-154506_492289084 is finished, status: ERROR, exception: null, result: %text Fail to execute line 1: import StringIO
Traceback (most recent call last):
  File "/tmp/zeppelin_pyspark-22800890596813490.py", line 375, in <module>
    exec(code, _zcUserQueryNameSpace)
  File "<stdin>", line 1, in <module>
ModuleNotFoundError: No module named 'StringIO'

 INFO [2020-10-30 20:06:12,356] ({pool-2-thread-3} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:06:12,403] ({pool-2-thread-3} SchedulerFactory.java[jobFinished]:120) - Job 20161102-154506_492289084 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:06:57,242] ({qtp89387388-25} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:06:57,358] ({qtp89387388-25} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:06:57,407] ({pool-2-thread-14} SchedulerFactory.java[jobStarted]:114) - Job 20161102-154506_492289084 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:06:57,408] ({pool-2-thread-14} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20161102-154506_492289084, interpreter: pyspark, note_id: 2FP7CYTB9, user: anonymous]
 INFO [2020-10-30 20:06:57,693] ({pool-2-thread-14} NotebookServer.java[afterStatusChange]:2314) - Job 20161102-154506_492289084 is finished successfully, status: FINISHED
 INFO [2020-10-30 20:06:57,771] ({pool-2-thread-14} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:06:57,827] ({pool-2-thread-14} SchedulerFactory.java[jobFinished]:120) - Job 20161102-154506_492289084 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:07:28,573] ({qtp89387388-69} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:07:29,601] ({qtp89387388-94} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:07:29,665] ({pool-2-thread-8} SchedulerFactory.java[jobStarted]:114) - Job 20161102-154506_492289084 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:07:29,667] ({pool-2-thread-8} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20161102-154506_492289084, interpreter: pyspark, note_id: 2FP7CYTB9, user: anonymous]
 INFO [2020-10-30 20:07:29,677] ({pool-2-thread-8} NotebookServer.java[afterStatusChange]:2314) - Job 20161102-154506_492289084 is finished successfully, status: FINISHED
 INFO [2020-10-30 20:07:29,750] ({pool-2-thread-8} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:07:29,800] ({pool-2-thread-8} SchedulerFactory.java[jobFinished]:120) - Job 20161102-154506_492289084 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:07:32,795] ({qtp89387388-94} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:07:32,841] ({pool-2-thread-15} SchedulerFactory.java[jobStarted]:114) - Job 20171030-173939_397652020 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:07:32,842] ({pool-2-thread-15} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20171030-173939_397652020, interpreter: pyspark, note_id: 2FP7CYTB9, user: anonymous]
 WARN [2020-10-30 20:07:32,997] ({pool-2-thread-15} NotebookServer.java[afterStatusChange]:2316) - Job 20171030-173939_397652020 is finished, status: ERROR, exception: null, result: %text Fail to execute line 1: plot_classification(trainFeaturized)
Traceback (most recent call last):
  File "/tmp/zeppelin_pyspark-22800890596813490.py", line 380, in <module>
    exec(code, _zcUserQueryNameSpace)
  File "<stdin>", line 1, in <module>
  File "<stdin>", line 60, in plot_classification
  File "<stdin>", line 16, in show
AttributeError: type object '_io.StringIO' has no attribute 'StringIO'

 INFO [2020-10-30 20:07:33,071] ({pool-2-thread-15} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:07:33,119] ({pool-2-thread-15} SchedulerFactory.java[jobFinished]:120) - Job 20171030-173939_397652020 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:09:13,202] ({qtp89387388-586} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:09:13,257] ({pool-2-thread-5} SchedulerFactory.java[jobStarted]:114) - Job 20161102-154506_492289084 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:09:13,257] ({pool-2-thread-5} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20161102-154506_492289084, interpreter: pyspark, note_id: 2FP7CYTB9, user: anonymous]
 INFO [2020-10-30 20:09:13,548] ({pool-2-thread-5} NotebookServer.java[afterStatusChange]:2314) - Job 20161102-154506_492289084 is finished successfully, status: FINISHED
 INFO [2020-10-30 20:09:13,686] ({pool-2-thread-5} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:09:13,771] ({pool-2-thread-5} SchedulerFactory.java[jobFinished]:120) - Job 20161102-154506_492289084 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:09:21,149] ({qtp89387388-586} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:09:21,209] ({pool-2-thread-16} SchedulerFactory.java[jobStarted]:114) - Job 20171030-173939_397652020 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:09:21,212] ({pool-2-thread-16} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20171030-173939_397652020, interpreter: pyspark, note_id: 2FP7CYTB9, user: anonymous]
 INFO [2020-10-30 20:09:38,039] ({qtp89387388-586} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:09:38,102] ({pool-2-thread-9} SchedulerFactory.java[jobStarted]:114) - Job 20161107-153258_1183600330 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:09:38,104] ({pool-2-thread-9} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20161107-153258_1183600330, interpreter: pyspark, note_id: 2FP7CYTB9, user: anonymous]
 INFO [2020-10-30 20:16:15,199] ({qtp89387388-723} NotebookServer.java[onClose]:372) - Closed connection to 127.0.0.1 : 51380. (1001) null
 WARN [2020-10-30 20:16:15,592] ({qtp89387388-723} SecurityRestApi.java[ticket]:88) - {"status":"OK","message":"","body":{"principal":"anonymous","ticket":"anonymous","roles":"[]"}}
 INFO [2020-10-30 20:16:15,739] ({qtp89387388-71} NotebookServer.java[onOpen]:151) - New connection from 127.0.0.1 : 52090
 INFO [2020-10-30 20:16:15,863] ({qtp89387388-93} NotebookServer.java[sendNote]:828) - New operation from 127.0.0.1 : 52090 : anonymous : GET_NOTE : 2FP7CYTB9
 WARN [2020-10-30 20:16:16,106] ({qtp89387388-93} GitNotebookRepo.java[revisionHistory]:158) - No Head found for 2FP7CYTB9, No HEAD exists and no explicit starting revision was specified
 WARN [2020-10-30 20:16:19,902] ({qtp89387388-25} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 20:16:19,903] ({qtp89387388-25} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 20:16:19,903] ({qtp89387388-25} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 20:16:19,904] ({qtp89387388-25} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 20:16:19,904] ({qtp89387388-25} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 20:16:19,904] ({qtp89387388-25} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 INFO [2020-10-30 20:16:38,181] ({Thread-39} ZeppelinServer.java[run]:253) - Shutting down Zeppelin Server ... 
 INFO [2020-10-30 20:16:38,192] ({qtp89387388-731} NotebookServer.java[onClose]:372) - Closed connection to 127.0.0.1 : 52090. (1006) Disconnected
 INFO [2020-10-30 20:16:38,193] ({Thread-39} AbstractConnector.java[doStop]:341) - Stopped ServerConnector@39e69ea7{HTTP/1.1,[http/1.1]}{127.0.0.1:9322}
 INFO [2020-10-30 20:16:38,193] ({Thread-39} HouseKeeper.java[stopScavenging]:167) - node0 Stopped scavenging
ERROR [2020-10-30 20:16:38,648] ({pool-2-thread-9} Job.java[run]:190) - Job failed
java.lang.RuntimeException: org.apache.thrift.transport.TTransportException
	at org.apache.zeppelin.interpreter.remote.RemoteInterpreterProcess.callRemoteFunction(RemoteInterpreterProcess.java:139)
	at org.apache.zeppelin.interpreter.remote.RemoteInterpreter.interpret(RemoteInterpreter.java:228)
	at org.apache.zeppelin.notebook.Paragraph.jobRun(Paragraph.java:449)
	at org.apache.zeppelin.scheduler.Job.run(Job.java:188)
	at org.apache.zeppelin.scheduler.RemoteScheduler$JobRunner.run(RemoteScheduler.java:315)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.thrift.transport.TTransportException
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:69)
	at org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Client.recv_interpret(RemoteInterpreterService.java:274)
	at org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Client.interpret(RemoteInterpreterService.java:258)
	at org.apache.zeppelin.interpreter.remote.RemoteInterpreter$4.call(RemoteInterpreter.java:233)
	at org.apache.zeppelin.interpreter.remote.RemoteInterpreter$4.call(RemoteInterpreter.java:229)
	at org.apache.zeppelin.interpreter.remote.RemoteInterpreterProcess.callRemoteFunction(RemoteInterpreterProcess.java:135)
	... 11 more
ERROR [2020-10-30 20:16:38,648] ({pool-2-thread-16} Job.java[run]:190) - Job failed
java.lang.RuntimeException: org.apache.thrift.transport.TTransportException
	at org.apache.zeppelin.interpreter.remote.RemoteInterpreterProcess.callRemoteFunction(RemoteInterpreterProcess.java:139)
	at org.apache.zeppelin.interpreter.remote.RemoteInterpreter.interpret(RemoteInterpreter.java:228)
	at org.apache.zeppelin.notebook.Paragraph.jobRun(Paragraph.java:449)
	at org.apache.zeppelin.scheduler.Job.run(Job.java:188)
	at org.apache.zeppelin.scheduler.RemoteScheduler$JobRunner.run(RemoteScheduler.java:315)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.thrift.transport.TTransportException
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:69)
	at org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Client.recv_interpret(RemoteInterpreterService.java:274)
	at org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Client.interpret(RemoteInterpreterService.java:258)
	at org.apache.zeppelin.interpreter.remote.RemoteInterpreter$4.call(RemoteInterpreter.java:233)
	at org.apache.zeppelin.interpreter.remote.RemoteInterpreter$4.call(RemoteInterpreter.java:229)
	at org.apache.zeppelin.interpreter.remote.RemoteInterpreterProcess.callRemoteFunction(RemoteInterpreterProcess.java:135)
	... 11 more
 INFO [2020-10-30 20:16:38,648] ({Exec Default Executor} RemoteInterpreterManagedProcess.java[onProcessFailed]:250) - Interpreter process failed {}
org.apache.commons.exec.ExecuteException: Process exited with an error: 130 (Exit value: 130)
	at org.apache.commons.exec.DefaultExecutor.executeInternal(DefaultExecutor.java:404)
	at org.apache.commons.exec.DefaultExecutor.access$200(DefaultExecutor.java:48)
	at org.apache.commons.exec.DefaultExecutor$1.run(DefaultExecutor.java:200)
	at java.lang.Thread.run(Thread.java:745)
ERROR [2020-10-30 20:16:38,654] ({JobProgressPoller, jobId=20171030-173939_397652020} JobProgressPoller.java[run]:58) - Can not get or update progress
java.lang.RuntimeException: org.apache.thrift.transport.TTransportException: java.net.SocketException: Broken pipe (Write failed)
	at org.apache.zeppelin.interpreter.remote.RemoteInterpreterProcess.callRemoteFunction(RemoteInterpreterProcess.java:139)
	at org.apache.zeppelin.interpreter.remote.RemoteInterpreter.getProgress(RemoteInterpreter.java:334)
	at org.apache.zeppelin.notebook.Paragraph.progress(Paragraph.java:315)
	at org.apache.zeppelin.scheduler.JobProgressPoller.run(JobProgressPoller.java:55)
Caused by: org.apache.thrift.transport.TTransportException: java.net.SocketException: Broken pipe (Write failed)
	at org.apache.thrift.transport.TIOStreamTransport.write(TIOStreamTransport.java:147)
	at org.apache.thrift.protocol.TBinaryProtocol.writeString(TBinaryProtocol.java:202)
	at org.apache.zeppelin.interpreter.thrift.RemoteInterpreterContext$RemoteInterpreterContextStandardScheme.write(RemoteInterpreterContext.java:1228)
	at org.apache.zeppelin.interpreter.thrift.RemoteInterpreterContext$RemoteInterpreterContextStandardScheme.write(RemoteInterpreterContext.java:1074)
	at org.apache.zeppelin.interpreter.thrift.RemoteInterpreterContext.write(RemoteInterpreterContext.java:956)
	at org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$getProgress_args$getProgress_argsStandardScheme.write(RemoteInterpreterService.java:8557)
	at org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$getProgress_args$getProgress_argsStandardScheme.write(RemoteInterpreterService.java:8493)
	at org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$getProgress_args.write(RemoteInterpreterService.java:8428)
	at org.apache.thrift.TServiceClient.sendBase(TServiceClient.java:63)
	at org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Client.send_getProgress(RemoteInterpreterService.java:315)
	at org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Client.getProgress(RemoteInterpreterService.java:305)
	at org.apache.zeppelin.interpreter.remote.RemoteInterpreter$7.call(RemoteInterpreter.java:338)
	at org.apache.zeppelin.interpreter.remote.RemoteInterpreter$7.call(RemoteInterpreter.java:335)
	at org.apache.zeppelin.interpreter.remote.RemoteInterpreterProcess.callRemoteFunction(RemoteInterpreterProcess.java:135)
	... 3 more
Caused by: java.net.SocketException: Broken pipe (Write failed)
	at java.net.SocketOutputStream.socketWrite0(Native Method)
	at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:111)
	at java.net.SocketOutputStream.write(SocketOutputStream.java:155)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at org.apache.thrift.transport.TIOStreamTransport.write(TIOStreamTransport.java:145)
	... 16 more
ERROR [2020-10-30 20:16:38,655] ({pool-2-thread-9} NotebookServer.java[afterStatusChange]:2308) - Error
java.lang.RuntimeException: org.apache.thrift.transport.TTransportException
	at org.apache.zeppelin.interpreter.remote.RemoteInterpreterProcess.callRemoteFunction(RemoteInterpreterProcess.java:139)
	at org.apache.zeppelin.interpreter.remote.RemoteInterpreter.interpret(RemoteInterpreter.java:228)
	at org.apache.zeppelin.notebook.Paragraph.jobRun(Paragraph.java:449)
	at org.apache.zeppelin.scheduler.Job.run(Job.java:188)
	at org.apache.zeppelin.scheduler.RemoteScheduler$JobRunner.run(RemoteScheduler.java:315)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.thrift.transport.TTransportException
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:69)
	at org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Client.recv_interpret(RemoteInterpreterService.java:274)
	at org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Client.interpret(RemoteInterpreterService.java:258)
	at org.apache.zeppelin.interpreter.remote.RemoteInterpreter$4.call(RemoteInterpreter.java:233)
	at org.apache.zeppelin.interpreter.remote.RemoteInterpreter$4.call(RemoteInterpreter.java:229)
	at org.apache.zeppelin.interpreter.remote.RemoteInterpreterProcess.callRemoteFunction(RemoteInterpreterProcess.java:135)
	... 11 more
 WARN [2020-10-30 20:16:38,655] ({pool-2-thread-16} NotebookServer.java[afterStatusChange]:2316) - Job 20171030-173939_397652020 is finished, status: ABORT, exception: java.lang.RuntimeException: org.apache.thrift.transport.TTransportException, result: %text org.apache.thrift.transport.TTransportException
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:69)
	at org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Client.recv_interpret(RemoteInterpreterService.java:274)
	at org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Client.interpret(RemoteInterpreterService.java:258)
	at org.apache.zeppelin.interpreter.remote.RemoteInterpreter$4.call(RemoteInterpreter.java:233)
	at org.apache.zeppelin.interpreter.remote.RemoteInterpreter$4.call(RemoteInterpreter.java:229)
	at org.apache.zeppelin.interpreter.remote.RemoteInterpreterProcess.callRemoteFunction(RemoteInterpreterProcess.java:135)
	at org.apache.zeppelin.interpreter.remote.RemoteInterpreter.interpret(RemoteInterpreter.java:228)
	at org.apache.zeppelin.notebook.Paragraph.jobRun(Paragraph.java:449)
	at org.apache.zeppelin.scheduler.Job.run(Job.java:188)
	at org.apache.zeppelin.scheduler.RemoteScheduler$JobRunner.run(RemoteScheduler.java:315)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

 WARN [2020-10-30 20:16:38,655] ({pool-2-thread-9} NotebookServer.java[afterStatusChange]:2316) - Job 20161107-153258_1183600330 is finished, status: ERROR, exception: java.lang.RuntimeException: org.apache.thrift.transport.TTransportException, result: %text org.apache.thrift.transport.TTransportException
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:69)
	at org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Client.recv_interpret(RemoteInterpreterService.java:274)
	at org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Client.interpret(RemoteInterpreterService.java:258)
	at org.apache.zeppelin.interpreter.remote.RemoteInterpreter$4.call(RemoteInterpreter.java:233)
	at org.apache.zeppelin.interpreter.remote.RemoteInterpreter$4.call(RemoteInterpreter.java:229)
	at org.apache.zeppelin.interpreter.remote.RemoteInterpreterProcess.callRemoteFunction(RemoteInterpreterProcess.java:135)
	at org.apache.zeppelin.interpreter.remote.RemoteInterpreter.interpret(RemoteInterpreter.java:228)
	at org.apache.zeppelin.notebook.Paragraph.jobRun(Paragraph.java:449)
	at org.apache.zeppelin.scheduler.Job.run(Job.java:188)
	at org.apache.zeppelin.scheduler.RemoteScheduler$JobRunner.run(RemoteScheduler.java:315)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

 INFO [2020-10-30 20:16:38,976] ({pool-2-thread-9} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:16:39,024] ({pool-2-thread-16} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:16:39,025] ({pool-2-thread-9} SchedulerFactory.java[jobFinished]:120) - Job 20161107-153258_1183600330 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:16:39,074] ({pool-2-thread-16} SchedulerFactory.java[jobFinished]:120) - Job 20171030-173939_397652020 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:16:40,462] ({Thread-39} ContextHandler.java[doStop]:1045) - Stopped o.e.j.w.WebAppContext@15761df8{zeppelin-web,/,null,UNAVAILABLE}{/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/zeppelin-web-0.8.2.war}
 INFO [2020-10-30 20:16:40,465] ({Thread-641} InterpreterSetting.java[close]:483) - Close InterpreterSetting: ignite
 INFO [2020-10-30 20:16:40,465] ({Thread-643} InterpreterSetting.java[close]:483) - Close InterpreterSetting: python
 INFO [2020-10-30 20:16:40,466] ({Thread-642} InterpreterSetting.java[close]:483) - Close InterpreterSetting: ignite
 INFO [2020-10-30 20:16:40,466] ({Thread-644} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sap
 INFO [2020-10-30 20:16:40,466] ({Thread-646} InterpreterSetting.java[close]:483) - Close InterpreterSetting: jdbc
 INFO [2020-10-30 20:16:40,467] ({Thread-650} InterpreterSetting.java[close]:483) - Close InterpreterSetting: angular
 INFO [2020-10-30 20:16:40,467] ({Thread-652} InterpreterSetting.java[close]:483) - Close InterpreterSetting: groovy
 INFO [2020-10-30 20:16:40,466] ({Thread-647} InterpreterSetting.java[close]:483) - Close InterpreterSetting: lens
 INFO [2020-10-30 20:16:40,467] ({Thread-648} InterpreterSetting.java[close]:483) - Close InterpreterSetting: pig
 INFO [2020-10-30 20:16:40,467] ({Thread-649} InterpreterSetting.java[close]:483) - Close InterpreterSetting: flink
 INFO [2020-10-30 20:16:40,469] ({Thread-657} InterpreterSetting.java[close]:483) - Close InterpreterSetting: jdbc
 INFO [2020-10-30 20:16:40,469] ({Thread-660} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sh
 INFO [2020-10-30 20:16:40,469] ({Thread-659} InterpreterSetting.java[close]:483) - Close InterpreterSetting: cassandra
 INFO [2020-10-30 20:16:40,471] ({Thread-665} InterpreterSetting.java[close]:483) - Close InterpreterSetting: alluxio
 INFO [2020-10-30 20:16:40,468] ({Thread-654} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sap
 INFO [2020-10-30 20:16:40,468] ({Thread-656} InterpreterSetting.java[close]:483) - Close InterpreterSetting: elasticsearch
 INFO [2020-10-30 20:16:40,468] ({Thread-658} InterpreterSetting.java[close]:483) - Close InterpreterSetting: spark
 INFO [2020-10-30 20:16:40,468] ({Thread-655} InterpreterSetting.java[close]:483) - Close InterpreterSetting: file
 INFO [2020-10-30 20:16:40,472] ({Thread-672} InterpreterSetting.java[close]:483) - Close InterpreterSetting: neo4j
 INFO [2020-10-30 20:16:40,468] ({Thread-653} InterpreterSetting.java[close]:483) - Close InterpreterSetting: neo4j
 INFO [2020-10-30 20:16:40,473] ({Thread-676} InterpreterSetting.java[close]:483) - Close InterpreterSetting: cassandra
 INFO [2020-10-30 20:16:40,474] ({Thread-677} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sh
 INFO [2020-10-30 20:16:40,467] ({Thread-645} InterpreterSetting.java[close]:483) - Close InterpreterSetting: python
 INFO [2020-10-30 20:16:40,467] ({Thread-651} InterpreterSetting.java[close]:483) - Close InterpreterSetting: livy
 INFO [2020-10-30 20:16:40,474] ({Thread-680} InterpreterSetting.java[close]:483) - Close InterpreterSetting: bigquery
 INFO [2020-10-30 20:16:40,474] ({Thread-679} InterpreterSetting.java[close]:483) - Close InterpreterSetting: alluxio
 INFO [2020-10-30 20:16:40,474] ({Thread-678} InterpreterSetting.java[close]:483) - Close InterpreterSetting: md
 INFO [2020-10-30 20:16:40,473] ({Thread-675} InterpreterSetting.java[close]:483) - Close InterpreterSetting: spark
 INFO [2020-10-30 20:16:40,473] ({Thread-674} InterpreterSetting.java[close]:483) - Close InterpreterSetting: elasticsearch
 INFO [2020-10-30 20:16:40,472] ({Thread-673} InterpreterSetting.java[close]:483) - Close InterpreterSetting: file
 INFO [2020-10-30 20:16:40,472] ({Thread-669} InterpreterSetting.java[close]:483) - Close InterpreterSetting: kylin
 INFO [2020-10-30 20:16:40,472] ({Thread-658} ManagedInterpreterGroup.java[close]:89) - Close InterpreterGroup: spark:shared_process
 INFO [2020-10-30 20:16:40,472] ({Thread-671} InterpreterSetting.java[close]:483) - Close InterpreterSetting: groovy
 INFO [2020-10-30 20:16:40,472] ({Thread-670} InterpreterSetting.java[close]:483) - Close InterpreterSetting: livy
 INFO [2020-10-30 20:16:40,471] ({Thread-666} InterpreterSetting.java[close]:483) - Close InterpreterSetting: angular
 INFO [2020-10-30 20:16:40,471] ({Thread-668} InterpreterSetting.java[close]:483) - Close InterpreterSetting: hbase
 INFO [2020-10-30 20:16:40,471] ({Thread-667} InterpreterSetting.java[close]:483) - Close InterpreterSetting: bigquery
 INFO [2020-10-30 20:16:40,471] ({Thread-664} InterpreterSetting.java[close]:483) - Close InterpreterSetting: flink
 INFO [2020-10-30 20:16:40,470] ({Thread-661} InterpreterSetting.java[close]:483) - Close InterpreterSetting: md
 INFO [2020-10-30 20:16:40,470] ({Thread-663} InterpreterSetting.java[close]:483) - Close InterpreterSetting: pig
 INFO [2020-10-30 20:16:40,469] ({Thread-662} InterpreterSetting.java[close]:483) - Close InterpreterSetting: lens
 INFO [2020-10-30 20:16:40,475] ({Thread-658} ManagedInterpreterGroup.java[close]:100) - Close Session: shared_session for interpreter setting: spark
 INFO [2020-10-30 20:16:40,475] ({Thread-678} ManagedInterpreterGroup.java[close]:89) - Close InterpreterGroup: md:shared_process
 INFO [2020-10-30 20:16:40,474] ({Thread-682} InterpreterSetting.java[close]:483) - Close InterpreterSetting: kylin
 INFO [2020-10-30 20:16:40,474] ({Thread-681} InterpreterSetting.java[close]:483) - Close InterpreterSetting: hbase
 WARN [2020-10-30 20:16:40,477] ({Thread-658} RemoteInterpreter.java[close]:199) - close is called when RemoterInterpreter is not opened for org.apache.zeppelin.spark.SparkInterpreter
 INFO [2020-10-30 20:16:40,477] ({Thread-678} ManagedInterpreterGroup.java[close]:100) - Close Session: shared_session for interpreter setting: md
 WARN [2020-10-30 20:16:40,478] ({Thread-658} RemoteInterpreter.java[close]:199) - close is called when RemoterInterpreter is not opened for org.apache.zeppelin.spark.SparkSqlInterpreter
 WARN [2020-10-30 20:16:40,478] ({Thread-678} RemoteInterpreter.java[close]:199) - close is called when RemoterInterpreter is not opened for org.apache.zeppelin.markdown.Markdown
 WARN [2020-10-30 20:16:40,479] ({Thread-658} RemoteInterpreter.java[close]:199) - close is called when RemoterInterpreter is not opened for org.apache.zeppelin.spark.DepInterpreter
 INFO [2020-10-30 20:16:40,480] ({Thread-678} ManagedInterpreterGroup.java[close]:105) - Remove this InterpreterGroup: md:shared_process as all the sessions are closed
 INFO [2020-10-30 20:16:40,480] ({Thread-661} ManagedInterpreterGroup.java[close]:89) - Close InterpreterGroup: md:shared_process
 INFO [2020-10-30 20:16:40,487] ({Thread-675} ManagedInterpreterGroup.java[close]:89) - Close InterpreterGroup: spark:shared_process
 INFO [2020-10-30 20:16:40,488] ({Thread-39} NotebookRepoSync.java[close]:428) - Closing all notebook storages
 INFO [2020-10-30 20:16:43,495] ({Thread-39} ZeppelinServer.java[run]:264) - Bye
 INFO [2020-10-30 20:16:44,982] ({main} ZeppelinConfiguration.java[create]:121) - Load configuration from file:/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/zeppelin-site.xml
 WARN [2020-10-30 20:16:45,041] ({main} ZeppelinConfiguration.java[create]:124) - Failed to load configuration from file:/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/zeppelin-site.xml proceeding with a default
org.apache.commons.configuration.ConfigurationException: Error parsing file:/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/zeppelin-site.xml
	at org.apache.commons.configuration.XMLConfiguration.load(XMLConfiguration.java:950)
	at org.apache.commons.configuration.XMLConfiguration.load(XMLConfiguration.java:908)
	at org.apache.commons.configuration.XMLConfiguration$XMLFileConfigurationDelegate.load(XMLConfiguration.java:1583)
	at org.apache.commons.configuration.AbstractFileConfiguration.load(AbstractFileConfiguration.java:324)
	at org.apache.commons.configuration.AbstractHierarchicalFileConfiguration.load(AbstractHierarchicalFileConfiguration.java:199)
	at org.apache.zeppelin.conf.ZeppelinConfiguration.<init>(ZeppelinConfiguration.java:52)
	at org.apache.zeppelin.conf.ZeppelinConfiguration.create(ZeppelinConfiguration.java:122)
	at org.apache.zeppelin.server.ZeppelinServer.main(ZeppelinServer.java:219)
Caused by: org.xml.sax.SAXParseException; systemId: file:/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/zeppelin-site.xml; lineNumber: 1; columnNumber: 1; Premature end of file.
	at com.sun.org.apache.xerces.internal.parsers.DOMParser.parse(DOMParser.java:257)
	at com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderImpl.parse(DocumentBuilderImpl.java:339)
	at org.apache.commons.configuration.XMLConfiguration.load(XMLConfiguration.java:942)
	... 7 more
 INFO [2020-10-30 20:16:45,065] ({main} ZeppelinConfiguration.java[create]:129) - Server Host: 127.0.0.1
 INFO [2020-10-30 20:16:45,065] ({main} ZeppelinConfiguration.java[create]:131) - Server Port: 9322
 INFO [2020-10-30 20:16:45,065] ({main} ZeppelinConfiguration.java[create]:135) - Context Path: /
 INFO [2020-10-30 20:16:45,066] ({main} ZeppelinConfiguration.java[create]:136) - Zeppelin Version: 0.8.2
 INFO [2020-10-30 20:16:45,088] ({main} Log.java[initialized]:193) - Logging initialized @496ms to org.eclipse.jetty.util.log.Slf4jLog
 WARN [2020-10-30 20:16:45,204] ({main} ServerConnector.java[setSoLingerTime]:458) - Ignoring deprecated socket close linger time
 INFO [2020-10-30 20:16:45,262] ({main} ZeppelinServer.java[setupWebAppContext]:413) - ZeppelinServer Webapp path: /users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/webapps
 INFO [2020-10-30 20:16:45,349] ({main} ZeppelinServer.java[main]:239) - Starting zeppelin server
 INFO [2020-10-30 20:16:45,350] ({main} Server.java[doStart]:370) - jetty-9.4.14.v20181114; built: 2018-11-14T21:20:31.478Z; git: c4550056e785fb5665914545889f21dc136ad9e6; jvm 1.8.0_152-release-1056-b12
 INFO [2020-10-30 20:16:50,631] ({main} StandardDescriptorProcessor.java[visitServlet]:283) - NO JSP Support for /, did not find org.eclipse.jetty.jsp.JettyJspServlet
 INFO [2020-10-30 20:16:50,650] ({main} DefaultSessionIdManager.java[doStart]:365) - DefaultSessionIdManager workerName=node0
 INFO [2020-10-30 20:16:50,651] ({main} DefaultSessionIdManager.java[doStart]:370) - No SessionScavenger set, using defaults
 INFO [2020-10-30 20:16:50,654] ({main} HouseKeeper.java[startScavenging]:149) - node0 Scavenging every 600000ms
 INFO [2020-10-30 20:16:51,033] ({main} SchedulerFactory.java[<init>]:59) - Scheduler Thread Pool Size: 100
 WARN [2020-10-30 20:16:51,049] ({main} ZeppelinConfiguration.java[getConfigFSDir]:527) - zeppelin.config.fs.dir is not specified, fall back to local conf directory zeppelin.conf.dir
 WARN [2020-10-30 20:16:51,050] ({main} ZeppelinConfiguration.java[getConfigFSDir]:527) - zeppelin.config.fs.dir is not specified, fall back to local conf directory zeppelin.conf.dir
 INFO [2020-10-30 20:16:51,163] ({main} InterpreterSettingManager.java[<init>]:165) - Using RecoveryStorage: org.apache.zeppelin.interpreter.recovery.NullRecoveryStorage
 INFO [2020-10-30 20:16:51,164] ({main} InterpreterSettingManager.java[<init>]:169) - Using LifecycleManager: org.apache.zeppelin.interpreter.lifecycle.NullLifecycleManager
 INFO [2020-10-30 20:16:51,197] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: cassandra
 WARN [2020-10-30 20:16:51,203] ({main} InterpreterSettingManager.java[init]:331) - No interpreter-setting.json found in /users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/${interpreter.name}
 INFO [2020-10-30 20:16:51,213] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: angular
 INFO [2020-10-30 20:16:51,216] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: md
 INFO [2020-10-30 20:16:51,218] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: alluxio
 INFO [2020-10-30 20:16:51,221] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: groovy
 INFO [2020-10-30 20:16:51,224] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: pig
 INFO [2020-10-30 20:16:51,227] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: file
 INFO [2020-10-30 20:16:51,229] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: elasticsearch
 INFO [2020-10-30 20:16:51,232] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: lens
 INFO [2020-10-30 20:16:51,235] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: kylin
 INFO [2020-10-30 20:16:51,238] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: sap
 INFO [2020-10-30 20:16:51,241] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: ignite
 INFO [2020-10-30 20:16:51,247] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: neo4j
 INFO [2020-10-30 20:16:51,250] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: python
 INFO [2020-10-30 20:16:51,252] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: bigquery
 WARN [2020-10-30 20:16:51,371] ({main} InterpreterSettingManager.java[init]:331) - No interpreter-setting.json found in /users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/scio
 INFO [2020-10-30 20:16:51,375] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: spark
 INFO [2020-10-30 20:16:51,378] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: livy
 WARN [2020-10-30 20:16:51,381] ({main} InterpreterSettingManager.java[init]:331) - No interpreter-setting.json found in /users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/lib
 INFO [2020-10-30 20:16:51,383] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: sh
 INFO [2020-10-30 20:16:51,384] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: flink
 INFO [2020-10-30 20:16:51,386] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: hbase
 INFO [2020-10-30 20:16:51,388] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: jdbc
 INFO [2020-10-30 20:16:51,389] ({main} LocalConfigStorage.java[loadInterpreterSettings]:63) - Load Interpreter Setting from file: /users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/conf/interpreter.json
 INFO [2020-10-30 20:16:51,441] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting ignite from interpreter.json
 INFO [2020-10-30 20:16:51,441] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting python from interpreter.json
 INFO [2020-10-30 20:16:51,442] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting sap from interpreter.json
 INFO [2020-10-30 20:16:51,444] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting jdbc from interpreter.json
 INFO [2020-10-30 20:16:51,444] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting lens from interpreter.json
 INFO [2020-10-30 20:16:51,445] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting pig from interpreter.json
 INFO [2020-10-30 20:16:51,445] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting flink from interpreter.json
 INFO [2020-10-30 20:16:51,446] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting angular from interpreter.json
 INFO [2020-10-30 20:16:51,447] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting livy from interpreter.json
 INFO [2020-10-30 20:16:51,448] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting groovy from interpreter.json
 INFO [2020-10-30 20:16:51,448] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting neo4j from interpreter.json
 INFO [2020-10-30 20:16:51,448] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting file from interpreter.json
 INFO [2020-10-30 20:16:51,449] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting elasticsearch from interpreter.json
 INFO [2020-10-30 20:16:51,450] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting spark from interpreter.json
 INFO [2020-10-30 20:16:51,451] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting cassandra from interpreter.json
 INFO [2020-10-30 20:16:51,452] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting sh from interpreter.json
 INFO [2020-10-30 20:16:51,452] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting md from interpreter.json
 INFO [2020-10-30 20:16:51,453] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting alluxio from interpreter.json
 INFO [2020-10-30 20:16:51,453] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting bigquery from interpreter.json
 INFO [2020-10-30 20:16:51,453] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting hbase from interpreter.json
 INFO [2020-10-30 20:16:51,454] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting kylin from interpreter.json
 INFO [2020-10-30 20:16:51,462] ({main} LocalConfigStorage.java[save]:53) - Save Interpreter Setting to /users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/conf/interpreter.json
 INFO [2020-10-30 20:16:51,633] ({main} VfsLog.java[info]:138) - Using "/tmp/vfs_cache" as temporary files store.
 INFO [2020-10-30 20:16:51,684] ({main} GitNotebookRepo.java[<init>]:64) - Opening a git repo at '/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/notebook'
 INFO [2020-10-30 20:16:51,758] ({main} NotebookRepoSync.java[<init>]:77) - Instantiate NotebookRepo: org.apache.zeppelin.notebook.repo.GitNotebookRepo
 WARN [2020-10-30 20:16:51,875] ({main} NotebookAuthorization.java[getInstance]:86) - Notebook authorization module was called without initialization, initializing with default configuration
 INFO [2020-10-30 20:16:51,875] ({main} LocalConfigStorage.java[loadNotebookAuthorization]:80) - Load notebook authorization from file: /users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/conf/notebook-authorization.json
 INFO [2020-10-30 20:16:51,877] ({main} Credentials.java[loadFromFile]:121) - /users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/conf/credentials.json
 INFO [2020-10-30 20:16:51,912] ({main} StdSchedulerFactory.java[instantiate]:1184) - Using default implementation for ThreadExecutor
 INFO [2020-10-30 20:16:51,915] ({main} SimpleThreadPool.java[initialize]:268) - Job execution threads will use class loader of thread: main
 INFO [2020-10-30 20:16:51,927] ({main} SchedulerSignalerImpl.java[<init>]:61) - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
 INFO [2020-10-30 20:16:51,928] ({main} QuartzScheduler.java[<init>]:240) - Quartz Scheduler v.2.2.1 created.
 INFO [2020-10-30 20:16:51,929] ({main} RAMJobStore.java[initialize]:155) - RAMJobStore initialized.
 INFO [2020-10-30 20:16:51,930] ({main} QuartzScheduler.java[initialize]:305) - Scheduler meta-data: Quartz Scheduler (v2.2.1) 'DefaultQuartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

 INFO [2020-10-30 20:16:51,930] ({main} StdSchedulerFactory.java[instantiate]:1339) - Quartz scheduler 'DefaultQuartzScheduler' initialized from default resource file in Quartz package: 'quartz.properties'
 INFO [2020-10-30 20:16:51,930] ({main} StdSchedulerFactory.java[instantiate]:1343) - Quartz scheduler version: 2.2.1
 INFO [2020-10-30 20:16:51,931] ({main} QuartzScheduler.java[start]:575) - Scheduler DefaultQuartzScheduler_$_NON_CLUSTERED started.
 INFO [2020-10-30 20:16:52,385] ({main} FolderView.java[createFolder]:107) - Create folder Zeppelin Tutorial
 INFO [2020-10-30 20:16:52,385] ({main} FolderView.java[createFolder]:107) - Create folder /
 INFO [2020-10-30 20:16:52,386] ({main} Folder.java[setParent]:169) - Set parent of / to /
 INFO [2020-10-30 20:16:52,386] ({main} Folder.java[setParent]:169) - Set parent of Zeppelin Tutorial to /
 INFO [2020-10-30 20:16:52,386] ({main} Folder.java[addNote]:185) - Add note 2A94M5J1Z to folder Zeppelin Tutorial
 WARN [2020-10-30 20:16:52,387] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 20:16:52,396] ({main} Folder.java[addNote]:185) - Add note 2BWJFTXKJ to folder Zeppelin Tutorial
 WARN [2020-10-30 20:16:52,398] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 20:16:52,406] ({main} FolderView.java[createFolder]:107) - Create folder Diplodatos
 INFO [2020-10-30 20:16:52,406] ({main} Folder.java[setParent]:169) - Set parent of Diplodatos to /
 INFO [2020-10-30 20:16:52,406] ({main} Folder.java[addNote]:185) - Add note 2FMXBM6HK to folder Diplodatos
 WARN [2020-10-30 20:16:52,407] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 20:16:52,412] ({main} Folder.java[addNote]:185) - Add note 2FNG3ZFM5 to folder Diplodatos
 WARN [2020-10-30 20:16:52,412] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 20:16:52,423] ({main} Folder.java[addNote]:185) - Add note 2FP83VA8P to folder Diplodatos
 WARN [2020-10-30 20:16:52,424] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 20:16:52,431] ({main} Folder.java[addNote]:185) - Add note 2FQA9JFA8 to folder Diplodatos
 WARN [2020-10-30 20:16:52,431] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 20:16:52,441] ({main} Folder.java[addNote]:185) - Add note 2FRXGF37P to folder Diplodatos
 WARN [2020-10-30 20:16:52,442] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 20:16:52,447] ({main} Folder.java[addNote]:185) - Add note 2FPTJC7P4 to folder Diplodatos
 WARN [2020-10-30 20:16:52,448] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 20:16:52,452] ({main} Folder.java[addNote]:185) - Add note 2C2AUG798 to folder Zeppelin Tutorial
 WARN [2020-10-30 20:16:52,453] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 20:16:52,455] ({main} Folder.java[addNote]:185) - Add note 2C57UKYWR to folder Zeppelin Tutorial
 WARN [2020-10-30 20:16:52,455] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 20:16:52,527] ({main} Folder.java[addNote]:185) - Add note 2FP7CYTB9 to folder Diplodatos
 WARN [2020-10-30 20:16:52,532] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 20:16:52,547] ({main} Folder.java[addNote]:185) - Add note 2FP1YEJHN to folder Diplodatos
 WARN [2020-10-30 20:16:52,548] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 20:16:52,559] ({main} Folder.java[addNote]:185) - Add note 2BYEZ5EVK to folder Zeppelin Tutorial
 WARN [2020-10-30 20:16:52,560] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 20:16:52,572] ({main} Folder.java[addNote]:185) - Add note 2FNR8STJW to folder Diplodatos
 WARN [2020-10-30 20:16:52,572] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
ERROR [2020-10-30 20:16:52,573] ({main} Notebook.java[loadNoteFromRepo]:508) - Failed to load 2EUZZ1P8Y
java.io.IOException: file:///users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/notebook/2EUZZ1P8Y is not a directory
	at org.apache.zeppelin.notebook.repo.VFSNotebookRepo.getNote(VFSNotebookRepo.java:151)
	at org.apache.zeppelin.notebook.repo.VFSNotebookRepo.get(VFSNotebookRepo.java:177)
	at org.apache.zeppelin.notebook.repo.NotebookRepoSync.get(NotebookRepoSync.java:165)
	at org.apache.zeppelin.notebook.Notebook.loadNoteFromRepo(Notebook.java:506)
	at org.apache.zeppelin.notebook.Notebook.loadAllNotes(Notebook.java:590)
	at org.apache.zeppelin.notebook.Notebook.<init>(Notebook.java:124)
	at org.apache.zeppelin.server.ZeppelinServer.<init>(ZeppelinServer.java:168)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.glassfish.hk2.utilities.reflection.ReflectionHelper.makeMe(ReflectionHelper.java:1375)
	at org.jvnet.hk2.internal.Utilities.justCreate(Utilities.java:1083)
	at org.jvnet.hk2.internal.ServiceLocatorImpl.create(ServiceLocatorImpl.java:978)
	at org.jvnet.hk2.internal.ServiceLocatorImpl.createAndInitialize(ServiceLocatorImpl.java:1082)
	at org.jvnet.hk2.internal.ServiceLocatorImpl.createAndInitialize(ServiceLocatorImpl.java:1074)
	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.createAndInitialize(AbstractHk2InjectionManager.java:213)
	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.createAndInitialize(ImmediateHk2InjectionManager.java:54)
	at org.glassfish.jersey.server.ApplicationConfigurator.createApplication(ApplicationConfigurator.java:138)
	at org.glassfish.jersey.server.ApplicationConfigurator.init(ApplicationConfigurator.java:96)
	at org.glassfish.jersey.server.ApplicationHandler.lambda$initialize$0(ApplicationHandler.java:313)
	at java.util.Arrays$ArrayList.forEach(Arrays.java:3880)
	at org.glassfish.jersey.server.ApplicationHandler.initialize(ApplicationHandler.java:313)
	at org.glassfish.jersey.server.ApplicationHandler.<init>(ApplicationHandler.java:282)
	at org.glassfish.jersey.servlet.WebComponent.<init>(WebComponent.java:335)
	at org.glassfish.jersey.servlet.ServletContainer.init(ServletContainer.java:178)
	at org.glassfish.jersey.servlet.ServletContainer.init(ServletContainer.java:370)
	at javax.servlet.GenericServlet.init(GenericServlet.java:244)
	at org.eclipse.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:672)
	at org.eclipse.jetty.servlet.ServletHolder.initialize(ServletHolder.java:429)
	at org.eclipse.jetty.servlet.ServletHandler.lambda$initialize$0(ServletHandler.java:750)
	at java.util.stream.SortedOps$SizedRefSortingSink.end(SortedOps.java:352)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471)
	at java.util.stream.StreamSpliterators$WrappingSpliterator.forEachRemaining(StreamSpliterators.java:312)
	at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:743)
	at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742)
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580)
	at org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:744)
	at org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:368)
	at org.eclipse.jetty.webapp.WebAppContext.startWebapp(WebAppContext.java:1497)
	at org.eclipse.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1459)
	at org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:852)
	at org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:278)
	at org.eclipse.jetty.webapp.WebAppContext.doStart(WebAppContext.java:545)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:138)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)
	at org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:113)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.doStart(ContextHandlerCollection.java:168)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:138)
	at org.eclipse.jetty.server.Server.start(Server.java:415)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:108)
	at org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:113)
	at org.eclipse.jetty.server.Server.doStart(Server.java:382)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.zeppelin.server.ZeppelinServer.main(ZeppelinServer.java:241)
ERROR [2020-10-30 20:16:52,574] ({main} Notebook.java[loadNoteFromRepo]:508) - Failed to load 2FNMF7WE2
java.io.IOException: file:///users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/notebook/2FNMF7WE2 is not a directory
	at org.apache.zeppelin.notebook.repo.VFSNotebookRepo.getNote(VFSNotebookRepo.java:151)
	at org.apache.zeppelin.notebook.repo.VFSNotebookRepo.get(VFSNotebookRepo.java:177)
	at org.apache.zeppelin.notebook.repo.NotebookRepoSync.get(NotebookRepoSync.java:165)
	at org.apache.zeppelin.notebook.Notebook.loadNoteFromRepo(Notebook.java:506)
	at org.apache.zeppelin.notebook.Notebook.loadAllNotes(Notebook.java:590)
	at org.apache.zeppelin.notebook.Notebook.<init>(Notebook.java:124)
	at org.apache.zeppelin.server.ZeppelinServer.<init>(ZeppelinServer.java:168)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.glassfish.hk2.utilities.reflection.ReflectionHelper.makeMe(ReflectionHelper.java:1375)
	at org.jvnet.hk2.internal.Utilities.justCreate(Utilities.java:1083)
	at org.jvnet.hk2.internal.ServiceLocatorImpl.create(ServiceLocatorImpl.java:978)
	at org.jvnet.hk2.internal.ServiceLocatorImpl.createAndInitialize(ServiceLocatorImpl.java:1082)
	at org.jvnet.hk2.internal.ServiceLocatorImpl.createAndInitialize(ServiceLocatorImpl.java:1074)
	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.createAndInitialize(AbstractHk2InjectionManager.java:213)
	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.createAndInitialize(ImmediateHk2InjectionManager.java:54)
	at org.glassfish.jersey.server.ApplicationConfigurator.createApplication(ApplicationConfigurator.java:138)
	at org.glassfish.jersey.server.ApplicationConfigurator.init(ApplicationConfigurator.java:96)
	at org.glassfish.jersey.server.ApplicationHandler.lambda$initialize$0(ApplicationHandler.java:313)
	at java.util.Arrays$ArrayList.forEach(Arrays.java:3880)
	at org.glassfish.jersey.server.ApplicationHandler.initialize(ApplicationHandler.java:313)
	at org.glassfish.jersey.server.ApplicationHandler.<init>(ApplicationHandler.java:282)
	at org.glassfish.jersey.servlet.WebComponent.<init>(WebComponent.java:335)
	at org.glassfish.jersey.servlet.ServletContainer.init(ServletContainer.java:178)
	at org.glassfish.jersey.servlet.ServletContainer.init(ServletContainer.java:370)
	at javax.servlet.GenericServlet.init(GenericServlet.java:244)
	at org.eclipse.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:672)
	at org.eclipse.jetty.servlet.ServletHolder.initialize(ServletHolder.java:429)
	at org.eclipse.jetty.servlet.ServletHandler.lambda$initialize$0(ServletHandler.java:750)
	at java.util.stream.SortedOps$SizedRefSortingSink.end(SortedOps.java:352)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471)
	at java.util.stream.StreamSpliterators$WrappingSpliterator.forEachRemaining(StreamSpliterators.java:312)
	at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:743)
	at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742)
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580)
	at org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:744)
	at org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:368)
	at org.eclipse.jetty.webapp.WebAppContext.startWebapp(WebAppContext.java:1497)
	at org.eclipse.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1459)
	at org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:852)
	at org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:278)
	at org.eclipse.jetty.webapp.WebAppContext.doStart(WebAppContext.java:545)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:138)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)
	at org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:113)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.doStart(ContextHandlerCollection.java:168)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:138)
	at org.eclipse.jetty.server.Server.start(Server.java:415)
	at org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:108)
	at org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:113)
	at org.eclipse.jetty.server.Server.doStart(Server.java:382)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.zeppelin.server.ZeppelinServer.main(ZeppelinServer.java:241)
 INFO [2020-10-30 20:16:52,579] ({main} Folder.java[addNote]:185) - Add note 2C35YU814 to folder Zeppelin Tutorial
 WARN [2020-10-30 20:16:52,580] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-10-30 20:16:52,580] ({main} Notebook.java[<init>]:127) - Notebook indexing started...
 INFO [2020-10-30 20:16:52,841] ({main} LuceneSearch.java[addIndexDocs]:305) - Indexing 15 notebooks took 260ms
 INFO [2020-10-30 20:16:52,841] ({main} Notebook.java[<init>]:129) - Notebook indexing finished: 15 indexed in 0s
 INFO [2020-10-30 20:16:52,843] ({main} Helium.java[loadConf]:103) - Add helium local registry /users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/helium
 INFO [2020-10-30 20:16:52,844] ({main} Helium.java[loadConf]:100) - Add helium online registry https://s3.amazonaws.com/helium-package/helium.json
 WARN [2020-10-30 20:16:52,849] ({main} Helium.java[loadConf]:111) - /users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/conf/helium.json does not exists
 INFO [2020-10-30 20:16:55,187] ({main} ContextHandler.java[doStart]:855) - Started o.e.j.w.WebAppContext@15761df8{zeppelin-web,/,file:///users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/webapps/webapp/,AVAILABLE}{/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/zeppelin-web-0.8.2.war}
 INFO [2020-10-30 20:16:55,205] ({main} AbstractConnector.java[doStart]:292) - Started ServerConnector@643d2dae{HTTP/1.1,[http/1.1]}{127.0.0.1:9322}
 INFO [2020-10-30 20:16:55,205] ({main} Server.java[doStart]:407) - Started @10616ms
 INFO [2020-10-30 20:16:55,205] ({main} ZeppelinServer.java[main]:249) - Done, zeppelin server started
 WARN [2020-10-30 20:17:26,330] ({qtp89387388-71} SecurityRestApi.java[ticket]:88) - {"status":"OK","message":"","body":{"principal":"anonymous","ticket":"anonymous","roles":"[]"}}
 INFO [2020-10-30 20:17:26,493] ({qtp89387388-22} NotebookServer.java[onOpen]:151) - New connection from 127.0.0.1 : 52238
 INFO [2020-10-30 20:17:26,599] ({qtp89387388-75} NotebookServer.java[sendNote]:828) - New operation from 127.0.0.1 : 52238 : anonymous : GET_NOTE : 2FP7CYTB9
 WARN [2020-10-30 20:17:26,922] ({qtp89387388-75} GitNotebookRepo.java[revisionHistory]:158) - No Head found for 2FP7CYTB9, No HEAD exists and no explicit starting revision was specified
 WARN [2020-10-30 20:17:27,863] ({qtp89387388-20} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 20:17:27,865] ({qtp89387388-20} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 20:17:27,865] ({qtp89387388-20} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 20:17:27,865] ({qtp89387388-20} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 20:17:27,865] ({qtp89387388-20} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 20:17:27,866] ({qtp89387388-20} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 INFO [2020-10-30 20:17:28,382] ({qtp89387388-71} InterpreterSetting.java[getOrCreateInterpreterGroup]:419) - Create InterpreterGroup with groupId: spark:shared_process for user: anonymous and note: 2FP7CYTB9
 INFO [2020-10-30 20:17:28,382] ({qtp89387388-23} InterpreterSetting.java[getOrCreateInterpreterGroup]:419) - Create InterpreterGroup with groupId: md:shared_process for user: anonymous and note: 2FP7CYTB9
 INFO [2020-10-30 20:17:28,388] ({qtp89387388-23} InterpreterSetting.java[createInterpreters]:689) - Interpreter org.apache.zeppelin.markdown.Markdown created for user: anonymous, sessionId: shared_session
 INFO [2020-10-30 20:17:28,388] ({qtp89387388-71} InterpreterSetting.java[createInterpreters]:689) - Interpreter org.apache.zeppelin.spark.SparkInterpreter created for user: anonymous, sessionId: shared_session
 INFO [2020-10-30 20:17:28,389] ({qtp89387388-71} InterpreterSetting.java[createInterpreters]:689) - Interpreter org.apache.zeppelin.spark.SparkSqlInterpreter created for user: anonymous, sessionId: shared_session
 INFO [2020-10-30 20:17:28,389] ({qtp89387388-71} InterpreterSetting.java[createInterpreters]:689) - Interpreter org.apache.zeppelin.spark.DepInterpreter created for user: anonymous, sessionId: shared_session
 INFO [2020-10-30 20:17:28,389] ({qtp89387388-71} InterpreterSetting.java[createInterpreters]:689) - Interpreter org.apache.zeppelin.spark.PySparkInterpreter created for user: anonymous, sessionId: shared_session
 INFO [2020-10-30 20:17:28,389] ({qtp89387388-23} ManagedInterpreterGroup.java[getOrCreateSession]:158) - Create Session: shared_session in InterpreterGroup: md:shared_process for user: anonymous
 INFO [2020-10-30 20:17:28,389] ({qtp89387388-71} InterpreterSetting.java[createInterpreters]:689) - Interpreter org.apache.zeppelin.spark.IPySparkInterpreter created for user: anonymous, sessionId: shared_session
 INFO [2020-10-30 20:17:28,390] ({qtp89387388-71} InterpreterSetting.java[createInterpreters]:689) - Interpreter org.apache.zeppelin.spark.SparkRInterpreter created for user: anonymous, sessionId: shared_session
 INFO [2020-10-30 20:17:28,390] ({qtp89387388-71} ManagedInterpreterGroup.java[getOrCreateSession]:158) - Create Session: shared_session in InterpreterGroup: spark:shared_process for user: anonymous
 INFO [2020-10-30 20:17:40,207] ({qtp89387388-75} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:17:40,327] ({pool-2-thread-2} SchedulerFactory.java[jobStarted]:114) - Job 20161101-163522_1877878760 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:17:40,328] ({pool-2-thread-2} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20161101-163522_1877878760, interpreter: pyspark, note_id: 2FP7CYTB9, user: anonymous]
 INFO [2020-10-30 20:17:40,329] ({pool-2-thread-2} ManagedInterpreterGroup.java[getOrCreateInterpreterProcess]:61) - Create InterpreterProcess for InterpreterGroup: spark:shared_process
 INFO [2020-10-30 20:17:40,330] ({pool-2-thread-2} ShellScriptLauncher.java[launch]:48) - Launching Interpreter: spark
 WARN [2020-10-30 20:17:40,339] ({pool-2-thread-2} SparkInterpreterLauncher.java[setupPropertiesForSparkR]:172) - sparkr.zip is not found, SparkR may not work.
 INFO [2020-10-30 20:17:40,339] ({pool-2-thread-2} SparkInterpreterLauncher.java[buildEnvFromProperties]:108) - Run Spark under non-secure mode as no keytab and principal is specified
 INFO [2020-10-30 20:17:40,344] ({pool-2-thread-2} RemoteInterpreterManagedProcess.java[start]:115) - Thrift server for callback will start. Port: 33961
 INFO [2020-10-30 20:17:40,357] ({pool-2-thread-2} RemoteInterpreterManagedProcess.java[start]:190) - Run interpreter process [/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/bin/interpreter.sh, -d, /users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark, -c, 200.16.29.165, -p, 33961, -r, :, -l, /users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/local-repo/spark, -g, spark]
 INFO [2020-10-30 20:17:41,760] ({pool-7-thread-1} RemoteInterpreterManagedProcess.java[callback]:123) - RemoteInterpreterServer Registered: CallbackInfo(host:200.16.29.165, port:34331)
 INFO [2020-10-30 20:17:41,817] ({pool-2-thread-2} RemoteInterpreter.java[call]:168) - Create RemoteInterpreter org.apache.zeppelin.spark.SparkInterpreter
 INFO [2020-10-30 20:17:41,975] ({pool-2-thread-2} RemoteInterpreter.java[call]:168) - Create RemoteInterpreter org.apache.zeppelin.spark.SparkSqlInterpreter
 INFO [2020-10-30 20:17:41,977] ({pool-2-thread-2} RemoteInterpreter.java[call]:168) - Create RemoteInterpreter org.apache.zeppelin.spark.DepInterpreter
 INFO [2020-10-30 20:17:41,987] ({pool-2-thread-2} RemoteInterpreter.java[call]:168) - Create RemoteInterpreter org.apache.zeppelin.spark.PySparkInterpreter
 INFO [2020-10-30 20:17:42,002] ({pool-2-thread-2} RemoteInterpreter.java[call]:168) - Create RemoteInterpreter org.apache.zeppelin.spark.IPySparkInterpreter
 INFO [2020-10-30 20:17:42,008] ({pool-2-thread-2} RemoteInterpreter.java[call]:168) - Create RemoteInterpreter org.apache.zeppelin.spark.SparkRInterpreter
 INFO [2020-10-30 20:17:42,011] ({pool-2-thread-2} RemoteInterpreter.java[call]:142) - Open RemoteInterpreter org.apache.zeppelin.spark.PySparkInterpreter
 INFO [2020-10-30 20:17:42,011] ({pool-2-thread-2} RemoteInterpreter.java[pushAngularObjectRegistryToRemote]:436) - Push local angular object registry from ZeppelinServer to remote interpreter group spark:shared_process
 INFO [2020-10-30 20:17:58,790] ({pool-2-thread-2} NotebookServer.java[afterStatusChange]:2314) - Job 20161101-163522_1877878760 is finished successfully, status: FINISHED
 INFO [2020-10-30 20:17:58,954] ({pool-2-thread-2} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:17:59,006] ({pool-2-thread-2} SchedulerFactory.java[jobFinished]:120) - Job 20161101-163522_1877878760 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:18:04,267] ({qtp89387388-22} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:18:04,320] ({pool-2-thread-2} SchedulerFactory.java[jobStarted]:114) - Job 20171030-162612_256050184 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:18:04,320] ({pool-2-thread-2} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20171030-162612_256050184, interpreter: pyspark, note_id: 2FP7CYTB9, user: anonymous]
 INFO [2020-10-30 20:18:04,800] ({pool-2-thread-2} NotebookServer.java[afterStatusChange]:2314) - Job 20171030-162612_256050184 is finished successfully, status: FINISHED
 INFO [2020-10-30 20:18:04,902] ({pool-2-thread-2} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:18:04,957] ({pool-2-thread-2} SchedulerFactory.java[jobFinished]:120) - Job 20171030-162612_256050184 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:18:08,698] ({qtp89387388-22} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:18:08,745] ({pool-2-thread-3} SchedulerFactory.java[jobStarted]:114) - Job 20171030-163816_785316912 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:18:08,746] ({pool-2-thread-3} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20171030-163816_785316912, interpreter: pyspark, note_id: 2FP7CYTB9, user: anonymous]
 INFO [2020-10-30 20:18:09,224] ({pool-2-thread-3} NotebookServer.java[afterStatusChange]:2314) - Job 20171030-163816_785316912 is finished successfully, status: FINISHED
 INFO [2020-10-30 20:18:09,316] ({pool-2-thread-3} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:18:09,363] ({pool-2-thread-3} SchedulerFactory.java[jobFinished]:120) - Job 20171030-163816_785316912 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:18:17,152] ({qtp89387388-77} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:18:17,208] ({pool-2-thread-2} SchedulerFactory.java[jobStarted]:114) - Job 20171030-164611_870874723 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:18:17,208] ({pool-2-thread-2} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20171030-164611_870874723, interpreter: pyspark, note_id: 2FP7CYTB9, user: anonymous]
 INFO [2020-10-30 20:18:17,932] ({pool-2-thread-2} NotebookServer.java[afterStatusChange]:2314) - Job 20171030-164611_870874723 is finished successfully, status: FINISHED
 INFO [2020-10-30 20:18:18,011] ({pool-2-thread-2} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:18:18,057] ({pool-2-thread-2} SchedulerFactory.java[jobFinished]:120) - Job 20171030-164611_870874723 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:18:25,221] ({qtp89387388-77} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:18:25,285] ({pool-2-thread-4} SchedulerFactory.java[jobStarted]:114) - Job 20161102-154506_492289084 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:18:25,285] ({pool-2-thread-4} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20161102-154506_492289084, interpreter: pyspark, note_id: 2FP7CYTB9, user: anonymous]
 INFO [2020-10-30 20:18:25,297] ({pool-2-thread-4} NotebookServer.java[afterStatusChange]:2314) - Job 20161102-154506_492289084 is finished successfully, status: FINISHED
 INFO [2020-10-30 20:18:25,370] ({pool-2-thread-4} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:18:25,418] ({pool-2-thread-4} SchedulerFactory.java[jobFinished]:120) - Job 20161102-154506_492289084 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:18:30,250] ({qtp89387388-77} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:18:30,298] ({pool-2-thread-3} SchedulerFactory.java[jobStarted]:114) - Job 20171030-173939_397652020 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:18:30,298] ({pool-2-thread-3} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20171030-173939_397652020, interpreter: pyspark, note_id: 2FP7CYTB9, user: anonymous]
 WARN [2020-10-30 20:18:30,921] ({pool-2-thread-3} NotebookServer.java[afterStatusChange]:2316) - Job 20171030-173939_397652020 is finished, status: ERROR, exception: null, result: %text Fail to execute line 1: plot_classification(trainFeaturized)
Traceback (most recent call last):
  File "/tmp/zeppelin_pyspark-3446420817745028958.py", line 380, in <module>
    exec(code, _zcUserQueryNameSpace)
  File "<stdin>", line 1, in <module>
  File "<stdin>", line 60, in plot_classification
  File "<stdin>", line 16, in show
AttributeError: type object '_io.StringIO' has no attribute 'StringIO'

 INFO [2020-10-30 20:18:30,997] ({pool-2-thread-3} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:18:31,047] ({pool-2-thread-3} SchedulerFactory.java[jobFinished]:120) - Job 20171030-173939_397652020 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:18:42,332] ({qtp89387388-22} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:18:42,378] ({pool-2-thread-5} SchedulerFactory.java[jobStarted]:114) - Job 20161107-153258_1183600330 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:18:42,379] ({pool-2-thread-5} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20161107-153258_1183600330, interpreter: pyspark, note_id: 2FP7CYTB9, user: anonymous]
 INFO [2020-10-30 20:18:43,916] ({pool-2-thread-5} NotebookServer.java[afterStatusChange]:2314) - Job 20161107-153258_1183600330 is finished successfully, status: FINISHED
 INFO [2020-10-30 20:18:43,987] ({pool-2-thread-5} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:18:44,041] ({pool-2-thread-5} SchedulerFactory.java[jobFinished]:120) - Job 20161107-153258_1183600330 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:18:48,537] ({qtp89387388-22} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:18:48,602] ({pool-2-thread-2} SchedulerFactory.java[jobStarted]:114) - Job 20171030-191336_34491578 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:18:48,602] ({pool-2-thread-2} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20171030-191336_34491578, interpreter: pyspark, note_id: 2FP7CYTB9, user: anonymous]
 INFO [2020-10-30 20:18:48,752] ({pool-2-thread-2} NotebookServer.java[afterStatusChange]:2314) - Job 20171030-191336_34491578 is finished successfully, status: FINISHED
 INFO [2020-10-30 20:18:48,853] ({pool-2-thread-2} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:18:48,898] ({pool-2-thread-2} SchedulerFactory.java[jobFinished]:120) - Job 20171030-191336_34491578 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:18:57,728] ({qtp89387388-25} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:18:57,780] ({pool-2-thread-6} SchedulerFactory.java[jobStarted]:114) - Job 20161107-030549_2115288931 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:18:57,781] ({pool-2-thread-6} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20161107-030549_2115288931, interpreter: pyspark, note_id: 2FP7CYTB9, user: anonymous]
 WARN [2020-10-30 20:18:58,544] ({pool-2-thread-6} NotebookServer.java[afterStatusChange]:2316) - Job 20161107-030549_2115288931 is finished, status: ERROR, exception: null, result: %text Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 64.0 failed 1 times, most recent failure: Lost task 0.0 in stage 64.0 (TID 469, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py", line 177, in main
    process()
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py", line 172, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/rdd.py", line 1339, in takeUpToNumLeft
TypeError: <lambda>() missing 1 required positional argument: 'y'

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2069)
	at org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:455)
	at org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:214)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py", line 177, in main
    process()
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py", line 172, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/rdd.py", line 1339, in takeUpToNumLeft
TypeError: <lambda>() missing 1 required positional argument: 'y'

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	... 1 more

(<class 'py4j.protocol.Py4JJavaError'>, Py4JJavaError('An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n', JavaObject id=o186), <traceback object at 0x7f0f73d40ec8>)
 INFO [2020-10-30 20:18:58,620] ({pool-2-thread-6} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:18:58,672] ({pool-2-thread-6} SchedulerFactory.java[jobFinished]:120) - Job 20161107-030549_2115288931 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:21:21,275] ({qtp89387388-71} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:21:21,324] ({pool-2-thread-4} SchedulerFactory.java[jobStarted]:114) - Job 20161107-030549_2115288931 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:21:21,325] ({pool-2-thread-4} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20161107-030549_2115288931, interpreter: pyspark, note_id: 2FP7CYTB9, user: anonymous]
 WARN [2020-10-30 20:21:21,529] ({pool-2-thread-4} NotebookServer.java[afterStatusChange]:2316) - Job 20161107-030549_2115288931 is finished, status: ERROR, exception: null, result: %text Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 68.0 failed 1 times, most recent failure: Lost task 0.0 in stage 68.0 (TID 491, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py", line 177, in main
    process()
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py", line 172, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/rdd.py", line 1339, in takeUpToNumLeft
TypeError: <lambda>() missing 1 required positional argument: 'y'

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2069)
	at org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:455)
	at org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:214)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py", line 177, in main
    process()
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py", line 172, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/rdd.py", line 1339, in takeUpToNumLeft
TypeError: <lambda>() missing 1 required positional argument: 'y'

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	... 1 more

(<class 'py4j.protocol.Py4JJavaError'>, Py4JJavaError('An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n', JavaObject id=o243), <traceback object at 0x7f0f73c8d608>)
 INFO [2020-10-30 20:21:21,601] ({pool-2-thread-4} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:21:21,656] ({pool-2-thread-4} SchedulerFactory.java[jobFinished]:120) - Job 20161107-030549_2115288931 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:22:42,379] ({qtp89387388-71} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:22:42,497] ({qtp89387388-71} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:22:42,547] ({pool-2-thread-7} SchedulerFactory.java[jobStarted]:114) - Job 20161107-030549_2115288931 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:22:42,548] ({pool-2-thread-7} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20161107-030549_2115288931, interpreter: pyspark, note_id: 2FP7CYTB9, user: anonymous]
 WARN [2020-10-30 20:22:42,767] ({pool-2-thread-7} NotebookServer.java[afterStatusChange]:2316) - Job 20161107-030549_2115288931 is finished, status: ERROR, exception: null, result: %text Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 72.0 failed 1 times, most recent failure: Lost task 0.0 in stage 72.0 (TID 513, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py", line 177, in main
    process()
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py", line 172, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/rdd.py", line 1339, in takeUpToNumLeft
TypeError: <lambda>() missing 1 required positional argument: 'y'

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2069)
	at org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:455)
	at org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:214)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py", line 177, in main
    process()
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py", line 172, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/rdd.py", line 1339, in takeUpToNumLeft
TypeError: <lambda>() missing 1 required positional argument: 'y'

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	... 1 more

(<class 'py4j.protocol.Py4JJavaError'>, Py4JJavaError('An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n', JavaObject id=o300), <traceback object at 0x7f0f73d40088>)
 INFO [2020-10-30 20:22:42,835] ({pool-2-thread-7} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:22:42,883] ({pool-2-thread-7} SchedulerFactory.java[jobFinished]:120) - Job 20161107-030549_2115288931 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:23:03,401] ({qtp89387388-66} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:23:03,513] ({qtp89387388-66} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:23:03,565] ({pool-2-thread-3} SchedulerFactory.java[jobStarted]:114) - Job 20161107-030549_2115288931 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:23:03,566] ({pool-2-thread-3} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20161107-030549_2115288931, interpreter: pyspark, note_id: 2FP7CYTB9, user: anonymous]
 INFO [2020-10-30 20:23:03,579] ({pool-2-thread-3} NotebookServer.java[afterStatusChange]:2314) - Job 20161107-030549_2115288931 is finished successfully, status: FINISHED
 INFO [2020-10-30 20:23:03,647] ({pool-2-thread-3} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:23:03,699] ({pool-2-thread-3} SchedulerFactory.java[jobFinished]:120) - Job 20161107-030549_2115288931 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:23:25,747] ({qtp89387388-71} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:23:25,854] ({qtp89387388-71} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:23:25,901] ({pool-2-thread-8} SchedulerFactory.java[jobStarted]:114) - Job 20161107-030549_2115288931 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:23:25,902] ({pool-2-thread-8} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20161107-030549_2115288931, interpreter: pyspark, note_id: 2FP7CYTB9, user: anonymous]
 INFO [2020-10-30 20:23:26,011] ({pool-2-thread-8} NotebookServer.java[afterStatusChange]:2314) - Job 20161107-030549_2115288931 is finished successfully, status: FINISHED
 INFO [2020-10-30 20:23:26,083] ({pool-2-thread-8} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:23:26,130] ({pool-2-thread-8} SchedulerFactory.java[jobFinished]:120) - Job 20161107-030549_2115288931 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:23:39,340] ({qtp89387388-66} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:24:21,975] ({qtp89387388-79} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:24:22,023] ({pool-2-thread-5} SchedulerFactory.java[jobStarted]:114) - Job 20161107-030549_2115288931 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:24:22,024] ({pool-2-thread-5} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20161107-030549_2115288931, interpreter: pyspark, note_id: 2FP7CYTB9, user: anonymous]
 WARN [2020-10-30 20:24:22,218] ({pool-2-thread-5} NotebookServer.java[afterStatusChange]:2316) - Job 20161107-030549_2115288931 is finished, status: ERROR, exception: null, result: %text Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 79.0 failed 1 times, most recent failure: Lost task 0.0 in stage 79.0 (TID 556, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py", line 177, in main
    process()
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py", line 172, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/rdd.py", line 1339, in takeUpToNumLeft
TypeError: <lambda>() missing 1 required positional argument: 'y'

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2069)
	at org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:455)
	at org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:214)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py", line 177, in main
    process()
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py", line 172, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/rdd.py", line 1339, in takeUpToNumLeft
TypeError: <lambda>() missing 1 required positional argument: 'y'

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	... 1 more

(<class 'py4j.protocol.Py4JJavaError'>, Py4JJavaError('An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n', JavaObject id=o370), <traceback object at 0x7f0f73d40d48>)
 INFO [2020-10-30 20:24:22,285] ({pool-2-thread-5} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:24:22,331] ({pool-2-thread-5} SchedulerFactory.java[jobFinished]:120) - Job 20161107-030549_2115288931 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:24:40,974] ({qtp89387388-66} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:24:43,849] ({qtp89387388-26} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:24:43,897] ({pool-2-thread-9} SchedulerFactory.java[jobStarted]:114) - Job 20161107-030549_2115288931 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:24:43,898] ({pool-2-thread-9} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20161107-030549_2115288931, interpreter: pyspark, note_id: 2FP7CYTB9, user: anonymous]
 WARN [2020-10-30 20:24:44,096] ({pool-2-thread-9} NotebookServer.java[afterStatusChange]:2316) - Job 20161107-030549_2115288931 is finished, status: ERROR, exception: null, result: %text Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 83.0 failed 1 times, most recent failure: Lost task 0.0 in stage 83.0 (TID 578, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py", line 177, in main
    process()
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py", line 172, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/rdd.py", line 1339, in takeUpToNumLeft
TypeError: <lambda>() missing 1 required positional argument: 'y'

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2069)
	at org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:455)
	at org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:214)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py", line 177, in main
    process()
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py", line 172, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/rdd.py", line 1339, in takeUpToNumLeft
TypeError: <lambda>() missing 1 required positional argument: 'y'

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	... 1 more

(<class 'py4j.protocol.Py4JJavaError'>, Py4JJavaError('An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n', JavaObject id=o427), <traceback object at 0x7f0f73d1ce08>)
 INFO [2020-10-30 20:24:44,165] ({pool-2-thread-9} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:24:44,218] ({pool-2-thread-9} SchedulerFactory.java[jobFinished]:120) - Job 20161107-030549_2115288931 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:24:59,521] ({qtp89387388-66} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:24:59,614] ({qtp89387388-66} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:24:59,654] ({pool-2-thread-2} SchedulerFactory.java[jobStarted]:114) - Job 20161107-030549_2115288931 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:24:59,655] ({pool-2-thread-2} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20161107-030549_2115288931, interpreter: pyspark, note_id: 2FP7CYTB9, user: anonymous]
 WARN [2020-10-30 20:24:59,674] ({pool-2-thread-2} NotebookServer.java[afterStatusChange]:2316) - Job 20161107-030549_2115288931 is finished, status: ERROR, exception: null, result: %text Traceback (most recent call last):
  File "/tmp/zeppelin_pyspark-3446420817745028958.py", line 364, in <module>
    code = compile('\n'.join(stmts), '<stdin>', 'exec', ast.PyCF_ONLY_AST, 1)
  File "<stdin>", line 20
    .map(lambda (x,y): (fgrid(x,minKgs,maxKgs,maxTics), fgrid(y,minMts,maxMts,maxTics))) \
                ^
SyntaxError: invalid syntax

 INFO [2020-10-30 20:24:59,739] ({pool-2-thread-2} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:24:59,784] ({pool-2-thread-2} SchedulerFactory.java[jobFinished]:120) - Job 20161107-030549_2115288931 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:25:19,723] ({qtp89387388-79} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:25:19,829] ({qtp89387388-79} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:25:19,880] ({pool-2-thread-10} SchedulerFactory.java[jobStarted]:114) - Job 20161107-030549_2115288931 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:25:19,881] ({pool-2-thread-10} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20161107-030549_2115288931, interpreter: pyspark, note_id: 2FP7CYTB9, user: anonymous]
 WARN [2020-10-30 20:25:20,082] ({pool-2-thread-10} NotebookServer.java[afterStatusChange]:2316) - Job 20161107-030549_2115288931 is finished, status: ERROR, exception: null, result: %text Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 87.0 failed 1 times, most recent failure: Lost task 0.0 in stage 87.0 (TID 600, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py", line 177, in main
    process()
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py", line 172, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/rdd.py", line 1339, in takeUpToNumLeft
TypeError: <lambda>() missing 1 required positional argument: 'y'

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2069)
	at org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:455)
	at org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:214)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py", line 177, in main
    process()
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py", line 172, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/rdd.py", line 1339, in takeUpToNumLeft
TypeError: <lambda>() missing 1 required positional argument: 'y'

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	... 1 more

(<class 'py4j.protocol.Py4JJavaError'>, Py4JJavaError('An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n', JavaObject id=o485), <traceback object at 0x7f0f73d264c8>)
 INFO [2020-10-30 20:25:20,146] ({pool-2-thread-10} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:25:20,193] ({pool-2-thread-10} SchedulerFactory.java[jobFinished]:120) - Job 20161107-030549_2115288931 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:25:36,756] ({qtp89387388-71} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:25:36,805] ({pool-2-thread-6} SchedulerFactory.java[jobStarted]:114) - Job 20171030-185922_914672286 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:25:36,806] ({pool-2-thread-6} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20171030-185922_914672286, interpreter: pyspark, note_id: 2FP7CYTB9, user: anonymous]
 WARN [2020-10-30 20:25:36,820] ({pool-2-thread-6} NotebookServer.java[afterStatusChange]:2316) - Job 20171030-185922_914672286 is finished, status: ERROR, exception: null, result: %text Fail to execute line 2: gridPredictionDT = dtModel.transform(grid)
Traceback (most recent call last):
  File "/tmp/zeppelin_pyspark-3446420817745028958.py", line 375, in <module>
    exec(code, _zcUserQueryNameSpace)
  File "<stdin>", line 2, in <module>
NameError: name 'grid' is not defined

 INFO [2020-10-30 20:25:36,889] ({pool-2-thread-6} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:25:36,939] ({pool-2-thread-6} SchedulerFactory.java[jobFinished]:120) - Job 20171030-185922_914672286 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:25:45,672] ({qtp89387388-79} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:25:45,723] ({pool-2-thread-11} SchedulerFactory.java[jobStarted]:114) - Job 20171030-192143_1165730818 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:25:45,723] ({pool-2-thread-11} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20171030-192143_1165730818, interpreter: pyspark, note_id: 2FP7CYTB9, user: anonymous]
 WARN [2020-10-30 20:25:46,877] ({pool-2-thread-11} NotebookServer.java[afterStatusChange]:2316) - Job 20171030-192143_1165730818 is finished, status: ERROR, exception: null, result: %text Fail to execute line 14: gridPredictionDT2 = dtModel2.transform(grid)
Traceback (most recent call last):
  File "/tmp/zeppelin_pyspark-3446420817745028958.py", line 380, in <module>
    exec(code, _zcUserQueryNameSpace)
  File "<stdin>", line 14, in <module>
NameError: name 'grid' is not defined

 INFO [2020-10-30 20:25:46,940] ({pool-2-thread-11} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:25:46,988] ({pool-2-thread-11} SchedulerFactory.java[jobFinished]:120) - Job 20171030-192143_1165730818 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:26:29,628] ({qtp89387388-446} FolderView.java[onNoteNameChanged]:205) - Note name changed: Diplodatos/Clase 05 - Machine Learning -> ~Trash/Diplodatos/Clase 05 - Machine Learning
 INFO [2020-10-30 20:26:29,629] ({qtp89387388-446} FolderView.java[createFolder]:107) - Create folder ~Trash/Diplodatos
 INFO [2020-10-30 20:26:29,630] ({qtp89387388-446} FolderView.java[createFolder]:107) - Create folder ~Trash
 INFO [2020-10-30 20:26:29,630] ({qtp89387388-446} Folder.java[setParent]:169) - Set parent of ~Trash to /
 INFO [2020-10-30 20:26:29,630] ({qtp89387388-446} Folder.java[setParent]:169) - Set parent of ~Trash/Diplodatos to ~Trash
 INFO [2020-10-30 20:26:29,630] ({qtp89387388-446} Folder.java[addNote]:185) - Add note 2FP7CYTB9 to folder ~Trash/Diplodatos
 INFO [2020-10-30 20:26:29,718] ({qtp89387388-446} VFSNotebookRepo.java[save]:196) - Saving note:2FP7CYTB9
 INFO [2020-10-30 20:26:29,765] ({qtp89387388-446} LocalConfigStorage.java[save]:53) - Save Interpreter Setting to /users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/conf/interpreter.json
 WARN [2020-10-30 20:27:15,462] ({qtp89387388-79} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 20:27:15,462] ({qtp89387388-79} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 20:27:15,462] ({qtp89387388-79} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 20:27:15,462] ({qtp89387388-79} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 20:27:15,463] ({qtp89387388-79} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 20:27:15,463] ({qtp89387388-79} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 INFO [2020-10-30 20:27:15,463] ({qtp89387388-79} LocalConfigStorage.java[save]:53) - Save Interpreter Setting to /users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/conf/interpreter.json
 INFO [2020-10-30 20:27:15,466] ({qtp89387388-79} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:27:15,468] ({qtp89387388-79} FolderView.java[onNoteNameChanged]:205) - Note name changed: 2FQ9A4Z9B -> Diplodatos/Clase 05 - Machine Learning
 INFO [2020-10-30 20:27:15,468] ({qtp89387388-79} Folder.java[addNote]:185) - Add note 2FQ9A4Z9B to folder Diplodatos
 INFO [2020-10-30 20:27:15,572] ({qtp89387388-79} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:27:15,647] ({qtp89387388-79} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:27:21,823] ({qtp89387388-79} NotebookServer.java[sendNote]:828) - New operation from 127.0.0.1 : 52238 : anonymous : GET_NOTE : 2FQ9A4Z9B
 WARN [2020-10-30 20:27:21,834] ({qtp89387388-79} GitNotebookRepo.java[revisionHistory]:158) - No Head found for 2FQ9A4Z9B, No HEAD exists and no explicit starting revision was specified
 WARN [2020-10-30 20:27:21,908] ({qtp89387388-446} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 20:27:21,909] ({qtp89387388-446} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 20:27:21,909] ({qtp89387388-446} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 20:27:21,909] ({qtp89387388-446} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 20:27:21,909] ({qtp89387388-446} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 20:27:21,910] ({qtp89387388-446} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 INFO [2020-10-30 20:27:30,806] ({qtp89387388-22} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:27:30,821] ({pool-2-thread-4} SchedulerFactory.java[jobStarted]:114) - Job 20201029-105118_47901818 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:27:30,822] ({pool-2-thread-4} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20201029-105118_47901818, interpreter: pyspark, note_id: 2FQ9A4Z9B, user: anonymous]
 WARN [2020-10-30 20:27:30,857] ({pool-2-thread-4} NotebookServer.java[afterStatusChange]:2316) - Job 20201029-105118_47901818 is finished, status: ERROR, exception: null, result: %text Fail to execute line 3: people = spark.read.json(inputFile) \
Traceback (most recent call last):
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/sql/utils.py", line 63, in deco
    return f(*a, **kw)
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/py4j-0.10.4-src.zip/py4j/protocol.py", line 319, in get_return_value
    format(target_id, ".", name), value)
py4j.protocol.Py4JJavaError: An error occurred while calling o565.json.
: org.apache.spark.sql.AnalysisException: Path does not exist: file:/users/ssulca/diplodatos_bigdata/diplodatos_bigdata/ds/people_sex_height_age_weight.json;
	at org.apache.spark.sql.execution.datasources.DataSource$.org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary(DataSource.scala:626)
	at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:350)
	at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:350)
	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
	at scala.collection.immutable.List.flatMap(List.scala:344)
	at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:349)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:178)
	at org.apache.spark.sql.DataFrameReader.json(DataFrameReader.scala:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:214)
	at java.lang.Thread.run(Thread.java:745)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/tmp/zeppelin_pyspark-3446420817745028958.py", line 375, in <module>
    exec(code, _zcUserQueryNameSpace)
  File "<stdin>", line 3, in <module>
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/sql/readwriter.py", line 249, in json
    return self._df(self._jreader.json(self._spark._sc._jvm.PythonUtils.toSeq(path)))
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/py4j-0.10.4-src.zip/py4j/java_gateway.py", line 1133, in __call__
    answer, self.gateway_client, self.target_id, self.name)
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/sql/utils.py", line 69, in deco
    raise AnalysisException(s.split(': ', 1)[1], stackTrace)
pyspark.sql.utils.AnalysisException: 'Path does not exist: file:/users/ssulca/diplodatos_bigdata/diplodatos_bigdata/ds/people_sex_height_age_weight.json;'

 INFO [2020-10-30 20:27:30,925] ({pool-2-thread-4} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:27:30,934] ({pool-2-thread-4} SchedulerFactory.java[jobFinished]:120) - Job 20201029-105118_47901818 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:27:37,411] ({qtp89387388-79} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:27:37,507] ({qtp89387388-446} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:27:37,512] ({pool-2-thread-12} SchedulerFactory.java[jobStarted]:114) - Job 20201029-105118_47901818 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:27:37,513] ({pool-2-thread-12} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20201029-105118_47901818, interpreter: pyspark, note_id: 2FQ9A4Z9B, user: anonymous]
 INFO [2020-10-30 20:27:37,861] ({pool-2-thread-12} NotebookServer.java[afterStatusChange]:2314) - Job 20201029-105118_47901818 is finished successfully, status: FINISHED
 INFO [2020-10-30 20:27:37,926] ({pool-2-thread-12} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:27:37,931] ({pool-2-thread-12} SchedulerFactory.java[jobFinished]:120) - Job 20201029-105118_47901818 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:27:41,069] ({qtp89387388-446} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:27:41,074] ({pool-2-thread-7} SchedulerFactory.java[jobStarted]:114) - Job 20201029-105132_386130372 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:27:41,075] ({pool-2-thread-7} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20201029-105132_386130372, interpreter: pyspark, note_id: 2FQ9A4Z9B, user: anonymous]
 INFO [2020-10-30 20:27:41,313] ({pool-2-thread-7} NotebookServer.java[afterStatusChange]:2314) - Job 20201029-105132_386130372 is finished successfully, status: FINISHED
 INFO [2020-10-30 20:27:41,379] ({pool-2-thread-7} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:27:41,384] ({pool-2-thread-7} SchedulerFactory.java[jobFinished]:120) - Job 20201029-105132_386130372 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:27:43,964] ({qtp89387388-79} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:27:43,969] ({pool-2-thread-13} SchedulerFactory.java[jobStarted]:114) - Job 20171030-163816_785316912 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:27:43,969] ({pool-2-thread-13} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20171030-163816_785316912, interpreter: pyspark, note_id: 2FQ9A4Z9B, user: anonymous]
 INFO [2020-10-30 20:27:44,096] ({pool-2-thread-13} NotebookServer.java[afterStatusChange]:2314) - Job 20171030-163816_785316912 is finished successfully, status: FINISHED
 INFO [2020-10-30 20:27:44,158] ({pool-2-thread-13} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:27:44,162] ({pool-2-thread-13} SchedulerFactory.java[jobFinished]:120) - Job 20171030-163816_785316912 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:27:47,498] ({qtp89387388-446} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:27:47,504] ({pool-2-thread-3} SchedulerFactory.java[jobStarted]:114) - Job 20171030-164611_870874723 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:27:47,504] ({pool-2-thread-3} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20171030-164611_870874723, interpreter: pyspark, note_id: 2FQ9A4Z9B, user: anonymous]
 INFO [2020-10-30 20:27:47,724] ({pool-2-thread-3} NotebookServer.java[afterStatusChange]:2314) - Job 20171030-164611_870874723 is finished successfully, status: FINISHED
 INFO [2020-10-30 20:27:47,785] ({pool-2-thread-3} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:27:47,789] ({pool-2-thread-3} SchedulerFactory.java[jobFinished]:120) - Job 20171030-164611_870874723 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:27:51,062] ({qtp89387388-69} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:27:51,068] ({pool-2-thread-14} SchedulerFactory.java[jobStarted]:114) - Job 20161102-154506_492289084 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:27:51,068] ({pool-2-thread-14} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20161102-154506_492289084, interpreter: pyspark, note_id: 2FQ9A4Z9B, user: anonymous]
 INFO [2020-10-30 20:27:51,079] ({pool-2-thread-14} NotebookServer.java[afterStatusChange]:2314) - Job 20161102-154506_492289084 is finished successfully, status: FINISHED
 INFO [2020-10-30 20:27:51,141] ({pool-2-thread-14} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:27:51,146] ({pool-2-thread-14} SchedulerFactory.java[jobFinished]:120) - Job 20161102-154506_492289084 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:27:54,878] ({qtp89387388-79} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:27:54,884] ({pool-2-thread-8} SchedulerFactory.java[jobStarted]:114) - Job 20171030-173939_397652020 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:27:54,885] ({pool-2-thread-8} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20171030-173939_397652020, interpreter: pyspark, note_id: 2FQ9A4Z9B, user: anonymous]
 INFO [2020-10-30 20:27:55,512] ({pool-2-thread-8} NotebookServer.java[afterStatusChange]:2314) - Job 20171030-173939_397652020 is finished successfully, status: FINISHED
 INFO [2020-10-30 20:27:55,587] ({pool-2-thread-8} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:27:55,600] ({pool-2-thread-8} SchedulerFactory.java[jobFinished]:120) - Job 20171030-173939_397652020 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:27:59,507] ({qtp89387388-79} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:27:59,513] ({pool-2-thread-15} SchedulerFactory.java[jobStarted]:114) - Job 20161107-153258_1183600330 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:27:59,513] ({pool-2-thread-15} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20161107-153258_1183600330, interpreter: pyspark, note_id: 2FQ9A4Z9B, user: anonymous]
 INFO [2020-10-30 20:28:00,131] ({pool-2-thread-15} NotebookServer.java[afterStatusChange]:2314) - Job 20161107-153258_1183600330 is finished successfully, status: FINISHED
 INFO [2020-10-30 20:28:00,195] ({pool-2-thread-15} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:28:00,201] ({pool-2-thread-15} SchedulerFactory.java[jobFinished]:120) - Job 20161107-153258_1183600330 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:28:02,842] ({qtp89387388-69} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:28:02,848] ({pool-2-thread-5} SchedulerFactory.java[jobStarted]:114) - Job 20171030-191336_34491578 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:28:02,849] ({pool-2-thread-5} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20171030-191336_34491578, interpreter: pyspark, note_id: 2FQ9A4Z9B, user: anonymous]
 INFO [2020-10-30 20:28:03,008] ({pool-2-thread-5} NotebookServer.java[afterStatusChange]:2314) - Job 20171030-191336_34491578 is finished successfully, status: FINISHED
 INFO [2020-10-30 20:28:03,070] ({pool-2-thread-5} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:28:03,075] ({pool-2-thread-5} SchedulerFactory.java[jobFinished]:120) - Job 20171030-191336_34491578 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:28:05,789] ({qtp89387388-79} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:28:05,795] ({pool-2-thread-16} SchedulerFactory.java[jobStarted]:114) - Job 20201028-174622_901506110 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:28:05,795] ({pool-2-thread-16} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20201028-174622_901506110, interpreter: pyspark, note_id: 2FQ9A4Z9B, user: anonymous]
 INFO [2020-10-30 20:28:06,246] ({pool-2-thread-16} NotebookServer.java[afterStatusChange]:2314) - Job 20201028-174622_901506110 is finished successfully, status: FINISHED
 INFO [2020-10-30 20:28:06,309] ({pool-2-thread-16} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:28:06,314] ({pool-2-thread-16} SchedulerFactory.java[jobFinished]:120) - Job 20201028-174622_901506110 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:28:10,420] ({qtp89387388-22} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:28:10,426] ({pool-2-thread-9} SchedulerFactory.java[jobStarted]:114) - Job 20171030-185922_914672286 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:28:10,427] ({pool-2-thread-9} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20171030-185922_914672286, interpreter: pyspark, note_id: 2FQ9A4Z9B, user: anonymous]
 INFO [2020-10-30 20:28:10,800] ({pool-2-thread-9} NotebookServer.java[afterStatusChange]:2314) - Job 20171030-185922_914672286 is finished successfully, status: FINISHED
 INFO [2020-10-30 20:28:10,867] ({pool-2-thread-9} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:28:10,873] ({pool-2-thread-9} SchedulerFactory.java[jobFinished]:120) - Job 20171030-185922_914672286 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:28:14,724] ({qtp89387388-507} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:28:14,730] ({pool-2-thread-17} SchedulerFactory.java[jobStarted]:114) - Job 20171030-191207_1802786448 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:28:14,731] ({pool-2-thread-17} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20171030-191207_1802786448, interpreter: pyspark, note_id: 2FQ9A4Z9B, user: anonymous]
 INFO [2020-10-30 20:28:15,644] ({pool-2-thread-17} NotebookServer.java[afterStatusChange]:2314) - Job 20171030-191207_1802786448 is finished successfully, status: FINISHED
 INFO [2020-10-30 20:28:15,712] ({pool-2-thread-17} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:28:15,721] ({pool-2-thread-17} SchedulerFactory.java[jobFinished]:120) - Job 20171030-191207_1802786448 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:28:18,793] ({qtp89387388-446} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:28:18,799] ({pool-2-thread-2} SchedulerFactory.java[jobStarted]:114) - Job 20171030-192143_1165730818 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:28:18,800] ({pool-2-thread-2} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20171030-192143_1165730818, interpreter: pyspark, note_id: 2FQ9A4Z9B, user: anonymous]
 WARN [2020-10-30 20:28:18,806] ({pool-2-thread-2} NotebookServer.java[afterStatusChange]:2316) - Job 20171030-192143_1165730818 is finished, status: ERROR, exception: null, result: %text Traceback (most recent call last):
  File "/tmp/zeppelin_pyspark-3446420817745028958.py", line 364, in <module>
    code = compile('\n'.join(stmts), '<stdin>', 'exec', ast.PyCF_ONLY_AST, 1)
  File "<stdin>", line 11
    dtModel2 = dtEstimator2...
                             ^
SyntaxError: invalid syntax

 INFO [2020-10-30 20:28:18,869] ({pool-2-thread-2} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:28:18,878] ({pool-2-thread-2} SchedulerFactory.java[jobFinished]:120) - Job 20171030-192143_1165730818 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:28:38,258] ({qtp89387388-506} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:28:55,774] ({qtp89387388-66} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:29:00,433] ({qtp89387388-66} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:29:01,421] ({qtp89387388-446} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:29:01,428] ({pool-2-thread-18} SchedulerFactory.java[jobStarted]:114) - Job 20171030-192143_1165730818 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:29:01,429] ({pool-2-thread-18} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20171030-192143_1165730818, interpreter: pyspark, note_id: 2FQ9A4Z9B, user: anonymous]
 INFO [2020-10-30 20:29:02,433] ({pool-2-thread-18} NotebookServer.java[afterStatusChange]:2314) - Job 20171030-192143_1165730818 is finished successfully, status: FINISHED
 INFO [2020-10-30 20:29:02,438] ({JobProgressPoller, jobId=20171030-192143_1165730818} NotebookServer.java[onClose]:372) - Closed connection to 127.0.0.1 : 52238. (1006) WebSocket Write EOF
 INFO [2020-10-30 20:29:02,494] ({pool-2-thread-18} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:29:02,499] ({pool-2-thread-18} SchedulerFactory.java[jobFinished]:120) - Job 20171030-192143_1165730818 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:29:04,048] ({qtp89387388-76} NotebookServer.java[onOpen]:151) - New connection from 127.0.0.1 : 52988
 INFO [2020-10-30 20:29:04,085] ({qtp89387388-446} NotebookServer.java[sendNote]:828) - New operation from 127.0.0.1 : 52988 : anonymous : GET_NOTE : 2FQ9A4Z9B
 WARN [2020-10-30 20:29:04,104] ({qtp89387388-446} GitNotebookRepo.java[revisionHistory]:158) - No Head found for 2FQ9A4Z9B, No HEAD exists and no explicit starting revision was specified
 WARN [2020-10-30 20:29:04,299] ({qtp89387388-76} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 20:29:04,299] ({qtp89387388-76} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 20:29:04,300] ({qtp89387388-76} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 20:29:04,300] ({qtp89387388-76} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 20:29:04,300] ({qtp89387388-76} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-10-30 20:29:04,300] ({qtp89387388-76} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 INFO [2020-10-30 20:29:24,520] ({qtp89387388-446} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:29:24,530] ({pool-2-thread-10} SchedulerFactory.java[jobStarted]:114) - Job 20161107-153542_1780323791 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:29:24,531] ({pool-2-thread-10} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20161107-153542_1780323791, interpreter: pyspark, note_id: 2FQ9A4Z9B, user: anonymous]
 INFO [2020-10-30 20:29:25,283] ({pool-2-thread-10} NotebookServer.java[afterStatusChange]:2314) - Job 20161107-153542_1780323791 is finished successfully, status: FINISHED
 INFO [2020-10-30 20:29:25,347] ({pool-2-thread-10} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:29:25,356] ({pool-2-thread-10} SchedulerFactory.java[jobFinished]:120) - Job 20161107-153542_1780323791 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:29:28,267] ({qtp89387388-21} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:29:28,273] ({pool-2-thread-19} SchedulerFactory.java[jobStarted]:114) - Job 20171030-034039_1210912394 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:29:28,274] ({pool-2-thread-19} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20171030-034039_1210912394, interpreter: pyspark, note_id: 2FQ9A4Z9B, user: anonymous]
 INFO [2020-10-30 20:29:29,343] ({pool-2-thread-19} NotebookServer.java[afterStatusChange]:2314) - Job 20171030-034039_1210912394 is finished successfully, status: FINISHED
 INFO [2020-10-30 20:29:29,406] ({pool-2-thread-19} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:29:29,412] ({pool-2-thread-19} SchedulerFactory.java[jobFinished]:120) - Job 20171030-034039_1210912394 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:29:31,205] ({qtp89387388-446} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:29:31,211] ({pool-2-thread-6} SchedulerFactory.java[jobStarted]:114) - Job 20171030-195356_14273686 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:29:31,212] ({pool-2-thread-6} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20171030-195356_14273686, interpreter: pyspark, note_id: 2FQ9A4Z9B, user: anonymous]
 INFO [2020-10-30 20:29:31,244] ({pool-2-thread-6} NotebookServer.java[afterStatusChange]:2314) - Job 20171030-195356_14273686 is finished successfully, status: FINISHED
 INFO [2020-10-30 20:29:31,307] ({pool-2-thread-6} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:29:31,312] ({pool-2-thread-6} SchedulerFactory.java[jobFinished]:120) - Job 20171030-195356_14273686 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:29:37,069] ({qtp89387388-446} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:29:37,075] ({pool-2-thread-20} SchedulerFactory.java[jobStarted]:114) - Job 20171030-034111_1613140514 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:29:37,076] ({pool-2-thread-20} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20171030-034111_1613140514, interpreter: pyspark, note_id: 2FQ9A4Z9B, user: anonymous]
 INFO [2020-10-30 20:29:37,978] ({pool-2-thread-20} NotebookServer.java[afterStatusChange]:2314) - Job 20171030-034111_1613140514 is finished successfully, status: FINISHED
 INFO [2020-10-30 20:29:38,047] ({pool-2-thread-20} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:29:38,056] ({pool-2-thread-20} SchedulerFactory.java[jobFinished]:120) - Job 20171030-034111_1613140514 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:29:41,136] ({qtp89387388-71} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:29:41,143] ({pool-2-thread-11} SchedulerFactory.java[jobStarted]:114) - Job 20161107-130547_297924932 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:29:41,143] ({pool-2-thread-11} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20161107-130547_297924932, interpreter: pyspark, note_id: 2FQ9A4Z9B, user: anonymous]
 INFO [2020-10-30 20:29:43,877] ({pool-2-thread-11} NotebookServer.java[afterStatusChange]:2314) - Job 20161107-130547_297924932 is finished successfully, status: FINISHED
 INFO [2020-10-30 20:29:43,942] ({pool-2-thread-11} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:29:43,949] ({pool-2-thread-11} SchedulerFactory.java[jobFinished]:120) - Job 20161107-130547_297924932 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:29:55,852] ({qtp89387388-446} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:29:55,860] ({pool-2-thread-21} SchedulerFactory.java[jobStarted]:114) - Job 20171030-202050_1263604133 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:29:55,861] ({pool-2-thread-21} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20171030-202050_1263604133, interpreter: pyspark, note_id: 2FQ9A4Z9B, user: anonymous]
 WARN [2020-10-30 20:29:55,892] ({pool-2-thread-21} NotebookServer.java[afterStatusChange]:2316) - Job 20171030-202050_1263604133 is finished, status: ERROR, exception: null, result: %text Fail to execute line 14:                     .select("*", ith("probability",lit(1-posF)).alias("prob"))
Traceback (most recent call last):
  File "/tmp/zeppelin_pyspark-3446420817745028958.py", line 375, in <module>
    exec(code, _zcUserQueryNameSpace)
  File "<stdin>", line 14, in <module>
NameError: name 'posF' is not defined

 INFO [2020-10-30 20:29:55,956] ({pool-2-thread-21} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:29:55,963] ({pool-2-thread-21} SchedulerFactory.java[jobFinished]:120) - Job 20171030-202050_1263604133 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:30:25,373] ({qtp89387388-26} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:30:25,381] ({pool-2-thread-4} SchedulerFactory.java[jobStarted]:114) - Job 20161107-130547_297924932 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:30:25,381] ({pool-2-thread-4} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20161107-130547_297924932, interpreter: pyspark, note_id: 2FQ9A4Z9B, user: anonymous]
 INFO [2020-10-30 20:30:27,255] ({pool-2-thread-4} NotebookServer.java[afterStatusChange]:2314) - Job 20161107-130547_297924932 is finished successfully, status: FINISHED
 INFO [2020-10-30 20:30:27,317] ({pool-2-thread-4} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:30:27,325] ({pool-2-thread-4} SchedulerFactory.java[jobFinished]:120) - Job 20161107-130547_297924932 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:30:49,247] ({qtp89387388-66} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:30:49,254] ({pool-2-thread-22} SchedulerFactory.java[jobStarted]:114) - Job 20161107-131714_601581381 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:30:49,255] ({pool-2-thread-22} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20161107-131714_601581381, interpreter: pyspark, note_id: 2FQ9A4Z9B, user: anonymous]
 WARN [2020-10-30 20:30:49,263] ({pool-2-thread-22} NotebookServer.java[afterStatusChange]:2316) - Job 20161107-131714_601581381 is finished, status: ERROR, exception: null, result: %text Fail to execute line 1: plot_classification(testFeaturized, surfaceDF=gridPredictionLR, prob=True)
Traceback (most recent call last):
  File "/tmp/zeppelin_pyspark-3446420817745028958.py", line 380, in <module>
    exec(code, _zcUserQueryNameSpace)
  File "<stdin>", line 1, in <module>
NameError: name 'gridPredictionLR' is not defined

 INFO [2020-10-30 20:30:49,333] ({pool-2-thread-22} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:30:49,340] ({pool-2-thread-22} SchedulerFactory.java[jobFinished]:120) - Job 20161107-131714_601581381 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:31:09,243] ({qtp89387388-446} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:31:09,328] ({qtp89387388-25} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:31:09,335] ({pool-2-thread-12} SchedulerFactory.java[jobStarted]:114) - Job 20171030-202050_1263604133 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:31:09,336] ({pool-2-thread-12} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20171030-202050_1263604133, interpreter: pyspark, note_id: 2FQ9A4Z9B, user: anonymous]
 WARN [2020-10-30 20:31:09,361] ({pool-2-thread-12} NotebookServer.java[afterStatusChange]:2316) - Job 20171030-202050_1263604133 is finished, status: ERROR, exception: null, result: %text Fail to execute line 14:                     .select("*", ith("probability",lit(1-pos)).alias("prob"))
Traceback (most recent call last):
  File "/tmp/zeppelin_pyspark-3446420817745028958.py", line 375, in <module>
    exec(code, _zcUserQueryNameSpace)
  File "<stdin>", line 14, in <module>
NameError: name 'pos' is not defined

 INFO [2020-10-30 20:31:09,419] ({pool-2-thread-12} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:31:09,426] ({pool-2-thread-12} SchedulerFactory.java[jobFinished]:120) - Job 20171030-202050_1263604133 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:31:17,754] ({qtp89387388-66} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:34:34,543] ({qtp89387388-797} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:35:45,272] ({qtp89387388-797} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:36:30,677] ({qtp89387388-71} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:36:47,650] ({qtp89387388-22} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:36:47,739] ({qtp89387388-71} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:36:47,746] ({pool-2-thread-23} SchedulerFactory.java[jobStarted]:114) - Job 20201029-105351_101361532 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:36:47,747] ({pool-2-thread-23} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20201029-105351_101361532, interpreter: pyspark, note_id: 2FQ9A4Z9B, user: anonymous]
 WARN [2020-10-30 20:36:47,813] ({pool-2-thread-23} NotebookServer.java[afterStatusChange]:2316) - Job 20201029-105351_101361532 is finished, status: ERROR, exception: null, result: %text Fail to execute line 15:     regParam=0.01)
Traceback (most recent call last):
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/ml/param/__init__.py", line 419, in _set
    value = p.typeConverter(value)
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/ml/param/__init__.py", line 204, in toString
    raise TypeError("Could not convert %s to string type" % type(value))
TypeError: Could not convert <class 'int'> to string type

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/tmp/zeppelin_pyspark-3446420817745028958.py", line 375, in <module>
    exec(code, _zcUserQueryNameSpace)
  File "<stdin>", line 15, in <module>
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/__init__.py", line 104, in wrapper
    return func(self, **kwargs)
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/ml/classification.py", line 286, in __init__
    self.setParams(**kwargs)
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/__init__.py", line 104, in wrapper
    return func(self, **kwargs)
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/ml/classification.py", line 306, in setParams
    self._set(**kwargs)
  File "/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/interpreter/spark/pyspark/pyspark.zip/pyspark/ml/param/__init__.py", line 421, in _set
    raise TypeError('Invalid param value given for param "%s". %s' % (p.name, e))
TypeError: Invalid param value given for param "featuresCol". Could not convert <class 'int'> to string type

 INFO [2020-10-30 20:36:47,873] ({pool-2-thread-23} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:36:47,880] ({pool-2-thread-23} SchedulerFactory.java[jobFinished]:120) - Job 20201029-105351_101361532 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:38:09,047] ({qtp89387388-71} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:38:22,762] ({qtp89387388-1024} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:38:22,769] ({pool-2-thread-7} SchedulerFactory.java[jobStarted]:114) - Job 20201029-115810_2102902904 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:38:22,770] ({pool-2-thread-7} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20201029-115810_2102902904, interpreter: pyspark, note_id: 2FQ9A4Z9B, user: anonymous]
 INFO [2020-10-30 20:38:23,657] ({pool-2-thread-7} NotebookServer.java[afterStatusChange]:2314) - Job 20201029-115810_2102902904 is finished successfully, status: FINISHED
 INFO [2020-10-30 20:38:23,729] ({pool-2-thread-7} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:38:23,737] ({pool-2-thread-7} SchedulerFactory.java[jobFinished]:120) - Job 20201029-115810_2102902904 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:38:27,663] ({qtp89387388-1024} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:38:27,672] ({pool-2-thread-24} SchedulerFactory.java[jobStarted]:114) - Job 20181023-192830_1881710964 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:38:27,672] ({pool-2-thread-24} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20181023-192830_1881710964, interpreter: pyspark, note_id: 2FQ9A4Z9B, user: anonymous]
 INFO [2020-10-30 20:38:28,258] ({pool-2-thread-24} NotebookServer.java[afterStatusChange]:2314) - Job 20181023-192830_1881710964 is finished successfully, status: FINISHED
 INFO [2020-10-30 20:38:28,365] ({pool-2-thread-24} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:38:28,373] ({pool-2-thread-24} SchedulerFactory.java[jobFinished]:120) - Job 20181023-192830_1881710964 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:38:34,531] ({qtp89387388-69} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:38:34,540] ({pool-2-thread-13} SchedulerFactory.java[jobStarted]:114) - Job 20171106-185738_491325525 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:38:34,541] ({pool-2-thread-13} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20171106-185738_491325525, interpreter: pyspark, note_id: 2FQ9A4Z9B, user: anonymous]
 INFO [2020-10-30 20:38:34,553] ({pool-2-thread-13} NotebookServer.java[afterStatusChange]:2314) - Job 20171106-185738_491325525 is finished successfully, status: FINISHED
 INFO [2020-10-30 20:38:34,623] ({pool-2-thread-13} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:38:34,629] ({pool-2-thread-13} SchedulerFactory.java[jobFinished]:120) - Job 20171106-185738_491325525 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:38:39,837] ({qtp89387388-1024} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:38:39,858] ({pool-2-thread-25} SchedulerFactory.java[jobStarted]:114) - Job 20171031-015523_507876710 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:38:39,858] ({pool-2-thread-25} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20171031-015523_507876710, interpreter: pyspark, note_id: 2FQ9A4Z9B, user: anonymous]
 INFO [2020-10-30 20:38:45,186] ({pool-2-thread-25} NotebookServer.java[afterStatusChange]:2314) - Job 20171031-015523_507876710 is finished successfully, status: FINISHED
 INFO [2020-10-30 20:38:45,258] ({pool-2-thread-25} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:38:45,627] ({pool-2-thread-25} SchedulerFactory.java[jobFinished]:120) - Job 20171031-015523_507876710 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:49:46,231] ({qtp89387388-1024} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:49:46,307] ({pool-2-thread-3} SchedulerFactory.java[jobStarted]:114) - Job 20171030-212354_434864230 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:49:46,308] ({pool-2-thread-3} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20171030-212354_434864230, interpreter: pyspark, note_id: 2FQ9A4Z9B, user: anonymous]
 INFO [2020-10-30 20:49:48,000] ({pool-2-thread-3} NotebookServer.java[afterStatusChange]:2314) - Job 20171030-212354_434864230 is finished successfully, status: FINISHED
 INFO [2020-10-30 20:49:48,054] ({pool-2-thread-3} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:49:48,102] ({pool-2-thread-3} SchedulerFactory.java[jobFinished]:120) - Job 20171030-212354_434864230 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:49:50,254] ({qtp89387388-1113} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:49:50,309] ({pool-2-thread-26} SchedulerFactory.java[jobStarted]:114) - Job 20171030-212654_1670049849 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:49:50,310] ({pool-2-thread-26} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20171030-212654_1670049849, interpreter: pyspark, note_id: 2FQ9A4Z9B, user: anonymous]
 INFO [2020-10-30 20:49:50,985] ({pool-2-thread-26} NotebookServer.java[afterStatusChange]:2314) - Job 20171030-212654_1670049849 is finished successfully, status: FINISHED
 INFO [2020-10-30 20:49:51,044] ({pool-2-thread-26} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:49:51,094] ({pool-2-thread-26} SchedulerFactory.java[jobFinished]:120) - Job 20171030-212654_1670049849 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:50:21,273] ({qtp89387388-1114} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:50:21,323] ({pool-2-thread-14} SchedulerFactory.java[jobStarted]:114) - Job 20191205-193540_1402055631 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:50:21,324] ({pool-2-thread-14} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20191205-193540_1402055631, interpreter: pyspark, note_id: 2FQ9A4Z9B, user: anonymous]
 WARN [2020-10-30 20:50:21,335] ({pool-2-thread-14} NotebookServer.java[afterStatusChange]:2316) - Job 20191205-193540_1402055631 is finished, status: ERROR, exception: null, result: %text Traceback (most recent call last):
  File "/tmp/zeppelin_pyspark-3446420817745028958.py", line 364, in <module>
    code = compile('\n'.join(stmts), '<stdin>', 'exec', ast.PyCF_ONLY_AST, 1)
  File "<stdin>", line 1
    from pyspark.ml.clustering import ...KMeans
                                        ^
SyntaxError: invalid syntax

 INFO [2020-10-30 20:50:21,395] ({pool-2-thread-14} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:50:21,444] ({pool-2-thread-14} SchedulerFactory.java[jobFinished]:120) - Job 20191205-193540_1402055631 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:50:38,929] ({qtp89387388-1024} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:50:38,977] ({pool-2-thread-27} SchedulerFactory.java[jobStarted]:114) - Job 20201028-184223_1946095610 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:50:38,978] ({pool-2-thread-27} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20201028-184223_1946095610, interpreter: pyspark, note_id: 2FQ9A4Z9B, user: anonymous]
 INFO [2020-10-30 20:50:39,478] ({pool-2-thread-27} NotebookServer.java[afterStatusChange]:2314) - Job 20201028-184223_1946095610 is finished successfully, status: FINISHED
 INFO [2020-10-30 20:50:39,538] ({pool-2-thread-27} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:50:39,593] ({pool-2-thread-27} SchedulerFactory.java[jobFinished]:120) - Job 20201028-184223_1946095610 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:52:42,443] ({qtp89387388-1113} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:52:42,491] ({pool-2-thread-8} SchedulerFactory.java[jobStarted]:114) - Job 20171031-020723_554273089 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 20:52:42,492] ({pool-2-thread-8} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20171031-020723_554273089, interpreter: pyspark, note_id: 2FQ9A4Z9B, user: anonymous]
 INFO [2020-10-30 20:52:43,815] ({pool-2-thread-8} NotebookServer.java[afterStatusChange]:2314) - Job 20171031-020723_554273089 is finished successfully, status: FINISHED
 INFO [2020-10-30 20:52:43,872] ({pool-2-thread-8} VFSNotebookRepo.java[save]:196) - Saving note:2FQ9A4Z9B
 INFO [2020-10-30 20:52:44,271] ({pool-2-thread-8} SchedulerFactory.java[jobFinished]:120) - Job 20171031-020723_554273089 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-10-30 23:18:42,070] ({qtp89387388-1350} NotebookServer.java[onClose]:372) - Closed connection to 127.0.0.1 : 52988. (1006) WebSocket Read EOF
 INFO [2020-10-30 23:18:46,323] ({Thread-39} ZeppelinServer.java[run]:253) - Shutting down Zeppelin Server ... 
 INFO [2020-10-30 23:18:46,345] ({Thread-39} AbstractConnector.java[doStop]:341) - Stopped ServerConnector@643d2dae{HTTP/1.1,[http/1.1]}{127.0.0.1:9322}
 INFO [2020-10-30 23:18:46,346] ({Thread-39} HouseKeeper.java[stopScavenging]:167) - node0 Stopped scavenging
 INFO [2020-10-30 23:18:46,892] ({Exec Default Executor} RemoteInterpreterManagedProcess.java[onProcessFailed]:250) - Interpreter process failed {}
org.apache.commons.exec.ExecuteException: Process exited with an error: 130 (Exit value: 130)
	at org.apache.commons.exec.DefaultExecutor.executeInternal(DefaultExecutor.java:404)
	at org.apache.commons.exec.DefaultExecutor.access$200(DefaultExecutor.java:48)
	at org.apache.commons.exec.DefaultExecutor$1.run(DefaultExecutor.java:200)
	at java.lang.Thread.run(Thread.java:745)
 INFO [2020-10-30 23:18:48,668] ({Thread-39} ContextHandler.java[doStop]:1045) - Stopped o.e.j.w.WebAppContext@15761df8{zeppelin-web,/,null,UNAVAILABLE}{/users/ssulca/diplodatos_bigdata/spark/zeppelin-0.8.2-bin-all/zeppelin-web-0.8.2.war}
 INFO [2020-10-30 23:18:48,669] ({Thread-1211} InterpreterSetting.java[close]:483) - Close InterpreterSetting: ignite
 INFO [2020-10-30 23:18:48,670] ({Thread-1210} InterpreterSetting.java[close]:483) - Close InterpreterSetting: ignite
 INFO [2020-10-30 23:18:48,670] ({Thread-1212} InterpreterSetting.java[close]:483) - Close InterpreterSetting: python
 INFO [2020-10-30 23:18:48,670] ({Thread-1213} InterpreterSetting.java[close]:483) - Close InterpreterSetting: python
 INFO [2020-10-30 23:18:48,670] ({Thread-1214} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sap
 INFO [2020-10-30 23:18:48,671] ({Thread-1221} InterpreterSetting.java[close]:483) - Close InterpreterSetting: pig
 INFO [2020-10-30 23:18:48,671] ({Thread-1217} InterpreterSetting.java[close]:483) - Close InterpreterSetting: jdbc
 INFO [2020-10-30 23:18:48,671] ({Thread-1219} InterpreterSetting.java[close]:483) - Close InterpreterSetting: lens
 INFO [2020-10-30 23:18:48,672] ({Thread-1226} InterpreterSetting.java[close]:483) - Close InterpreterSetting: groovy
 INFO [2020-10-30 23:18:48,670] ({Thread-1215} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sap
 INFO [2020-10-30 23:18:48,670] ({Thread-1216} InterpreterSetting.java[close]:483) - Close InterpreterSetting: jdbc
 INFO [2020-10-30 23:18:48,673] ({Thread-1231} InterpreterSetting.java[close]:483) - Close InterpreterSetting: livy
 INFO [2020-10-30 23:18:48,673] ({Thread-1227} InterpreterSetting.java[close]:483) - Close InterpreterSetting: angular
 INFO [2020-10-30 23:18:48,674] ({Thread-1237} InterpreterSetting.java[close]:483) - Close InterpreterSetting: cassandra
 INFO [2020-10-30 23:18:48,675] ({Thread-1239} InterpreterSetting.java[close]:483) - Close InterpreterSetting: md
 INFO [2020-10-30 23:18:48,675] ({Thread-1244} InterpreterSetting.java[close]:483) - Close InterpreterSetting: cassandra
 INFO [2020-10-30 23:18:48,673] ({Thread-1229} InterpreterSetting.java[close]:483) - Close InterpreterSetting: file
 INFO [2020-10-30 23:18:48,673] ({Thread-1225} InterpreterSetting.java[close]:483) - Close InterpreterSetting: flink
 INFO [2020-10-30 23:18:48,676] ({Thread-1251} InterpreterSetting.java[close]:483) - Close InterpreterSetting: kylin
 INFO [2020-10-30 23:18:48,673] ({Thread-1228} InterpreterSetting.java[close]:483) - Close InterpreterSetting: neo4j
 INFO [2020-10-30 23:18:48,672] ({Thread-1224} InterpreterSetting.java[close]:483) - Close InterpreterSetting: livy
 INFO [2020-10-30 23:18:48,672] ({Thread-1220} InterpreterSetting.java[close]:483) - Close InterpreterSetting: pig
 INFO [2020-10-30 23:18:48,671] ({Thread-1223} InterpreterSetting.java[close]:483) - Close InterpreterSetting: angular
 INFO [2020-10-30 23:18:48,671] ({Thread-1222} InterpreterSetting.java[close]:483) - Close InterpreterSetting: flink
 INFO [2020-10-30 23:18:48,671] ({Thread-1218} InterpreterSetting.java[close]:483) - Close InterpreterSetting: lens
 INFO [2020-10-30 23:18:48,676] ({Thread-1250} InterpreterSetting.java[close]:483) - Close InterpreterSetting: hbase
 INFO [2020-10-30 23:18:48,676] ({Thread-1248} InterpreterSetting.java[close]:483) - Close InterpreterSetting: kylin
 INFO [2020-10-30 23:18:48,676] ({Thread-1249} InterpreterSetting.java[close]:483) - Close InterpreterSetting: bigquery
 INFO [2020-10-30 23:18:48,676] ({Thread-1243} InterpreterSetting.java[close]:483) - Close InterpreterSetting: hbase
 INFO [2020-10-30 23:18:48,676] ({Thread-1247} InterpreterSetting.java[close]:483) - Close InterpreterSetting: alluxio
 INFO [2020-10-30 23:18:48,675] ({Thread-1246} InterpreterSetting.java[close]:483) - Close InterpreterSetting: md
 INFO [2020-10-30 23:18:48,675] ({Thread-1245} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sh
 INFO [2020-10-30 23:18:48,675] ({Thread-1239} ManagedInterpreterGroup.java[close]:89) - Close InterpreterGroup: md:shared_process
 INFO [2020-10-30 23:18:48,675] ({Thread-1242} InterpreterSetting.java[close]:483) - Close InterpreterSetting: spark
 INFO [2020-10-30 23:18:48,675] ({Thread-1236} InterpreterSetting.java[close]:483) - Close InterpreterSetting: elasticsearch
 INFO [2020-10-30 23:18:48,675] ({Thread-1241} InterpreterSetting.java[close]:483) - Close InterpreterSetting: bigquery
 INFO [2020-10-30 23:18:48,675] ({Thread-1240} InterpreterSetting.java[close]:483) - Close InterpreterSetting: alluxio
 INFO [2020-10-30 23:18:48,674] ({Thread-1238} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sh
 INFO [2020-10-30 23:18:48,674] ({Thread-1235} InterpreterSetting.java[close]:483) - Close InterpreterSetting: file
 INFO [2020-10-30 23:18:48,674] ({Thread-1234} InterpreterSetting.java[close]:483) - Close InterpreterSetting: spark
 INFO [2020-10-30 23:18:48,674] ({Thread-1233} InterpreterSetting.java[close]:483) - Close InterpreterSetting: neo4j
 INFO [2020-10-30 23:18:48,674] ({Thread-1232} InterpreterSetting.java[close]:483) - Close InterpreterSetting: groovy
 INFO [2020-10-30 23:18:48,674] ({Thread-1230} InterpreterSetting.java[close]:483) - Close InterpreterSetting: elasticsearch
 INFO [2020-10-30 23:18:48,678] ({Thread-1242} ManagedInterpreterGroup.java[close]:89) - Close InterpreterGroup: spark:shared_process
 INFO [2020-10-30 23:18:48,678] ({Thread-1239} ManagedInterpreterGroup.java[close]:100) - Close Session: shared_session for interpreter setting: md
 INFO [2020-10-30 23:18:48,680] ({Thread-1242} ManagedInterpreterGroup.java[close]:100) - Close Session: shared_session for interpreter setting: spark
 WARN [2020-10-30 23:18:48,680] ({Thread-1242} RemoteInterpreter.java[close]:199) - close is called when RemoterInterpreter is not opened for org.apache.zeppelin.spark.SparkInterpreter
 WARN [2020-10-30 23:18:48,680] ({Thread-1239} RemoteInterpreter.java[close]:199) - close is called when RemoterInterpreter is not opened for org.apache.zeppelin.markdown.Markdown
 WARN [2020-10-30 23:18:48,681] ({Thread-1242} RemoteInterpreter.java[close]:199) - close is called when RemoterInterpreter is not opened for org.apache.zeppelin.spark.SparkSqlInterpreter
 INFO [2020-10-30 23:18:48,683] ({Thread-1239} ManagedInterpreterGroup.java[close]:105) - Remove this InterpreterGroup: md:shared_process as all the sessions are closed
 WARN [2020-10-30 23:18:48,683] ({Thread-1242} RemoteInterpreter.java[close]:199) - close is called when RemoterInterpreter is not opened for org.apache.zeppelin.spark.DepInterpreter
 INFO [2020-10-30 23:18:48,683] ({Thread-1246} ManagedInterpreterGroup.java[close]:89) - Close InterpreterGroup: md:shared_process
 INFO [2020-10-30 23:18:48,693] ({Thread-1234} ManagedInterpreterGroup.java[close]:89) - Close InterpreterGroup: spark:shared_process
 INFO [2020-10-30 23:18:48,693] ({Thread-39} NotebookRepoSync.java[close]:428) - Closing all notebook storages
 INFO [2020-10-30 23:18:51,703] ({Thread-39} ZeppelinServer.java[run]:264) - Bye
